Loop device parser support.
===========================

These are my work-in-progress patches for developing
VHD/VMDK/qcow and other-virtual-disk support in loop device via
the addition of loop parser support and parser implementations.

Patches are now rebased to linux-next (as of 9/26/2011).

Performance is tested using superalign (https://github.com/andreiw/superalign)

I think a hallmark of good design isn't just time and space considerations, but
also ease of implementation. It's roughly 3 hours to implement the QCOW (v1) logic
and test. It's been about 8 to implement and test dynamic VHD - and you get better
use of unallocated space for QCOW.

Ex: for 100m qcow and VHD at default settings, empty disks take up 448 and 2.5k
respectively. Formatted with mkfs.ext2, they take up 3.3m and 24.3m respectively.
Astounding.

VHD spec is at:
http://www.microsoft.com/download/en/details.aspx?id=23850

QCOW spec is at: 
http://people.gnome.org/~markmc/qcow-image-format-version-1.html

VMDK spec is at:
http://www.vmware.com/technical-resources/interfaces/vmdk.html

Using.
======

Apply patches. Your .config should have something like:

CONFIG_BLK_DEV_LOOP=y
CONFIG_BLK_DEV_LOOP_MIN_COUNT=8
CONFIG_BLK_DEV_LOOP_UTIL=y
CONFIG_BLK_DEV_VHDLOOP=y
CONFIG_BLK_DEV_QCOWLOOP=y
CONFIG_BLK_DEV_VMDKLOOP=y

Mounting is easy, since the losetup interface isn't (and won't be)
changing.

$ losetup /dev/loop0 /path/to/image

You will see some acknowledging messages from the kernel regarding
image type and loop size.

Your either want to set loop.max_parts to something non-zero (10 sounds good to me),
or use kpartx to actually see partitions on devices.

To generate VHDs you can use my vhdtool (https://github.com/andreiw/vhdtool), which
allows you to fine-tune metadata details for dynamic disks (and unlike qemu-img, doesn't
create b0rked images).

For other image types `man 1 qemu-img` (obviously requires qemu installed).

To-do.
======

VHD parser to-do:
1) Fixed-size VHDs (Done!)
2) Dynamic VHDs (Done!)
3) Differencing VHDs (Should be trivial, since it's a special
   case of dynamic VHDs)
4) Benching against exsting nbd/fuse-based solutions.
6) Optimizations of read/write path.
8) Parser options and backwards-compat loop_info changes.

QCOW parser to-do:
1) Support RW on v1 (done!)
2) Support v2.
3) Support COW disks (painful, since there is no parent
   UUID to match against, necessitating some loop changes).

VMDK parser to do:
1) Support RO on hosted extents.
2) Support RW on hosted extents.
3) Support ESX extents.
4) Support COW.

Common:
1) Think about and split out common functionality: it's
   painful how similar both the VHD and QCOW parsers look,
   from an internal data structure POV. (done!)
2) lo_file management in loop.c is crucial for differencing/COW
   disk support.
3) Think about a common interface for dealing with COW/differencing
   disks. It looks like change_fd is the right mechanism, just need
   to figure out how to prevent silly things from happening (or not?)

Notes:
Previous versions used a complicated scheme to cache metadata, but
tests have pointed out that just reading/writing ended up being just
as good and possibly faster to caching metadata - after all, it's
already getting cached by the page and buffer caches. So the metadata
caching has been removed, at the additional benefit of clearer code
with less memory overhead. 

Contact Info
============

Andrei Warkentin (andrey.warkentin@gmail.com, andreiw@vmware.com, andreiw@msalumni.com)