# HG changeset patch
# User Andrei Warkentin <andreiw@motorola.com>
# Date 1304464411 18000
# Node ID 85377876ea8d0b33aff3cf6ea840250377f5d7bd
# Parent  476b0d68e7d5405babc1182da3b345b1e4cc1bca
ARM: ARMv7 support patch.

This is meant to be Xen 4.2 ARM support. Intially targetting
ARMv7 on a Tegra 2 SoC.

This doesn't build yet. Partially based on Samsung Xen 3.0 code.

Signed-off-by: Andrei Warkentin <andreiw@motorola.com>

diff --git a/Makefile b/Makefile
--- a/Makefile
+++ b/Makefile
@@ -10,7 +10,7 @@
 include Config.mk
 
 SUBARCH := $(subst x86_32,i386,$(XEN_TARGET_ARCH))
-export XEN_TARGET_ARCH SUBARCH XEN_SYSTYPE
+export XEN_TARGET_ARCH SUBARCH XEN_SYSTYPE XEN_TARGET_PLAT
 include buildconfigs/Rules.mk
 
 # build and install everything into the standard system directories
diff --git a/config/arm.mk b/config/arm.mk
new file mode 100644
--- /dev/null
+++ b/config/arm.mk
@@ -0,0 +1,4 @@
+CONFIG_ARM := y
+CONFIG_ARM_$(XEN_OS) := y
+
+CONFIG_IOEMU := n
diff --git a/xen/arch/arm/Makefile b/xen/arch/arm/Makefile
new file mode 100644
--- /dev/null
+++ b/xen/arch/arm/Makefile
@@ -0,0 +1,72 @@
+#
+# xen/arch/arm/Makefile
+#
+
+ifndef XEN_TARGET_PLAT
+$(error Unspecified target platform)
+endif
+
+CURRENT_PLAT_INCLUDE ?= $(shell readlink -f $(BASEDIR)/include/asm/plat)
+PLAT_INCLUDE ?= $(shell readlink -f $(BASEDIR)/include/asm/$(XEN_TARGET_PLAT))
+
+ifneq ($(PLAT_INCLUDE),$(CURRENT_PLAT_INCLUDE))
+$(shell rm -f $(BASEDIR)/include/asm/plat)
+$(shell ln -s $(BASEDIR)/include/asm/$(XEN_TARGET_PLAT) $(BASEDIR)/include/asm/plat )
+endif
+
+subdir-y += $(XEN_TARGET_PLAT)
+
+obj-$(crash_debug) += gdbstub.o
+
+$(TARGET): $(TARGET)-syms
+	@cp $(TARGET)-syms $@
+
+$(TARGET)-syms: $(ALL_OBJS) xen.lds.s
+	$(MAKE) -f $(BASEDIR)/Rules.mk $(BASEDIR)/common/symbols-dummy.o
+	$(LD) $(LDFLAGS) -T xen.lds.s -N -Map $(@D)/.$(@F).0.map $(ALL_OBJS) \
+		$(BASEDIR)/common/symbols-dummy.o -o $(@D)/.$(@F).0 
+	$(NM) -n $(@D)/.$(@F).0 | $(BASEDIR)/tools/symbols >$(@D)/.$(@F).0.S 
+	$(MAKE) -f $(BASEDIR)/Rules.mk $(@D)/.$(@F).0.o 
+	$(LD) $(LDFLAGS) -T xen.lds.s -N -Map $(@D)/.$(@F).1.map $(ALL_OBJS) \
+		$(@D)/.$(@F).0.o -o $(@D)/.$(@F).1 
+	$(NM) -n $(@D)/.$(@F).1 | $(BASEDIR)/tools/symbols >$(@D)/.$(@F).1.S 
+	$(MAKE) -f $(BASEDIR)/Rules.mk $(@D)/.$(@F).1.o 
+	$(LD) $(LDFLAGS) -T xen.lds.s -N -Map $@.map $(ALL_OBJS) \
+		$(@D)/.$(@F).1.o -o $@
+	rm -f $(@D)/.$(@F).[0-9]* 
+
+asm-offsets.s: asm-offsets.c \
+    $(BASEDIR)/include/asm-arm/.offsets.h.stamp
+	$(CC) $(CFLAGS) -DGENERATE_ASM_OFFSETS -S -o $@ $<
+
+$(BASEDIR)/include/asm-arm/asm-offsets.h: asm-offsets.s
+	@(set -e; \
+	  echo "/*"; \
+	  echo " * DO NOT MODIFY."; \
+	  echo " *"; \
+	  echo " * This file was auto-generated from $<"; \
+	  echo " *"; \
+	  echo " */"; \
+	  echo ""; \
+	  echo "#ifndef __ARM_OFFSETS_H__"; \
+	  echo "#define __ARM_OFFSETS_H__"; \
+	  echo ""; \
+	  sed -ne "/^->/{s:^->\([^ ]*\) [\$$#]*\([^ ]*\) \(.*\):#define \1 \2 /* \3 */:; s:->::; p;}"; \
+	  echo ""; \
+	  echo "#endif") <$< >$@
+
+$(BASEDIR)/include/asm-arm/.offsets.h.stamp:
+# Need such symbol link to make linux headers available
+	[ -e $(BASEDIR)/include/linux ] \
+	 || ln -sf $(BASEDIR)/include/xen $(BASEDIR)/include/linux
+	touch $@
+
+xen.lds.s: xen.lds.S
+	$(CC) -E $(CPPFLAGS) -P -DXEN $(AFLAGS) \
+		-o xen.lds.s xen.lds.S
+
+.PHONY: clean
+clean::
+	rm -f *.o *~ core xen.lds.s $(BASEDIR)/include/asm-arm/.offsets.h.stamp
+	rm -f asm-offsets.s $(BASEDIR)/include/asm-arm/asm-offsets.h
+	rm -f $(BASEDIR)/.xen-syms.[0-9]*
diff --git a/xen/arch/arm/Rules.mk b/xen/arch/arm/Rules.mk
new file mode 100644
--- /dev/null
+++ b/xen/arch/arm/Rules.mk
@@ -0,0 +1,28 @@
+########################################
+# arm-specific definitions
+
+arm := y
+HAS_ACPI := n
+HAS_VGA  := n
+xenoprof := n
+no_warns ?= n
+
+CFLAGS += -march=armv7-a -mlittle-endian -mabi=aapcs -mapcs -mpoke-function-name
+CFLAGS += -fno-builtin -fno-common
+CFLAGS += -iwithprefix include -pipe
+CFLAGS += -I$(BASEDIR)/include
+CFLAGS += -I$(BASEDIR)/include/asm-arm/mach-generic
+CFLAGS += -I$(BASEDIR)/include/asm-arm/mach-default
+
+# Prevent floating-point variables from creeping into Xen.
+CFLAGS += -msoft-float
+
+ifeq ($(no_warns),y)
+CFLAGS	+= -Wa,--fatal-warnings -Werror -Wno-uninitialized
+endif
+
+$(call cc-options-add,CFLAGS,CC,$(EMBEDDED_EXTRA_CFLAGS))
+
+# Require GCC v3.4+ (to avoid issues with alignment constraints in Xen headers)
+check-$(gcc) = $(call cc-ver-check,CC,0x030400,"Xen requires at least gcc-3.4")
+$(eval $(check-y))
diff --git a/xen/arch/arm/asm-offsets.c b/xen/arch/arm/asm-offsets.c
new file mode 100644
--- /dev/null
+++ b/xen/arch/arm/asm-offsets.c
@@ -0,0 +1,21 @@
+/*
+ * Generate definitions needed by assembly language modules.
+ * This code generates raw asm output which is post-processed
+ * to extract and format the required data.
+ */
+
+#include <xen/config.h>
+#include <xen/sched.h>
+#include <public/xen.h>
+
+#define DEFINE(sym, val) \
+        asm volatile("\n->" #sym " (%0) " #val : : "i" (val))
+
+#define BLANK() asm volatile("\n->" : : )
+
+#define OFFSET(_sym, _str, _mem) \
+    DEFINE(_sym, offsetof(_str, _mem));
+
+void foo(void)
+{
+}
diff --git a/xen/arch/arm/asm-offsets.s b/xen/arch/arm/asm-offsets.s
new file mode 100644
--- /dev/null
+++ b/xen/arch/arm/asm-offsets.s
@@ -0,0 +1,1396 @@
+	.arch armv7-a
+	.fpu softvfp
+	.eabi_attribute 20, 1
+	.eabi_attribute 21, 1
+	.eabi_attribute 23, 3
+	.eabi_attribute 24, 1
+	.eabi_attribute 25, 1
+	.eabi_attribute 26, 1
+	.eabi_attribute 30, 1
+	.eabi_attribute 18, 4
+	.file	"asm-offsets.c"
+	.section	.debug_abbrev,"",%progbits
+.Ldebug_abbrev0:
+	.section	.debug_info,"",%progbits
+.Ldebug_info0:
+	.section	.debug_line,"",%progbits
+.Ldebug_line0:
+	.text
+.Ltext0:
+	.align	2
+	.global	foo
+	.ascii	"foo\000"
+	.align	2
+	.word	4278190084
+	.type	foo, %function
+foo:
+.LFB182:
+	.file 1 "asm-offsets.c"
+	.loc 1 20 0
+	@ args = 0, pretend = 0, frame = 0
+	@ frame_needed = 1, uses_anonymous_args = 0
+	mov	ip, sp
+.LCFI0:
+	stmfd	sp!, {fp, ip, lr, pc}
+.LCFI1:
+	sub	fp, ip, #4
+.LCFI2:
+	.loc 1 21 0
+	ldmfd	sp, {fp, sp, pc}
+.LFE182:
+	.size	foo, .-foo
+	.section	.debug_frame,"",%progbits
+.Lframe0:
+	.4byte	.LECIE0-.LSCIE0
+.LSCIE0:
+	.4byte	0xffffffff
+	.byte	0x1
+	.ascii	"\000"
+	.uleb128 0x1
+	.sleb128 -4
+	.byte	0xe
+	.byte	0xc
+	.uleb128 0xd
+	.uleb128 0x0
+	.align	2
+.LECIE0:
+.LSFDE0:
+	.4byte	.LEFDE0-.LASFDE0
+.LASFDE0:
+	.4byte	.Lframe0
+	.4byte	.LFB182
+	.4byte	.LFE182-.LFB182
+	.byte	0x4
+	.4byte	.LCFI0-.LFB182
+	.byte	0xd
+	.uleb128 0xc
+	.byte	0x4
+	.4byte	.LCFI1-.LCFI0
+	.byte	0x11
+	.uleb128 0xe
+	.sleb128 2
+	.byte	0x11
+	.uleb128 0xd
+	.sleb128 3
+	.byte	0x11
+	.uleb128 0xb
+	.sleb128 4
+	.byte	0x4
+	.4byte	.LCFI2-.LCFI1
+	.byte	0xc
+	.uleb128 0xb
+	.uleb128 0x4
+	.align	2
+.LEFDE0:
+	.text
+.Letext0:
+	.section	.debug_loc,"",%progbits
+.Ldebug_loc0:
+.LLST0:
+	.4byte	.LFB182-.Ltext0
+	.4byte	.LCFI0-.Ltext0
+	.2byte	0x2
+	.byte	0x7d
+	.sleb128 0
+	.4byte	.LCFI0-.Ltext0
+	.4byte	.LCFI2-.Ltext0
+	.2byte	0x2
+	.byte	0x7c
+	.sleb128 0
+	.4byte	.LCFI2-.Ltext0
+	.4byte	.LFE182-.Ltext0
+	.2byte	0x2
+	.byte	0x7b
+	.sleb128 4
+	.4byte	0x0
+	.4byte	0x0
+	.file 2 "/home/fjnh84/src/xen-unstable.hg/xen/include/asm/types.h"
+	.file 3 "/home/fjnh84/src/xen-unstable.hg/xen/include/asm/spinlock.h"
+	.file 4 "/home/fjnh84/src/xen-unstable.hg/xen/include/xen/spinlock.h"
+	.file 5 "/home/fjnh84/src/xen-unstable.hg/xen/include/xen/cpumask.h"
+	.file 6 "/home/fjnh84/src/xen-unstable.hg/xen/include/xen/lib.h"
+	.file 7 "/home/fjnh84/src/xen-unstable.hg/xen/include/public/arch-arm.h"
+	.file 8 "/home/fjnh84/src/xen-unstable.hg/xen/include/xen/time.h"
+	.file 9 "/home/fjnh84/src/xen-unstable.hg/xen/include/xen/list.h"
+	.file 10 "/home/fjnh84/src/xen-unstable.hg/xen/include/xen/irq.h"
+	.file 11 "/home/fjnh84/src/xen-unstable.hg/xen/include/asm/irq.h"
+	.file 12 "/home/fjnh84/src/xen-unstable.hg/xen/include/xen/rcupdate.h"
+	.file 13 "/home/fjnh84/src/xen-unstable.hg/xen/include/xen/preempt.h"
+	.file 14 "/home/fjnh84/src/xen-unstable.hg/xen/include/asm/numa.h"
+	.file 15 "/home/fjnh84/src/xen-unstable.hg/xen/include/xen/sched.h"
+	.section	.debug_info
+	.4byte	0x5ba
+	.2byte	0x2
+	.4byte	.Ldebug_abbrev0
+	.byte	0x4
+	.uleb128 0x1
+	.4byte	.LASF64
+	.byte	0x1
+	.4byte	.LASF65
+	.4byte	.LASF66
+	.4byte	.Ltext0
+	.4byte	.Letext0
+	.4byte	.Ldebug_line0
+	.uleb128 0x2
+	.byte	0x1
+	.byte	0x6
+	.4byte	.LASF0
+	.uleb128 0x2
+	.byte	0x1
+	.byte	0x8
+	.4byte	.LASF1
+	.uleb128 0x2
+	.byte	0x2
+	.byte	0x5
+	.4byte	.LASF2
+	.uleb128 0x2
+	.byte	0x2
+	.byte	0x7
+	.4byte	.LASF3
+	.uleb128 0x3
+	.byte	0x4
+	.byte	0x5
+	.ascii	"int\000"
+	.uleb128 0x2
+	.byte	0x4
+	.byte	0x7
+	.4byte	.LASF4
+	.uleb128 0x2
+	.byte	0x8
+	.byte	0x5
+	.4byte	.LASF5
+	.uleb128 0x2
+	.byte	0x8
+	.byte	0x7
+	.4byte	.LASF6
+	.uleb128 0x4
+	.ascii	"u8\000"
+	.byte	0x2
+	.byte	0x17
+	.4byte	0x2c
+	.uleb128 0x4
+	.ascii	"u16\000"
+	.byte	0x2
+	.byte	0x1a
+	.4byte	0x3a
+	.uleb128 0x4
+	.ascii	"s64\000"
+	.byte	0x2
+	.byte	0x1f
+	.4byte	0x4f
+	.uleb128 0x2
+	.byte	0x4
+	.byte	0x7
+	.4byte	.LASF7
+	.uleb128 0x5
+	.4byte	.LASF8
+	.byte	0x2
+	.byte	0x27
+	.4byte	0x8f
+	.uleb128 0x2
+	.byte	0x1
+	.byte	0x8
+	.4byte	.LASF9
+	.uleb128 0x6
+	.byte	0x4
+	.uleb128 0x7
+	.byte	0x4
+	.byte	0x3
+	.byte	0x8
+	.4byte	0xaf
+	.uleb128 0x8
+	.4byte	.LASF11
+	.byte	0x3
+	.byte	0x9
+	.4byte	0xaf
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x0
+	.byte	0x0
+	.uleb128 0x9
+	.4byte	0x48
+	.uleb128 0x5
+	.4byte	.LASF10
+	.byte	0x3
+	.byte	0xa
+	.4byte	0x98
+	.uleb128 0xa
+	.4byte	.LASF18
+	.byte	0x4
+	.byte	0x4
+	.byte	0x9
+	.4byte	0xda
+	.uleb128 0x8
+	.4byte	.LASF12
+	.byte	0x4
+	.byte	0xa
+	.4byte	0x41
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x0
+	.byte	0x0
+	.uleb128 0xb
+	.4byte	.LASF55
+	.byte	0x0
+	.byte	0x4
+	.byte	0x67
+	.uleb128 0x7
+	.byte	0xc
+	.byte	0x4
+	.byte	0x74
+	.4byte	0x137
+	.uleb128 0xc
+	.ascii	"raw\000"
+	.byte	0x4
+	.byte	0x75
+	.4byte	0xb4
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x0
+	.uleb128 0xd
+	.4byte	.LASF13
+	.byte	0x4
+	.byte	0x76
+	.4byte	0x67
+	.byte	0x2
+	.byte	0xc
+	.byte	0x4
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x4
+	.uleb128 0xd
+	.4byte	.LASF14
+	.byte	0x4
+	.byte	0x77
+	.4byte	0x67
+	.byte	0x2
+	.byte	0x4
+	.byte	0x0
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x4
+	.uleb128 0x8
+	.4byte	.LASF15
+	.byte	0x4
+	.byte	0x78
+	.4byte	0xbf
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x8
+	.uleb128 0x8
+	.4byte	.LASF16
+	.byte	0x4
+	.byte	0x79
+	.4byte	0xda
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0xc
+	.byte	0x0
+	.uleb128 0x5
+	.4byte	.LASF17
+	.byte	0x4
+	.byte	0x7a
+	.4byte	0xe2
+	.uleb128 0xa
+	.4byte	.LASF19
+	.byte	0x4
+	.byte	0x5
+	.byte	0x52
+	.4byte	0x15d
+	.uleb128 0x8
+	.4byte	.LASF20
+	.byte	0x5
+	.byte	0x52
+	.4byte	0x15d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x0
+	.byte	0x0
+	.uleb128 0xe
+	.4byte	0x7d
+	.4byte	0x16d
+	.uleb128 0xf
+	.4byte	0x16d
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x10
+	.byte	0x4
+	.byte	0x7
+	.uleb128 0x5
+	.4byte	.LASF21
+	.byte	0x5
+	.byte	0x52
+	.4byte	0x142
+	.uleb128 0xa
+	.4byte	.LASF22
+	.byte	0x58
+	.byte	0x6
+	.byte	0x78
+	.4byte	0x2b1
+	.uleb128 0xc
+	.ascii	"r0\000"
+	.byte	0x7
+	.byte	0x4b
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x0
+	.uleb128 0xc
+	.ascii	"r1\000"
+	.byte	0x7
+	.byte	0x4c
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x4
+	.uleb128 0xc
+	.ascii	"r2\000"
+	.byte	0x7
+	.byte	0x4d
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x8
+	.uleb128 0xc
+	.ascii	"r3\000"
+	.byte	0x7
+	.byte	0x4e
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0xc
+	.uleb128 0xc
+	.ascii	"r4\000"
+	.byte	0x7
+	.byte	0x4f
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x10
+	.uleb128 0xc
+	.ascii	"r5\000"
+	.byte	0x7
+	.byte	0x50
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x14
+	.uleb128 0xc
+	.ascii	"r6\000"
+	.byte	0x7
+	.byte	0x51
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x18
+	.uleb128 0xc
+	.ascii	"r7\000"
+	.byte	0x7
+	.byte	0x52
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x1c
+	.uleb128 0xc
+	.ascii	"r8\000"
+	.byte	0x7
+	.byte	0x53
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x20
+	.uleb128 0xc
+	.ascii	"r9\000"
+	.byte	0x7
+	.byte	0x54
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x24
+	.uleb128 0xc
+	.ascii	"r10\000"
+	.byte	0x7
+	.byte	0x55
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x28
+	.uleb128 0xc
+	.ascii	"r11\000"
+	.byte	0x7
+	.byte	0x56
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x2c
+	.uleb128 0xc
+	.ascii	"r12\000"
+	.byte	0x7
+	.byte	0x57
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x30
+	.uleb128 0xc
+	.ascii	"r13\000"
+	.byte	0x7
+	.byte	0x58
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x34
+	.uleb128 0xc
+	.ascii	"r14\000"
+	.byte	0x7
+	.byte	0x59
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x38
+	.uleb128 0xc
+	.ascii	"r15\000"
+	.byte	0x7
+	.byte	0x5a
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x3c
+	.uleb128 0xc
+	.ascii	"psr\000"
+	.byte	0x7
+	.byte	0x5b
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x40
+	.uleb128 0xc
+	.ascii	"ctx\000"
+	.byte	0x7
+	.byte	0x5c
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x44
+	.uleb128 0x8
+	.4byte	.LASF23
+	.byte	0x7
+	.byte	0x5f
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x48
+	.uleb128 0xc
+	.ascii	"cr\000"
+	.byte	0x7
+	.byte	0x60
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x4c
+	.uleb128 0x8
+	.4byte	.LASF24
+	.byte	0x7
+	.byte	0x61
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x50
+	.uleb128 0x8
+	.4byte	.LASF25
+	.byte	0x7
+	.byte	0x62
+	.4byte	0x7d
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x54
+	.byte	0x0
+	.uleb128 0x11
+	.byte	0x4
+	.4byte	0x2b7
+	.uleb128 0x12
+	.4byte	0x8f
+	.uleb128 0x2
+	.byte	0x4
+	.byte	0x5
+	.4byte	.LASF26
+	.uleb128 0x5
+	.4byte	.LASF27
+	.byte	0x8
+	.byte	0x1f
+	.4byte	0x72
+	.uleb128 0xa
+	.4byte	.LASF28
+	.byte	0x8
+	.byte	0x9
+	.byte	0x1e
+	.4byte	0x2f7
+	.uleb128 0x8
+	.4byte	.LASF29
+	.byte	0x9
+	.byte	0x1f
+	.4byte	0x2f7
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x0
+	.uleb128 0x8
+	.4byte	.LASF30
+	.byte	0x9
+	.byte	0x1f
+	.4byte	0x2f7
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x4
+	.byte	0x0
+	.uleb128 0x11
+	.byte	0x4
+	.4byte	0x2ce
+	.uleb128 0xa
+	.4byte	.LASF31
+	.byte	0x10
+	.byte	0xa
+	.byte	0xc
+	.4byte	0x342
+	.uleb128 0x8
+	.4byte	.LASF32
+	.byte	0xa
+	.byte	0xd
+	.4byte	0x35e
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x0
+	.uleb128 0x8
+	.4byte	.LASF33
+	.byte	0xa
+	.byte	0xe
+	.4byte	0x2b1
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x4
+	.uleb128 0x8
+	.4byte	.LASF34
+	.byte	0xa
+	.byte	0xf
+	.4byte	0x96
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x8
+	.uleb128 0x8
+	.4byte	.LASF35
+	.byte	0xa
+	.byte	0x10
+	.4byte	0x84
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0xc
+	.byte	0x0
+	.uleb128 0x13
+	.byte	0x1
+	.4byte	0x358
+	.uleb128 0x14
+	.4byte	0x41
+	.uleb128 0x14
+	.4byte	0x96
+	.uleb128 0x14
+	.4byte	0x358
+	.byte	0x0
+	.uleb128 0x11
+	.byte	0x4
+	.4byte	0x17b
+	.uleb128 0x11
+	.byte	0x4
+	.4byte	0x342
+	.uleb128 0xa
+	.4byte	.LASF36
+	.byte	0x20
+	.byte	0xa
+	.byte	0x28
+	.4byte	0x3e1
+	.uleb128 0x8
+	.4byte	.LASF37
+	.byte	0xa
+	.byte	0x29
+	.4byte	0x2b1
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x0
+	.uleb128 0x8
+	.4byte	.LASF38
+	.byte	0xa
+	.byte	0x2a
+	.4byte	0x3f1
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x4
+	.uleb128 0x8
+	.4byte	.LASF39
+	.byte	0xa
+	.byte	0x2b
+	.4byte	0x403
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x8
+	.uleb128 0x8
+	.4byte	.LASF40
+	.byte	0xa
+	.byte	0x2c
+	.4byte	0x403
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0xc
+	.uleb128 0x8
+	.4byte	.LASF41
+	.byte	0xa
+	.byte	0x2d
+	.4byte	0x403
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x10
+	.uleb128 0xc
+	.ascii	"ack\000"
+	.byte	0xa
+	.byte	0x2e
+	.4byte	0x403
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x14
+	.uleb128 0xc
+	.ascii	"end\000"
+	.byte	0xa
+	.byte	0x2f
+	.4byte	0x403
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x18
+	.uleb128 0x8
+	.4byte	.LASF42
+	.byte	0xa
+	.byte	0x30
+	.4byte	0x41a
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x1c
+	.byte	0x0
+	.uleb128 0x15
+	.byte	0x1
+	.4byte	0x48
+	.4byte	0x3f1
+	.uleb128 0x14
+	.4byte	0x48
+	.byte	0x0
+	.uleb128 0x11
+	.byte	0x4
+	.4byte	0x3e1
+	.uleb128 0x13
+	.byte	0x1
+	.4byte	0x403
+	.uleb128 0x14
+	.4byte	0x48
+	.byte	0x0
+	.uleb128 0x11
+	.byte	0x4
+	.4byte	0x3f7
+	.uleb128 0x13
+	.byte	0x1
+	.4byte	0x41a
+	.uleb128 0x14
+	.4byte	0x48
+	.uleb128 0x14
+	.4byte	0x170
+	.byte	0x0
+	.uleb128 0x11
+	.byte	0x4
+	.4byte	0x409
+	.uleb128 0x16
+	.4byte	.LASF36
+	.4byte	0x364
+	.uleb128 0xa
+	.4byte	.LASF43
+	.byte	0x80
+	.byte	0xb
+	.byte	0x4
+	.4byte	0x4ec
+	.uleb128 0x8
+	.4byte	.LASF44
+	.byte	0xa
+	.byte	0x47
+	.4byte	0x48
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x0
+	.uleb128 0x8
+	.4byte	.LASF32
+	.byte	0xa
+	.byte	0x48
+	.4byte	0x4ec
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x4
+	.uleb128 0x8
+	.4byte	.LASF45
+	.byte	0xa
+	.byte	0x49
+	.4byte	0x4f8
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x8
+	.uleb128 0x8
+	.4byte	.LASF46
+	.byte	0xa
+	.byte	0x4a
+	.4byte	0x4fe
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0xc
+	.uleb128 0x8
+	.4byte	.LASF47
+	.byte	0xa
+	.byte	0x4b
+	.4byte	0x48
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x10
+	.uleb128 0x8
+	.4byte	.LASF48
+	.byte	0xa
+	.byte	0x4c
+	.4byte	0x50a
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x14
+	.uleb128 0xc
+	.ascii	"irq\000"
+	.byte	0xa
+	.byte	0x4d
+	.4byte	0x41
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x18
+	.uleb128 0x8
+	.4byte	.LASF11
+	.byte	0xa
+	.byte	0x4e
+	.4byte	0x137
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x1c
+	.uleb128 0x8
+	.4byte	.LASF49
+	.byte	0xa
+	.byte	0x4f
+	.4byte	0x170
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x28
+	.uleb128 0x8
+	.4byte	.LASF50
+	.byte	0xa
+	.byte	0x50
+	.4byte	0x170
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x2c
+	.uleb128 0x8
+	.4byte	.LASF51
+	.byte	0xa
+	.byte	0x53
+	.4byte	0x2c3
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x30
+	.uleb128 0x8
+	.4byte	.LASF52
+	.byte	0xa
+	.byte	0x54
+	.4byte	0x48
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x38
+	.uleb128 0x8
+	.4byte	.LASF53
+	.byte	0xa
+	.byte	0x55
+	.4byte	0x2ce
+	.byte	0x2
+	.byte	0x23
+	.uleb128 0x3c
+	.byte	0x0
+	.uleb128 0x11
+	.byte	0x4
+	.4byte	0x420
+	.uleb128 0x17
+	.4byte	.LASF45
+	.byte	0x1
+	.uleb128 0x11
+	.byte	0x4
+	.4byte	0x4f2
+	.uleb128 0x11
+	.byte	0x4
+	.4byte	0x2fd
+	.uleb128 0x17
+	.4byte	.LASF54
+	.byte	0x1
+	.uleb128 0x11
+	.byte	0x4
+	.4byte	0x504
+	.uleb128 0xb
+	.4byte	.LASF56
+	.byte	0x0
+	.byte	0xc
+	.byte	0x77
+	.uleb128 0x5
+	.4byte	.LASF57
+	.byte	0xc
+	.byte	0x78
+	.4byte	0x510
+	.uleb128 0x18
+	.byte	0x1
+	.ascii	"foo\000"
+	.byte	0x1
+	.byte	0x13
+	.byte	0x1
+	.4byte	.LFB182
+	.4byte	.LFE182
+	.4byte	.LLST0
+	.uleb128 0xe
+	.4byte	0x7d
+	.4byte	0x54e
+	.uleb128 0xf
+	.4byte	0x16d
+	.byte	0x20
+	.uleb128 0xf
+	.4byte	0x16d
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x19
+	.4byte	.LASF58
+	.byte	0x5
+	.2byte	0x116
+	.4byte	0x55c
+	.byte	0x1
+	.byte	0x1
+	.uleb128 0x12
+	.4byte	0x538
+	.uleb128 0x19
+	.4byte	.LASF59
+	.byte	0x5
+	.2byte	0x1c4
+	.4byte	0x170
+	.byte	0x1
+	.byte	0x1
+	.uleb128 0x1a
+	.4byte	.LASF43
+	.byte	0xb
+	.byte	0x5
+	.4byte	0x57c
+	.byte	0x1
+	.byte	0x1
+	.uleb128 0x11
+	.byte	0x4
+	.4byte	0x429
+	.uleb128 0x1a
+	.4byte	.LASF60
+	.byte	0xd
+	.byte	0x11
+	.4byte	0x48
+	.byte	0x1
+	.byte	0x1
+	.uleb128 0x1a
+	.4byte	.LASF61
+	.byte	0xe
+	.byte	0xf
+	.4byte	0x41
+	.byte	0x1
+	.byte	0x1
+	.uleb128 0x1a
+	.4byte	.LASF62
+	.byte	0xe
+	.byte	0x11
+	.4byte	0x5a9
+	.byte	0x1
+	.byte	0x1
+	.uleb128 0x11
+	.byte	0x4
+	.4byte	0x5d
+	.uleb128 0x19
+	.4byte	.LASF63
+	.byte	0xf
+	.2byte	0x169
+	.4byte	0x518
+	.byte	0x1
+	.byte	0x1
+	.byte	0x0
+	.section	.debug_abbrev
+	.uleb128 0x1
+	.uleb128 0x11
+	.byte	0x1
+	.uleb128 0x25
+	.uleb128 0xe
+	.uleb128 0x13
+	.uleb128 0xb
+	.uleb128 0x3
+	.uleb128 0xe
+	.uleb128 0x1b
+	.uleb128 0xe
+	.uleb128 0x11
+	.uleb128 0x1
+	.uleb128 0x12
+	.uleb128 0x1
+	.uleb128 0x10
+	.uleb128 0x6
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x2
+	.uleb128 0x24
+	.byte	0x0
+	.uleb128 0xb
+	.uleb128 0xb
+	.uleb128 0x3e
+	.uleb128 0xb
+	.uleb128 0x3
+	.uleb128 0xe
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x3
+	.uleb128 0x24
+	.byte	0x0
+	.uleb128 0xb
+	.uleb128 0xb
+	.uleb128 0x3e
+	.uleb128 0xb
+	.uleb128 0x3
+	.uleb128 0x8
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x4
+	.uleb128 0x16
+	.byte	0x0
+	.uleb128 0x3
+	.uleb128 0x8
+	.uleb128 0x3a
+	.uleb128 0xb
+	.uleb128 0x3b
+	.uleb128 0xb
+	.uleb128 0x49
+	.uleb128 0x13
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x5
+	.uleb128 0x16
+	.byte	0x0
+	.uleb128 0x3
+	.uleb128 0xe
+	.uleb128 0x3a
+	.uleb128 0xb
+	.uleb128 0x3b
+	.uleb128 0xb
+	.uleb128 0x49
+	.uleb128 0x13
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x6
+	.uleb128 0xf
+	.byte	0x0
+	.uleb128 0xb
+	.uleb128 0xb
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x7
+	.uleb128 0x13
+	.byte	0x1
+	.uleb128 0xb
+	.uleb128 0xb
+	.uleb128 0x3a
+	.uleb128 0xb
+	.uleb128 0x3b
+	.uleb128 0xb
+	.uleb128 0x1
+	.uleb128 0x13
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x8
+	.uleb128 0xd
+	.byte	0x0
+	.uleb128 0x3
+	.uleb128 0xe
+	.uleb128 0x3a
+	.uleb128 0xb
+	.uleb128 0x3b
+	.uleb128 0xb
+	.uleb128 0x49
+	.uleb128 0x13
+	.uleb128 0x38
+	.uleb128 0xa
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x9
+	.uleb128 0x35
+	.byte	0x0
+	.uleb128 0x49
+	.uleb128 0x13
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0xa
+	.uleb128 0x13
+	.byte	0x1
+	.uleb128 0x3
+	.uleb128 0xe
+	.uleb128 0xb
+	.uleb128 0xb
+	.uleb128 0x3a
+	.uleb128 0xb
+	.uleb128 0x3b
+	.uleb128 0xb
+	.uleb128 0x1
+	.uleb128 0x13
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0xb
+	.uleb128 0x13
+	.byte	0x0
+	.uleb128 0x3
+	.uleb128 0xe
+	.uleb128 0xb
+	.uleb128 0xb
+	.uleb128 0x3a
+	.uleb128 0xb
+	.uleb128 0x3b
+	.uleb128 0xb
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0xc
+	.uleb128 0xd
+	.byte	0x0
+	.uleb128 0x3
+	.uleb128 0x8
+	.uleb128 0x3a
+	.uleb128 0xb
+	.uleb128 0x3b
+	.uleb128 0xb
+	.uleb128 0x49
+	.uleb128 0x13
+	.uleb128 0x38
+	.uleb128 0xa
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0xd
+	.uleb128 0xd
+	.byte	0x0
+	.uleb128 0x3
+	.uleb128 0xe
+	.uleb128 0x3a
+	.uleb128 0xb
+	.uleb128 0x3b
+	.uleb128 0xb
+	.uleb128 0x49
+	.uleb128 0x13
+	.uleb128 0xb
+	.uleb128 0xb
+	.uleb128 0xd
+	.uleb128 0xb
+	.uleb128 0xc
+	.uleb128 0xb
+	.uleb128 0x38
+	.uleb128 0xa
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0xe
+	.uleb128 0x1
+	.byte	0x1
+	.uleb128 0x49
+	.uleb128 0x13
+	.uleb128 0x1
+	.uleb128 0x13
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0xf
+	.uleb128 0x21
+	.byte	0x0
+	.uleb128 0x49
+	.uleb128 0x13
+	.uleb128 0x2f
+	.uleb128 0xb
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x10
+	.uleb128 0x24
+	.byte	0x0
+	.uleb128 0xb
+	.uleb128 0xb
+	.uleb128 0x3e
+	.uleb128 0xb
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x11
+	.uleb128 0xf
+	.byte	0x0
+	.uleb128 0xb
+	.uleb128 0xb
+	.uleb128 0x49
+	.uleb128 0x13
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x12
+	.uleb128 0x26
+	.byte	0x0
+	.uleb128 0x49
+	.uleb128 0x13
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x13
+	.uleb128 0x15
+	.byte	0x1
+	.uleb128 0x27
+	.uleb128 0xc
+	.uleb128 0x1
+	.uleb128 0x13
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x14
+	.uleb128 0x5
+	.byte	0x0
+	.uleb128 0x49
+	.uleb128 0x13
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x15
+	.uleb128 0x15
+	.byte	0x1
+	.uleb128 0x27
+	.uleb128 0xc
+	.uleb128 0x49
+	.uleb128 0x13
+	.uleb128 0x1
+	.uleb128 0x13
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x16
+	.uleb128 0x26
+	.byte	0x0
+	.uleb128 0x3
+	.uleb128 0xe
+	.uleb128 0x49
+	.uleb128 0x13
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x17
+	.uleb128 0x13
+	.byte	0x0
+	.uleb128 0x3
+	.uleb128 0xe
+	.uleb128 0x3c
+	.uleb128 0xc
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x18
+	.uleb128 0x2e
+	.byte	0x0
+	.uleb128 0x3f
+	.uleb128 0xc
+	.uleb128 0x3
+	.uleb128 0x8
+	.uleb128 0x3a
+	.uleb128 0xb
+	.uleb128 0x3b
+	.uleb128 0xb
+	.uleb128 0x27
+	.uleb128 0xc
+	.uleb128 0x11
+	.uleb128 0x1
+	.uleb128 0x12
+	.uleb128 0x1
+	.uleb128 0x40
+	.uleb128 0x6
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x19
+	.uleb128 0x34
+	.byte	0x0
+	.uleb128 0x3
+	.uleb128 0xe
+	.uleb128 0x3a
+	.uleb128 0xb
+	.uleb128 0x3b
+	.uleb128 0x5
+	.uleb128 0x49
+	.uleb128 0x13
+	.uleb128 0x3f
+	.uleb128 0xc
+	.uleb128 0x3c
+	.uleb128 0xc
+	.byte	0x0
+	.byte	0x0
+	.uleb128 0x1a
+	.uleb128 0x34
+	.byte	0x0
+	.uleb128 0x3
+	.uleb128 0xe
+	.uleb128 0x3a
+	.uleb128 0xb
+	.uleb128 0x3b
+	.uleb128 0xb
+	.uleb128 0x49
+	.uleb128 0x13
+	.uleb128 0x3f
+	.uleb128 0xc
+	.uleb128 0x3c
+	.uleb128 0xc
+	.byte	0x0
+	.byte	0x0
+	.byte	0x0
+	.section	.debug_pubnames,"",%progbits
+	.4byte	0x16
+	.2byte	0x2
+	.4byte	.Ldebug_info0
+	.4byte	0x5be
+	.4byte	0x523
+	.ascii	"foo\000"
+	.4byte	0x0
+	.section	.debug_aranges,"",%progbits
+	.4byte	0x1c
+	.2byte	0x2
+	.4byte	.Ldebug_info0
+	.byte	0x4
+	.byte	0x0
+	.2byte	0x0
+	.2byte	0x0
+	.4byte	.Ltext0
+	.4byte	.Letext0-.Ltext0
+	.4byte	0x0
+	.4byte	0x0
+	.section	.debug_str,"MS",%progbits,1
+.LASF28:
+	.ascii	"list_head\000"
+.LASF34:
+	.ascii	"dev_id\000"
+.LASF18:
+	.ascii	"lock_debug\000"
+.LASF29:
+	.ascii	"next\000"
+.LASF30:
+	.ascii	"prev\000"
+.LASF2:
+	.ascii	"short int\000"
+.LASF63:
+	.ascii	"domlist_read_lock\000"
+.LASF36:
+	.ascii	"hw_interrupt_type\000"
+.LASF6:
+	.ascii	"long long unsigned int\000"
+.LASF50:
+	.ascii	"pending_mask\000"
+.LASF27:
+	.ascii	"s_time_t\000"
+.LASF35:
+	.ascii	"free_on_release\000"
+.LASF32:
+	.ascii	"handler\000"
+.LASF40:
+	.ascii	"enable\000"
+.LASF24:
+	.ascii	"dacr\000"
+.LASF39:
+	.ascii	"shutdown\000"
+.LASF8:
+	.ascii	"bool_t\000"
+.LASF5:
+	.ascii	"long long int\000"
+.LASF10:
+	.ascii	"raw_spinlock_t\000"
+.LASF20:
+	.ascii	"bits\000"
+.LASF46:
+	.ascii	"action\000"
+.LASF12:
+	.ascii	"irq_safe\000"
+.LASF26:
+	.ascii	"long int\000"
+.LASF55:
+	.ascii	"lock_profile\000"
+.LASF48:
+	.ascii	"chip_data\000"
+.LASF14:
+	.ascii	"recurse_cnt\000"
+.LASF33:
+	.ascii	"name\000"
+.LASF45:
+	.ascii	"msi_desc\000"
+.LASF56:
+	.ascii	"_rcu_read_lock\000"
+.LASF43:
+	.ascii	"irq_desc\000"
+.LASF1:
+	.ascii	"unsigned char\000"
+.LASF59:
+	.ascii	"cpu_online_map\000"
+.LASF0:
+	.ascii	"signed char\000"
+.LASF21:
+	.ascii	"cpumask_t\000"
+.LASF53:
+	.ascii	"rl_link\000"
+.LASF15:
+	.ascii	"debug\000"
+.LASF22:
+	.ascii	"cpu_user_regs\000"
+.LASF3:
+	.ascii	"short unsigned int\000"
+.LASF44:
+	.ascii	"status\000"
+.LASF37:
+	.ascii	"typename\000"
+.LASF54:
+	.ascii	"irq_cfg\000"
+.LASF19:
+	.ascii	"cpumask\000"
+.LASF9:
+	.ascii	"char\000"
+.LASF11:
+	.ascii	"lock\000"
+.LASF17:
+	.ascii	"spinlock_t\000"
+.LASF65:
+	.ascii	"asm-offsets.c\000"
+.LASF25:
+	.ascii	"pidr\000"
+.LASF61:
+	.ascii	"memnode_shift\000"
+.LASF47:
+	.ascii	"depth\000"
+.LASF23:
+	.ascii	"cpar\000"
+.LASF7:
+	.ascii	"long unsigned int\000"
+.LASF49:
+	.ascii	"affinity\000"
+.LASF58:
+	.ascii	"cpu_bit_bitmap\000"
+.LASF42:
+	.ascii	"set_affinity\000"
+.LASF57:
+	.ascii	"rcu_read_lock_t\000"
+.LASF52:
+	.ascii	"rl_cnt\000"
+.LASF31:
+	.ascii	"irqaction\000"
+.LASF64:
+	.ascii	"GNU C 4.4.3\000"
+.LASF38:
+	.ascii	"startup\000"
+.LASF60:
+	.ascii	"per_cpu____preempt_count\000"
+.LASF4:
+	.ascii	"unsigned int\000"
+.LASF16:
+	.ascii	"profile\000"
+.LASF51:
+	.ascii	"rl_quantum_start\000"
+.LASF41:
+	.ascii	"disable\000"
+.LASF66:
+	.ascii	"/home/fjnh84/src/xen-unstable.hg/xen/arch/arm\000"
+.LASF13:
+	.ascii	"recurse_cpu\000"
+.LASF62:
+	.ascii	"memnodemap\000"
+	.ident	"GCC: (GNU) 4.4.3"
+	.section	.note.GNU-stack,"",%progbits
diff --git a/xen/arch/arm/tegra/Makefile b/xen/arch/arm/tegra/Makefile
new file mode 100644
--- /dev/null
+++ b/xen/arch/arm/tegra/Makefile
@@ -0,0 +1,1 @@
+obj-y += dummy.o
\ No newline at end of file
diff --git a/xen/arch/arm/tegra/dummy.c b/xen/arch/arm/tegra/dummy.c
new file mode 100644
diff --git a/xen/arch/arm/xen.lds.S b/xen/arch/arm/xen.lds.S
new file mode 100644
--- /dev/null
+++ b/xen/arch/arm/xen.lds.S
@@ -0,0 +1,133 @@
+#include <xen/config.h>
+#include <xen/cache.h>
+#include <asm/page.h>
+#include <asm/percpu.h>
+#undef ENTRY
+#undef ALIGN
+
+OUTPUT_FORMAT("elf32-littlearm")
+OUTPUT_ARCH(arm)
+
+ENTRY(start)
+PHDRS
+{
+  text PT_LOAD ;
+}
+SECTIONS
+{
+  . = HYPERVISOR_VIRT_START;
+  _start = .;
+  .text : {
+        _stext = .;            /* Text and read-only data */
+       *(.text)
+       *(.fixup)
+       *(.gnu.warning)
+       _etext = .;             /* End of text section */
+  } :text = 0x9090
+
+  .rodata : {
+       *(.rodata)
+       *(.rodata.*)
+  } :text
+
+  . = ALIGN(SMP_CACHE_BYTES);
+  .data.read_mostly : {
+       /* Exception table */
+       __start___ex_table = .;
+       *(.ex_table)
+       __stop___ex_table = .;
+
+       /* Pre-exception table */
+       __start___pre_ex_table = .;
+       *(.ex_table.pre)
+       __stop___pre_ex_table = .;
+
+       *(.data.read_mostly)
+       *(.data.rel.ro)
+       *(.data.rel.ro.*)
+  } :text
+
+  .data : {                    /* Data */
+       . = ALIGN(PAGE_SIZE);
+       *(.data.page_aligned)
+       *(.data)
+       *(.data.rel)
+       *(.data.rel.*)
+       CONSTRUCTORS
+  } :text
+
+#ifdef LOCK_PROFILE
+  . = ALIGN(32);
+  __lock_profile_start = .;
+  .lockprofile.data : { *(.lockprofile.data) } :text
+  __lock_profile_end = .;
+#endif
+
+  . = ALIGN(PAGE_SIZE);             /* Init code and data */
+  __init_begin = .;
+  .init.text : {
+       _sinittext = .;
+       *(.init.text)
+       _einittext = .;
+  } :text
+  .init.data : {
+       *(.init.rodata)
+       *(.init.rodata.str*)
+       *(.init.data)
+       *(.init.data.rel)
+       *(.init.data.rel.*)
+  } :text
+  . = ALIGN(32);
+  .init.setup : {
+       __setup_start = .;
+       *(.init.setup)
+       __setup_end = .;
+  } :text
+  .initcall.init : {
+       __initcall_start = .;
+       *(.initcallpresmp.init)
+       __presmp_initcall_end = .;
+       *(.initcall1.init)
+       __initcall_end = .;
+  } :text
+  .xsm_initcall.init : {
+       __xsm_initcall_start = .;
+       *(.xsm_initcall.init)
+       __xsm_initcall_end = .;
+  } :text
+  . = ALIGN(STACK_SIZE);
+  __init_end = .;
+
+  .bss : {                     /* BSS */
+       __bss_start = .;
+       *(.bss.stack_aligned)
+       . = ALIGN(PAGE_SIZE);
+       *(.bss.page_aligned)
+       *(.bss)
+       . = ALIGN(SMP_CACHE_BYTES);
+       __per_cpu_start = .;
+       *(.bss.percpu)
+       . = ALIGN(SMP_CACHE_BYTES);
+       *(.bss.percpu.read_mostly)
+       . = ALIGN(SMP_CACHE_BYTES);
+       __per_cpu_data_end = .;
+  } :text
+  _end = . ;
+
+  /* Sections to be discarded */
+  /DISCARD/ : {
+       *(.exit.text)
+       *(.exit.data)
+       *(.exitcall.exit)
+       *(.eh_frame)
+  }
+
+  /* Stabs debugging sections.  */
+  .stab 0 : { *(.stab) }
+  .stabstr 0 : { *(.stabstr) }
+  .stab.excl 0 : { *(.stab.excl) }
+  .stab.exclstr 0 : { *(.stab.exclstr) }
+  .stab.index 0 : { *(.stab.index) }
+  .stab.indexstr 0 : { *(.stab.indexstr) }
+  .comment 0 : { *(.comment) }
+}
diff --git a/xen/common/kexec.c b/xen/common/kexec.c
--- a/xen/common/kexec.c
+++ b/xen/common/kexec.c
@@ -465,7 +465,7 @@
     VMCOREINFO_STRUCT_SIZE(domain);
 
     VMCOREINFO_OFFSET(page_info, count_info);
-#ifdef __ia64__
+#if defined(__ia64__) || defined(__arm__)
     VMCOREINFO_OFFSET_SUB(page_info, u.inuse, _domain);
 #else
     VMCOREINFO_OFFSET_SUB(page_info, v.inuse, _domain);
diff --git a/xen/common/timer.c b/xen/common/timer.c
--- a/xen/common/timer.c
+++ b/xen/common/timer.c
@@ -239,7 +239,7 @@
 
     for ( ; ; )
     {
-        cpu = atomic_read16(&timer->cpu);
+        cpu = atomic_read32(&timer->cpu);
         if ( unlikely(cpu == TIMER_CPU_status_killed) )
         {
             rcu_read_unlock(&timer_cpu_read_lock);
@@ -292,7 +292,7 @@
     memset(timer, 0, sizeof(*timer));
     timer->function = function;
     timer->data = data;
-    atomic_write16(&timer->cpu, cpu);
+    atomic_write32(&timer->cpu, cpu);
     timer->status = TIMER_STATUS_inactive;
     if ( !timer_lock_irqsave(timer, flags) )
         BUG();
@@ -343,7 +343,7 @@
 
     for ( ; ; )
     {
-        old_cpu = atomic_read16(&timer->cpu);
+        old_cpu = atomic_read32(&timer->cpu);
         if ( (old_cpu == new_cpu) || (old_cpu == TIMER_CPU_status_killed) )
         {
             rcu_read_unlock(&timer_cpu_read_lock);
@@ -375,7 +375,7 @@
         deactivate_timer(timer);
 
     list_del(&timer->inactive);
-    atomic_write16(&timer->cpu, new_cpu);
+    atomic_write32(&timer->cpu, new_cpu);
     list_add(&timer->inactive, &per_cpu(timers, new_cpu).inactive);
 
     if ( active )
@@ -402,7 +402,7 @@
     list_del(&timer->inactive);
     timer->status = TIMER_STATUS_killed;
     old_cpu = timer->cpu;
-    atomic_write16(&timer->cpu, TIMER_CPU_status_killed);
+    atomic_write32(&timer->cpu, TIMER_CPU_status_killed);
 
     spin_unlock_irqrestore(&per_cpu(timers, old_cpu).lock, flags);
 
@@ -573,7 +573,7 @@
              ? old_ts->heap[1] : old_ts->list) != NULL )
     {
         remove_entry(t);
-        atomic_write16(&t->cpu, new_cpu);
+        atomic_write32(&t->cpu, new_cpu);
         notify |= add_entry(t);
     }
 
@@ -581,7 +581,7 @@
     {
         t = list_entry(old_ts->inactive.next, struct timer, inactive);
         list_del(&t->inactive);
-        atomic_write16(&t->cpu, new_cpu);
+        atomic_write32(&t->cpu, new_cpu);
         list_add(&t->inactive, &new_ts->inactive);
     }
 
diff --git a/xen/common/tmem.c b/xen/common/tmem.c
--- a/xen/common/tmem.c
+++ b/xen/common/tmem.c
@@ -49,7 +49,7 @@
 #define INVERT_SENTINEL(_x,_y) _x->sentinel = ~_y##_SENTINEL
 #define ASSERT_SENTINEL(_x,_y) \
     ASSERT(_x->sentinel != ~_y##_SENTINEL);ASSERT(_x->sentinel == _y##_SENTINEL)
-#ifdef __i386__
+#if defined (__i386__) || defined (__arm__)
 #define POOL_SENTINEL 0x87658765
 #define OBJ_SENTINEL 0x12345678
 #define OBJNODE_SENTINEL 0xfedcba09
diff --git a/xen/common/tmem_xen.c b/xen/common/tmem_xen.c
--- a/xen/common/tmem_xen.c
+++ b/xen/common/tmem_xen.c
@@ -87,7 +87,7 @@
 #endif
 }
 
-#ifdef __ia64__
+#if defined (__ia64__) || defined (__arm__)
 static inline void *cli_get_page(tmem_cli_mfn_t cmfn, unsigned long *pcli_mfn,
                                  pfp_t **pcli_pfp, bool_t cli_write)
 {
diff --git a/xen/drivers/Makefile b/xen/drivers/Makefile
--- a/xen/drivers/Makefile
+++ b/xen/drivers/Makefile
@@ -1,6 +1,6 @@
 subdir-y += char
 subdir-y += cpufreq
 subdir-y += pci
-subdir-y += passthrough
+subdir-$(HASS_PASSTHROUGH) += passthrough
 subdir-$(HAS_ACPI) += acpi
 subdir-$(HAS_VGA) += video
diff --git a/xen/include/asm-arm/.offsets.h.stamp b/xen/include/asm-arm/.offsets.h.stamp
new file mode 100644
diff --git a/xen/include/asm-arm/acpi.h b/xen/include/asm-arm/acpi.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/acpi.h
@@ -0,0 +1,11 @@
+#ifndef _ASM_ARM_ACPI_H
+#define _ASM_ARM_ACPI_H
+
+#include <xen/config.h>
+
+typedef long long COMPILER_DEPENDENT_INT64;
+typedef unsigned long long COMPILER_DEPENDENT_UINT64;
+
+#define acpi_disabled (1)
+
+#endif /*__ARM_ASM_ACPI_H*/
diff --git a/xen/include/asm-arm/asm-macros.h b/xen/include/asm-arm/asm-macros.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/asm-macros.h
@@ -0,0 +1,151 @@
+#ifndef __ASM_ARM_ASM_MACROS_H
+#define __ASM_ARM_ASM_MACROS_H
+
+#include <asm/plat/config.h>
+#include <asm/system.h>
+
+#define __asmeq(x, y)  ".ifnc " x "," y " ; .err ; .endif\n\t"
+
+#ifdef __ASSEMBLY__
+
+/*
+ * Endian independent macros for shifting bytes within registers.
+ */
+#ifndef __ARMEB__
+#define pull            lsr
+#define push            lsl
+#define get_byte_0      lsl #0
+#define get_byte_1      lsr #8
+#define get_byte_2      lsr #16
+#define get_byte_3      lsr #24
+#define put_byte_0      lsl #0
+#define put_byte_1      lsl #8
+#define put_byte_2      lsl #16
+#define put_byte_3      lsl #24
+#else
+#define pull            lsl
+#define push            lsr
+#define get_byte_0      lsr #24
+#define get_byte_1      lsr #16
+#define get_byte_2      lsr #8
+#define get_byte_3      lsl #0
+#define put_byte_0      lsl #24
+#define put_byte_1      lsl #16
+#define put_byte_2      lsl #8
+#define put_byte_3      lsl #0
+#endif
+
+/*
+ * Data preload for architectures that support it
+ */
+#define PLD(code...)	code
+
+/*
+ * LOADREGS - ldm with PC in register list (eg, ldmfd sp!, {pc})
+ */
+#ifdef __STDC__
+#define LOADREGS(cond, base, reglist...)\
+        ldm##cond       base,reglist
+#else
+#define LOADREGS(cond, base, reglist...)\
+        ldm/**/cond     base,reglist
+#endif
+
+/*
+ * Build a return instruction for this processor type.
+ */
+#define RETINSTR(instr, regs...)\
+        instr   regs
+
+#define CTXT_R0			0
+#define CTXT_R1			4
+#define CTXT_R2			8
+#define CTXT_R3			12
+#define CTXT_R4			16
+#define CTXT_R5			20
+#define CTXT_R6			24
+#define CTXT_R7			28
+#define CTXT_R8			32
+#define CTXT_R9			36
+#define CTXT_R10		40
+#define CTXT_R11		44
+#define CTXT_R12		48
+#define CTXT_USP		52
+#define CTXT_ULR		56
+#define CTXT_SSP		60
+#define CTXT_SLR		64
+#define CTXT_PC			68
+#define CTXT_SPSR		72
+#define CTXT_EXTRA		76
+#define CTXT_FRAME_SIZE	80
+
+#ifdef CONFIG_EABI_SUPPORT
+#define SPFIX(code...)	code
+#else
+#define SPFIX(code...)
+#endif
+
+.macro	SWITCH_MODE mode, flags
+	msr cpsr_c, #(\mode | \flags)
+.endm
+
+.macro	DISABLE_INTERRUPTS
+	msr cpsr_c, #(PSR_I_BIT | PSR_MODE_SVC)
+.endm
+
+.macro	ENABLE_INTERRUPTS
+	msr cpsr_c, #PSR_MODE_SVC
+.endm
+
+.macro  disable_irq, temp
+	msr cpsr_c, #PSR_I_BIT | PSR_MODE_SVC
+.endm
+
+.macro  enable_irq, temp
+	msr cpsr_c, #PSR_MODE_SVC
+.endm 
+
+.macro	cci		rd
+	mov		\rd, #STACK_SIZE
+	sub		\rd, \rd, #1
+	bic		\rd, r13, \rd
+.endm
+
+/*
+ * Save the current IRQ state and disable IRQs.  Note that this macro
+ * assumes FIQs are enabled, and that the processor is in SVC mode.
+ */
+.macro	save_and_disable_irqs, oldcpsr, temp
+	mrs	\oldcpsr, cpsr
+	mov	\temp, #PSR_I_BIT | PSR_MODE_SVC
+	msr	cpsr_c, \temp
+.endm
+
+/*
+ * Restore interrupt state previously stored in a register.  We don't
+ * guarantee that this will preserve the flags.
+ */
+.macro	restore_irqs, oldcpsr
+	msr	cpsr_c, \oldcpsr
+.endm
+
+.macro  cpwait, rd
+	mrc     p15, 0, \rd, c2, c0, 0          @ arbitrary read of cp15
+	mov     \rd, \rd                        @ wait for completion
+	sub     pc, pc, #4                      @ flush instruction pipeline
+.endm
+
+.macro  cpwait_ret, lr, rd
+	mrc     p15, 0, \rd, c2, c0, 0          @ arbitrary read of cp15
+	sub     pc, \lr, \rd, LSR #32           @ wait for completion and
+.endm
+
+#define USER(x...)				\
+9999:	x;					\
+	.section .extable,"a";		\
+	.align	3;				\
+	.long	9999b,9001f;			\
+	.previous
+
+#endif
+#endif
diff --git a/xen/include/asm-arm/atomic.h b/xen/include/asm-arm/atomic.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/atomic.h
@@ -0,0 +1,93 @@
+#ifndef __ARM_ATOMIC__
+#define __ARM_ATOMIC__
+
+#include <xen/config.h>
+#include <asm/system.h>
+
+typedef struct {
+	volatile int counter;
+} atomic_t;
+
+
+#define ATOMIC_INIT(i)	{ (i) }
+
+#define atomic_read(v)		((v)->counter)
+#define atomic_set(v,i)		(((v)->counter) = (i))
+
+#define _atomic_read(v)		atomic_read(&v)
+#define _atomic_set(v,i)	atomic_set(&v,i)
+
+#define atomic_read32(v) atomic_read ((atomic_t *) v)
+#define atomic_write32(v,i) atomic_set ((atomic_t *)v, i)
+
+static inline int atomic_add_return(int i, atomic_t *v)
+{
+	unsigned long flags;
+	int val;
+
+	local_irq_save(flags);
+	val = v->counter;
+	v->counter = val += i;
+	local_irq_restore(flags);
+
+	return val;
+}
+
+static inline int atomic_sub_return(int i, atomic_t *v)
+{
+	unsigned long flags;
+	int val;
+
+	local_irq_save(flags);
+	val = v->counter;
+	v->counter = val -= i;
+	local_irq_restore(flags);
+
+	return val;
+}
+
+static inline void atomic_clear_mask(unsigned long mask, unsigned long *addr)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+	*addr &= ~mask;
+	local_irq_restore(flags);
+}
+
+
+static inline atomic_t atomic_cmpxchg(atomic_t *v, atomic_t old, atomic_t new)
+{
+        atomic_t ret; // by PCJ
+        unsigned long flags;
+
+        local_irq_save(flags);
+        ret.counter  = v->counter;
+        if (likely(ret.counter == old.counter))
+                v->counter = new.counter;
+        local_irq_restore(flags);
+
+        return ret;
+}
+
+static inline atomic_t atomic_compareandswap(
+        atomic_t old, atomic_t new, atomic_t *v)
+{
+        atomic_t rc;
+        rc = atomic_cmpxchg( (atomic_t *)v, old, new);  // by PCJ
+        return rc;
+}
+
+#define atomic_add(i, v)	(void) atomic_add_return(i, v)
+#define atomic_inc(v)		(void) atomic_add_return(1, v)
+#define atomic_sub(i, v)	(void) atomic_sub_return(i, v)
+#define atomic_dec(v)		(void) atomic_sub_return(1, v)
+
+#define atomic_inc_and_test(v)	(atomic_add_return(1, v) == 0)
+#define atomic_dec_and_test(v)	(atomic_sub_return(1, v) == 0)
+#define atomic_inc_return(v)    (atomic_add_return(1, v))
+#define atomic_dec_return(v)    (atomic_sub_return(1, v))
+
+#define atomic_add_negative(i,v) (atomic_add_return(i, v) < 0)
+
+#endif /* __ARM_ATOMIC__ */
diff --git a/xen/include/asm-arm/bitops.h b/xen/include/asm-arm/bitops.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/bitops.h
@@ -0,0 +1,291 @@
+#ifndef __ARM_BITOPS_H
+#define __ARM_BITOPS_H
+
+/*
+ * Copyright 1992, Linus Torvalds.
+ * Copyright 1995, Russell King.
+ * Copyright 2001, Nicolas Pitre.
+ */
+
+#include <asm/system.h>
+
+/*
+ * These functions are the basis of our bit ops.
+ *
+ * First, the atomic bitops. These use native endian.
+ */
+static inline void ____atomic_set_bit(unsigned int bit, volatile unsigned long *p)
+{
+	unsigned long flags;
+	unsigned long mask = 1UL << (bit & 31);
+
+	p += bit >> 5;
+
+	local_irq_save(flags);
+	*p |= mask;
+	local_irq_restore(flags);
+}
+
+static inline void ____atomic_clear_bit(unsigned int bit, volatile unsigned long *p)
+{
+	unsigned long flags;
+	unsigned long mask = 1UL << (bit & 31);
+
+	p += bit >> 5;
+
+	local_irq_save(flags);
+	*p &= ~mask;
+	local_irq_restore(flags);
+}
+
+static inline void ____atomic_change_bit(unsigned int bit, volatile unsigned long *p)
+{
+	unsigned long flags;
+	unsigned long mask = 1UL << (bit & 31);
+
+	p += bit >> 5;
+
+	local_irq_save(flags);
+	*p ^= mask;
+	local_irq_restore(flags);
+}
+
+static inline int
+____atomic_test_and_set_bit(unsigned int bit, volatile unsigned long *p)
+{
+	unsigned long flags;
+	unsigned int res;
+	unsigned long mask = 1UL << (bit & 31);
+
+	p += bit >> 5;
+
+	local_irq_save(flags);
+	res = *p;
+	*p = res | mask;
+	local_irq_restore(flags);
+
+	return res & mask;
+}
+
+static inline int
+____atomic_test_and_clear_bit(unsigned int bit, volatile unsigned long *p)
+{
+	unsigned long flags;
+	unsigned int res;
+	unsigned long mask = 1UL << (bit & 31);
+
+	p += bit >> 5;
+
+	local_irq_save(flags);
+	res = *p;
+	*p = res & ~mask;
+	local_irq_restore(flags);
+
+	return res & mask;
+}
+
+static inline int
+____atomic_test_and_change_bit(unsigned int bit, volatile unsigned long *p)
+{
+	unsigned long flags;
+	unsigned int res;
+	unsigned long mask = 1UL << (bit & 31);
+
+	p += bit >> 5;
+
+	local_irq_save(flags);
+	res = *p;
+	*p = res ^ mask;
+	local_irq_restore(flags);
+
+	return res & mask;
+}
+
+/*
+ * Now the non-atomic variants.  We let the compiler handle all
+ * optimisations for these.  These are all _native_ endian.
+ */
+static inline void __set_bit(int nr, volatile unsigned long *p)
+{
+	p[nr >> 5] |= (1UL << (nr & 31));
+}
+
+static inline void __clear_bit(int nr, volatile unsigned long *p)
+{
+	p[nr >> 5] &= ~(1UL << (nr & 31));
+}
+
+static inline void __change_bit(int nr, volatile unsigned long *p)
+{
+	p[nr >> 5] ^= (1UL << (nr & 31));
+}
+
+static inline int __test_and_set_bit(int nr, volatile unsigned long *p)
+{
+	unsigned long oldval, mask = 1UL << (nr & 31);
+
+	p += nr >> 5;
+
+	oldval = *p;
+	*p = oldval | mask;
+	return oldval & mask;
+}
+
+static inline int __test_and_clear_bit(int nr, volatile unsigned long *p)
+{
+	unsigned long oldval, mask = 1UL << (nr & 31);
+
+	p += nr >> 5;
+
+	oldval = *p;
+	*p = oldval & ~mask;
+	return oldval & mask;
+}
+
+static inline int __test_and_change_bit(int nr, volatile unsigned long *p)
+{
+	unsigned long oldval, mask = 1UL << (nr & 31);
+
+	p += nr >> 5;
+
+	oldval = *p;
+	*p = oldval ^ mask;
+	return oldval & mask;
+}
+
+/*
+ * This routine doesn't need to be atomic.
+ */
+static inline int __test_bit(int nr, const volatile unsigned long * p)
+{
+	return (p[nr >> 5] >> (nr & 31)) & 1UL;
+}
+
+/*
+ *  A note about Endian-ness.
+ *  -------------------------
+ *
+ * When the ARM is put into big endian mode via CR15, the processor
+ * merely swaps the order of bytes within words, thus:
+ *
+ *          ------------ physical data bus bits -----------
+ *          D31 ... D24  D23 ... D16  D15 ... D8  D7 ... D0
+ * little     byte 3       byte 2       byte 1      byte 0
+ * big        byte 0       byte 1       byte 2      byte 3
+ *
+ * This means that reading a 32-bit word at address 0 returns the same
+ * value irrespective of the endian mode bit.
+ *
+ * Peripheral devices should be connected with the data bus reversed in
+ * "Big Endian" mode.  ARM Application Note 61 is applicable, and is
+ * available from http://www.arm.com/.
+ *
+ * The following assumes that the data bus connectivity for big endian
+ * mode has been followed.
+ *
+ * Note that bit 0 is defined to be 32-bit word bit 0, not byte 0 bit 0.
+ */
+
+/*
+ * Little endian assembly bitops.  nr = 0 -> byte 0 bit 0.
+ */
+extern void _set_bit_le(int nr, volatile void *p);
+extern void _clear_bit_le(int nr, volatile void *p);
+extern void _change_bit_le(int nr, volatile void *p);
+extern int _test_and_set_bit_le(int nr, volatile void *p);
+extern int _test_and_clear_bit_le(int nr, volatile void *p);
+extern int _test_and_change_bit_le(int nr, volatile void *p);
+extern int _find_first_zero_bit_le(const unsigned long *p, unsigned size);
+extern int _find_next_zero_bit_le(const unsigned long *p, int size, int offset);
+extern int _find_first_bit_le(const unsigned long *p, unsigned size);
+extern int _find_next_bit_le(const unsigned long *p, int size, int offset);
+
+/*
+ * Big endian assembly bitops.  nr = 0 -> byte 3 bit 0.
+ */
+extern void _set_bit_be(int nr, volatile void *p);
+extern void _clear_bit_be(int nr, volatile void *p);
+extern void _change_bit_be(int nr, volatile void *p);
+extern int _test_and_set_bit_be(int nr, volatile void *p);
+extern int _test_and_clear_bit_be(int nr, volatile void *p);
+extern int _test_and_change_bit_be(int nr, volatile void *p);
+extern int _find_first_zero_bit_be(const unsigned long *p, unsigned size);
+extern int _find_next_zero_bit_be(const unsigned long *p, int size, int offset);
+extern int _find_first_bit_be(const unsigned long *p, unsigned size);
+extern int _find_next_bit_be(const unsigned long *p, int size, int offset);
+
+/*
+ * The __* form of bitops are non-atomic and may be reordered.
+ */
+#define	ATOMIC_BITOP_LE(name,nr,p)		\
+	(__builtin_constant_p(nr) ?		\
+	 ____atomic_##name(nr, (volatile void *)p) :		\
+	 _##name##_le(nr,p))
+
+#define	ATOMIC_BITOP_BE(name,nr,p)		\
+	(__builtin_constant_p(nr) ?		\
+	 ____atomic_##name(nr, (volatile void *)p) :		\
+	 _##name##_be(nr,p))
+
+#define NONATOMIC_BITOP(name,nr,p)		\
+	(____nonatomic_##name(nr, p))
+
+#ifndef __ARMEB__
+/*
+ * These are the little endian, atomic definitions.
+ */
+#define set_bit(nr,p)			ATOMIC_BITOP_LE(set_bit,nr,p)
+#define clear_bit(nr,p)			ATOMIC_BITOP_LE(clear_bit,nr,p)
+#define change_bit(nr,p)		ATOMIC_BITOP_LE(change_bit,nr,p)
+#define test_and_set_bit(nr,p)		ATOMIC_BITOP_LE(test_and_set_bit,nr,p)
+#define test_and_clear_bit(nr,p)	ATOMIC_BITOP_LE(test_and_clear_bit,nr,p)
+#define test_and_change_bit(nr,p)	ATOMIC_BITOP_LE(test_and_change_bit,nr,p)
+#define test_bit(nr,p)			__test_bit(nr, (const volatile void *)p)
+#define find_first_zero_bit(p,sz)	_find_first_zero_bit_le(p,sz)
+#define find_next_zero_bit(p,sz,off)	_find_next_zero_bit_le(p,sz,off)
+#define find_first_bit(p,sz)		_find_first_bit_le(p,sz)
+#define find_next_bit(p,sz,off)		_find_next_bit_le(p,sz,off)
+
+#else
+
+/*
+ * These are the big endian, atomic definitions.
+ */
+#define set_bit(nr,p)			ATOMIC_BITOP_BE(set_bit,nr,p)
+#define clear_bit(nr,p)			ATOMIC_BITOP_BE(clear_bit,nr,p)
+#define change_bit(nr,p)		ATOMIC_BITOP_BE(change_bit,nr,p)
+#define test_and_set_bit(nr,p)		ATOMIC_BITOP_BE(test_and_set_bit,nr,p)
+#define test_and_clear_bit(nr,p)	ATOMIC_BITOP_BE(test_and_clear_bit,nr,p)
+#define test_and_change_bit(nr,p)	ATOMIC_BITOP_BE(test_and_change_bit,nr,p)
+#define test_bit(nr,p)			__test_bit(nr,p)
+#define find_first_zero_bit(p,sz)	_find_first_zero_bit_be(p,sz)
+#define find_next_zero_bit(p,sz,off)	_find_next_zero_bit_be(p,sz,off)
+#define find_first_bit(p,sz)		_find_first_bit_be(p,sz)
+#define find_next_bit(p,sz,off)		_find_next_bit_be(p,sz,off)
+
+#endif
+
+/*
+ * On ARMv5 and above those functions can be implemented around
+ * the clz instruction for much better code efficiency.
+ */
+
+#define fls(x) \
+	( __builtin_constant_p(x) ? generic_fls(x) : \
+	  ({ int __r; asm("clz\t%0, %1" : "=r"(__r) : "r"(x) : "cc"); 32-__r; }) )
+#define ffs(x) ({ unsigned long __t = (x); fls(__t & -__t); })
+#define __ffs(x) (ffs(x) - 1)
+#define ffz(x) __ffs( ~(x) )
+
+#define find_first_set_bit(word) (ffs(word)-1)
+
+/*
+ * hweightN: returns the hamming weight (i.e. the number
+ * of bits set) of a N-bit word
+ */
+
+#define hweight32(x) generic_hweight32(x)
+#define hweight16(x) generic_hweight16(x)
+#define hweight8(x) generic_hweight8(x)
+
+#endif /* __ARM_BITOPS_H */
diff --git a/xen/include/asm-arm/bug.h b/xen/include/asm-arm/bug.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/bug.h
@@ -0,0 +1,20 @@
+#ifndef __ARM_BUG_H__
+#define __ARM_BUG_H__
+
+#include <xen/lib.h>
+
+#define BUG() __bug(__FILE__, __LINE__)
+#define WARN() __warn(__FILE__, __LINE__)
+
+#define dump_execution_state()                                      \
+	do {                                                            \
+		printk("FIXME: implement arm dump_execution_state()\n"); \
+		dump_stack();						\
+	} while (0)
+
+#define vcpu_show_execution_state(v)					\
+	do {								\
+		printk("FIXME: implement arm vcpu_show_execution_state()\n"); \
+	} while (0)
+
+#endif /* __ARM_BUG_H__ */
diff --git a/xen/include/asm-arm/byteorder.h b/xen/include/asm-arm/byteorder.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/byteorder.h
@@ -0,0 +1,22 @@
+#ifndef __ARM_BYTEORDER_H__
+#define __ARM_BYTEORDER_H__
+
+#include <asm/types.h>
+#include <xen/compiler.h>
+
+static inline __attribute_const__ __u32 ___arch__swab32(__u32 x)
+{
+    asm ("rev %0, %1" : "=r" (x) : "r" (x));
+    return x;
+}
+
+/* Do not define swab16.  Gcc is smart enough to recognize "C" version and
+   convert it into rotation or exchange.  */
+
+#define __arch__swab32(x) ___arch__swab32(x)
+
+#define __BYTEORDER_HAS_U64__
+
+#include <xen/byteorder/little_endian.h>
+
+#endif /* __ARM_BYTEORDER_H__ */
diff --git a/xen/include/asm-arm/cache.h b/xen/include/asm-arm/cache.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/cache.h
@@ -0,0 +1,15 @@
+/*
+ * include/asm-arm/cache.h
+ */
+#ifndef __ARCH_ARM_CACHE_H
+#define __ARCH_ARM_CACHE_H
+
+#include <xen/config.h>
+
+/* L1 cache line size */
+#define L1_CACHE_SHIFT	(CONFIG_ARM_L1_CACHE_SHIFT)
+#define L1_CACHE_BYTES	(1 << L1_CACHE_SHIFT)
+
+#define __read_mostly __attribute__((__section__(".data.read_mostly")))
+
+#endif
diff --git a/xen/include/asm-arm/capability.h b/xen/include/asm-arm/capability.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/capability.h
@@ -0,0 +1,7 @@
+#ifndef __ASM_CAPABILITY_H__
+#define __ASM_CAPABILITY_H__
+
+#define HCAP_VFP
+
+#endif /* __ASM_CAPABILITY_H__ */
+
diff --git a/xen/include/asm-arm/config.h b/xen/include/asm-arm/config.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/config.h
@@ -0,0 +1,85 @@
+#ifndef __ARM_CONFIG_H_
+#define __ARM_CONFIG_H_
+
+#ifdef CONFIG_USE_HIGH_VECTORS
+#define VECTORS_BASE	0xFFFF0000
+#else
+#define VECTORS_BASE	0x00000000
+#endif
+
+#ifndef NDEBUG
+#define MEMORY_GUARD
+#endif
+
+#ifndef STACK_ORDER
+#define STACK_ORDER	0
+#endif
+#define STACK_SIZE	(PAGE_SIZE << STACK_ORDER)
+
+#define CONFIG_SMP
+#define NR_CPUS	1
+#define MAX_VIRT_CPUS  1
+#define MAX_HVM_VCPUS  1
+#define CONFIG_ARM_L1_CACHE_SHIFT  7
+#define PADDR_BITS 32
+
+#define OPT_CONSOLE_STR "com1"
+
+/* Maybe do this...maybe not */
+#define supervisor_mode_kernel (0)
+
+/* FFC00000-100000000 - I/O remapping area (4MB) */
+#define IOREMAP_MBYTES		4
+#define IOREMAP_VIRT_END	(0UL)
+#define IOREMAP_VIRT_START	(IOREMAP_VIRT_END - (IOREMAP_MBYTES<<20))
+
+/* FF000000-FFC00000  - Xen code/data/heap (12MB) */
+#define DIRECTMAP_MBYTES	12
+#define DIRECTMAP_VIRT_END	IOREMAP_VIRT_START
+#define DIRECTMAP_VIRT_START	(DIRECTMAP_VIRT_END - (DIRECTMAP_MBYTES<<20))
+
+/* FEC00000-FF000000  - map_domain_page cache (4MB) */
+#define MAPCACHE_MBYTES		4
+#define MAPCACHE_VIRT_END	DIRECTMAP_VIRT_START
+#define MAPCACHE_VIRT_START	(MAPCACHE_VIRT_END - (MAPCACHE_MBYTES<<20))
+
+/* FE800000-FEC00000  - per-domain (inlcuding mapcache) (8MB) */
+#define PERDOMAIN_MBYTES	8
+#define PERDOMAIN_VIRT_END	DIRECTMAP_VIRT_START
+#define PERDOMAIN_VIRT_START	(PERDOMAIN_VIRT_END - (PERDOMAIN_MBYTES<<20))
+
+/* FE000000-FE800000  - linear page table (8MB) */
+#define LINEARPT_MBYTES		8
+#define LINEAR_PT_VIRT_END	PERDOMAIN_VIRT_START
+#define LINEAR_PT_VIRT_START	(LINEAR_PT_VIRT_END - (LINEARPT_MBYTES<<20))
+
+/* FDC00000-FE000000  - writeable m2p table (4MB) */
+#define MACHPHYS_MBYTES		4 /* 1 MB per 1 GB RAM */
+#define RDWR_MPT_VIRT_END	LINEAR_PT_VIRT_START
+#define RDWR_MPT_VIRT_START	(RDWR_MPT_VIRT_END - (MACHPHYS_MBYTES<<20))
+
+/* FC400000-FDC00000  - frame table (24MB) */
+#define FRAMETABLE_MBYTES	(MACHPHYS_MBYTES * 6)
+#define FRAMETABLE_VIRT_END	RDWR_MPT_VIRT_START
+#define FRAMETABLE_SIZE         (FRAMETABLE_MBYTES<<20)
+#define FRAMETABLE_VIRT_START	(FRAMETABLE_VIRT_END - FRAMETABLE_SIZE)
+
+/* FC000000-FC400000  - read-only m2p table (4MB) */
+#define RO_MPT_VIRT_END		FRAMETABLE_VIRT_START
+#define RO_MPT_VIRT_START	(RO_MPT_VIRT_END - (MACHPHYS_MBYTES<<20))
+
+/* Maximum lienar address accessible via guest. */
+#define GUEST_SEGMENT_MAX_ADDR	RO_MPT_VIRT_END
+
+/* Hypervisor owns > RO_MPT_VIRT_END */
+/* #define HYPERVISOR_VIRT_START	RO_MPT_VIRT_START */
+#define HYPERVISOR_VIRT_START	0xFC000000
+
+#define ELFSIZE	32
+#define asmlinkage
+
+#define watchdog_disable() ((void)0)
+#define watchdog_enable()  ((void)0)
+
+#endif /* __ARM_CONFIG_H_ */
+
diff --git a/xen/include/asm-arm/cp15.h b/xen/include/asm-arm/cp15.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/cp15.h
@@ -0,0 +1,43 @@
+/*
+ * cp15.h
+ *
+ * Copyright (C) 2008 Samsung Electronics
+ *          Jaemin Ryu      <jm77.ryu@samsung.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public version 2 of License as published by
+ * the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef __ASM_CP15_H__
+#define __ASM_CP15_H__
+
+/*
+ * Co-Processor Access Register
+ */
+#define CPAR_BIT_CP0	(1 << 0)
+#define CPAR_BIT_CP1	(1 << 1)
+#define CPAR_BIT_CP2	(1 << 2)
+#define CPAR_BIT_CP3	(1 << 3)
+#define CPAR_BIT_CP4	(1 << 4)
+#define CPAR_BIT_CP5	(1 << 5)
+#define CPAR_BIT_CP6	(1 << 6)
+#define CPAR_BIT_CP7	(1 << 7)
+#define CPAR_BIT_CP8	(1 << 8)
+#define CPAR_BIT_CP9	(1 << 9)
+#define CPAR_BIT_CP10	(1 << 10)
+#define CPAR_BIT_CP11	(1 << 11)
+#define CPAR_BIT_CP12	(1 << 12)
+#define CPAR_BIT_CP13	(1 << 13)
+
+#endif /* __ASM_CP15_H__ */
+
diff --git a/xen/include/asm-arm/cpu-domain.h b/xen/include/asm-arm/cpu-domain.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/cpu-domain.h
@@ -0,0 +1,51 @@
+#ifndef __ASM_CPU_DOMAIN_H
+#define __ASM_CPU_DOMAIN_H
+
+#define DOMAIN_HYPERVISOR	0
+#define DOMAIN_KERNEL		1
+#define DOMAIN_SUPERVISOR	1
+#define DOMAIN_IO			2
+#define DOMAIN_USER			3
+#define DOMAIN_METASET		4
+
+/*
+ * Domain types
+ */
+#define DOMAIN_NOACCESS			0
+#define DOMAIN_CLIENT			1
+#define DOMAIN_MANAGER			3
+
+#define DOMAIN_VALUE(dom,type)	((type) << (2*(dom)))
+
+#define DOMAIN_HYPERVISOR_VALUE					\
+	(DOMAIN_VALUE(DOMAIN_HYPERVISOR,DOMAIN_CLIENT) |	\
+	 DOMAIN_VALUE(DOMAIN_KERNEL, DOMAIN_CLIENT) |		\
+	 DOMAIN_VALUE(DOMAIN_IO, DOMAIN_CLIENT) |		\
+	 DOMAIN_VALUE(DOMAIN_USER,DOMAIN_CLIENT))
+
+#define DOMAIN_SUPERVISOR_VALUE
+#define DOMAIN_IO_VALUE
+
+#define DOMAIN_KERNEL_VALUE					\
+	(DOMAIN_VALUE(DOMAIN_HYPERVISOR, DOMAIN_CLIENT) |	\
+	 DOMAIN_VALUE(DOMAIN_KERNEL, DOMAIN_MANAGER) |		\
+	 DOMAIN_VALUE(DOMAIN_IO, DOMAIN_MANAGER) | 		\
+	 DOMAIN_VALUE(DOMAIN_USER, DOMAIN_CLIENT))		\
+
+#define DOMAIN_USER_VALUE					\
+	(DOMAIN_VALUE(DOMAIN_HYPERVISOR, DOMAIN_CLIENT) |	\
+	 DOMAIN_VALUE(DOMAIN_KERNEL,   DOMAIN_CLIENT) |		\
+	 DOMAIN_VALUE(DOMAIN_IO,       DOMAIN_CLIENT) |	\
+	 DOMAIN_VALUE(DOMAIN_USER,     DOMAIN_CLIENT))
+
+#ifndef __ASSEMBLY__
+
+#define set_domain(x)					\
+	do {								\
+	__asm__ __volatile__(				\
+	"mcr	p15, 0, %0, c3, c0"			\
+	  : : "r" (x));						\
+	isb();								\
+	} while (0)
+#endif
+#endif /* !__ASSEMBLY__ */
diff --git a/xen/include/asm-arm/cpu-ops.h b/xen/include/asm-arm/cpu-ops.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/cpu-ops.h
@@ -0,0 +1,77 @@
+/*
+ * cpu-ops.h
+ *
+ * Copyright (C) 2008 Samsung Electronics
+ *          JaeMin Ryu  <jm77.ryu@samsung.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public version 2 of License as published by
+ * the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef __ASM_CPU_OPS_H__
+#define __ASM_CPU_OPS_H__
+
+#ifndef __ASSEMBLY__
+#define DECLARE_CPU_OP(gop, nop)	\
+	typeof (nop) gop		\
+	__attribute__((weak, alias(#nop)))
+
+void cpu_halt(int mode);
+void cpu_idle(void);
+
+/*
+ * MMU Operations
+ */
+void cpu_set_pte(unsigned long pte, unsigned long page);
+void cpu_switch_ttb(unsigned long, int);
+unsigned long cpu_get_ttb(void);
+
+/*
+ * Cache operations
+ */
+void cpu_flush_cache_all(void);
+void cpu_flush_cache_range(unsigned long start, unsigned long end);
+void cpu_flush_cache_page(unsigned long page);
+void cpu_flush_cache_entry(unsigned long addr, unsigned long flags);
+void cpu_clean_cache_range(unsigned long start, unsigned long end);
+
+/*
+ *
+ */
+void cpu_invalidate_dma_range(unsigned long start, unsigned long end);
+void cpu_clean_dma_range(unsigned long start, unsigned long end);
+void cpu_flush_dma_range(unsigned long start, unsigned long end);
+void cpu_coherent_range(unsigned long start, unsigned long end);
+/*
+ * TLB operations
+ */
+void cpu_flush_tlb_all(void);
+void cpu_flush_tlb_entry(unsigned long addr);
+void cpu_flush_tlb_range(unsigned long start, unsigned long end);
+
+/*
+ * Page operations
+ */
+
+void cpu_copy_page(void *dst, void *src, unsigned long size);
+void cpu_clear_page(void *dst, unsigned long size);
+#endif
+
+#ifdef __ASSEMBLY__
+#define DECLARE_CPU_OP(gop, nop)	 \
+	.set gop, nop			;\
+	.global gop			;
+#endif
+
+#endif
+
diff --git a/xen/include/asm-arm/current.h b/xen/include/asm-arm/current.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/current.h
@@ -0,0 +1,56 @@
+/*
+ *  current.h
+ *
+ * Copyright (C) 2008 Samsung Electronics
+ * 			ChanJu Park <beastworld@samsung.com>
+ *          JaeMin Ryu  <jm77.ryu@samsung.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public version 2 of License as published by
+ * the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+#ifndef __ARM_CURRENT_H__
+#define __ARM_CURRENT_H__
+
+#include <public/xen.h>
+#include <asm/page.h>
+
+#ifndef __ASSEMBLY__
+struct vcpu;
+
+struct cpu_info {
+	int             processor_id;
+	struct vcpu    *current_vcpu;
+	unsigned long per_cpu_offset;
+};
+
+static inline struct cpu_info *get_cpu_info(void)
+{
+	register unsigned long sp asm("r13");
+	return (struct cpu_info *) ( sp & ~(STACK_SIZE -1)  );
+}
+
+#define get_current()         (get_cpu_info()->current_vcpu)
+#define set_current(vcpu)     (get_cpu_info()->current_vcpu = (vcpu))
+#define current get_current()
+
+#define get_processor_id()    (get_cpu_info()->processor_id)
+#define set_processor_id(id)  do {                                      \
+    struct cpu_info *ci__ = get_cpu_info();                             \
+    ci__->per_cpu_offset = __per_cpu_offset[ci__->processor_id = (id)]; \
+} while (0)
+
+
+#define guest_cpu_user_regs() (&get_cpu_info()->current_vcpu->arch.user_regs)
+#endif
+
+#endif /* __ASM_CURRENT_H__ */
diff --git a/xen/include/asm-arm/debugger.h b/xen/include/asm-arm/debugger.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/debugger.h
@@ -0,0 +1,37 @@
+/******************************************************************************
+ * asm/debugger.h
+ *
+ * Generic hooks into arch-dependent Xen.
+ *
+ * Each debugger should define two functions here:
+ *
+ * 1. debugger_trap_entry():
+ *  Called at start of any synchronous fault or trap, before any other work
+ *  is done. The idea is that if your debugger deliberately caused the trap
+ *  (e.g. to implement breakpoints or data watchpoints) then you can take
+ *  appropriate action and return a non-zero value to cause early exit from
+ *  the trap function.
+ *
+ * 2. debugger_trap_fatal():
+ *  Called when Xen is about to give up and crash. Typically you will use this
+ *  hook to drop into a debug session. It can also be used to hook off
+ *  deliberately caused traps (which you then handle and return non-zero).
+ *
+ * 3. debugger_trap_immediate():
+ *  Called if we want to drop into a debugger now.  This is essentially the
+ *  same as debugger_trap_fatal, except that we use the current register state
+ *  rather than the state which was in effect when we took the trap.
+ *  For example: if we're dying because of an unhandled exception, we call
+ *  debugger_trap_fatal; if we're dying because of a panic() we call
+ *  debugger_trap_immediate().
+ */
+
+#ifndef __ASM_ARM_DEBUGGER_H__
+#define __ASM_ARM_DEBUGGER_H__
+
+#define debugger_trap_fatal(v, r) (0)
+#define debugger_trap_immediate() ((void)0)
+#define debugger_trap_entry(v, r) (0)
+
+#endif
+
diff --git a/xen/include/asm-arm/delay.h b/xen/include/asm-arm/delay.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/delay.h
@@ -0,0 +1,13 @@
+#ifndef __ASM_DELAY_H__
+#define __ASM_DELAY_H__
+
+#include <asm/bug.h>
+
+static __inline__ void
+udelay (unsigned long usecs)
+{
+	BUG();
+}
+
+#endif
+
diff --git a/xen/include/asm-arm/desc.h b/xen/include/asm-arm/desc.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/desc.h
@@ -0,0 +1,1 @@
+/* This file is intentionally left empty. */
diff --git a/xen/include/asm-arm/div64.h b/xen/include/asm-arm/div64.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/div64.h
@@ -0,0 +1,49 @@
+#ifndef __ASM_ARM_DIV64
+#define __ASM_ARM_DIV64
+
+#include <asm/system.h>
+#include <asm/asm-macros.h>
+
+/*
+ * The semantics of do_div() are:
+ *
+ * uint32_t do_div(uint64_t *n, uint32_t base)
+ * {
+ * 	uint32_t remainder = *n % base;
+ * 	*n = *n / base;
+ * 	return remainder;
+ * }
+ *
+ * In other words, a 64-bit dividend with a 32-bit divisor producing
+ * a 64-bit result and a 32-bit remainder.  To accomplish this optimally
+ * we call a special __do_div64 helper with completely non standard
+ * calling convention for arguments and results (beware).
+ */
+
+#ifdef __ARMEB__
+#define __xh "r0"
+#define __xl "r1"
+#else
+#define __xl "r0"
+#define __xh "r1"
+#endif
+
+#define do_div(n,base)						\
+({								\
+	register unsigned int __base      asm("r4") = base;	\
+	register unsigned long long __n   asm("r0") = n;	\
+	register unsigned long long __res asm("r2");		\
+	register unsigned int __rem       asm(__xh);		\
+	asm(	__asmeq("%0", __xh)				\
+		__asmeq("%1", "r2")				\
+		__asmeq("%2", "r0")				\
+		__asmeq("%3", "r4")				\
+		"bl	__do_div64"				\
+		: "=r" (__rem), "=r" (__res)			\
+		: "r" (__n), "r" (__base)			\
+		: "ip", "lr", "cc");				\
+	n = __res;						\
+	__rem;							\
+})
+
+#endif
diff --git a/xen/include/asm-arm/dma.h b/xen/include/asm-arm/dma.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/dma.h
@@ -0,0 +1,11 @@
+#ifndef __ARCH_DMA_H__
+#define __ARCH_DMA_H__
+
+typedef struct dma_channel_info {
+	domid_t	owner;
+	int	in_use;
+}dma_channel_info_t;
+
+extern dma_channel_info_t dma_channel_map[];
+
+#endif /* _ARCH_DMA_H */
diff --git a/xen/include/asm-arm/domain.h b/xen/include/asm-arm/domain.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/domain.h
@@ -0,0 +1,92 @@
+#ifndef __ARM_DOMAIN_H__
+#define __ARM_DOMAIN_H__
+
+#include <xen/config.h>
+#include <xen/mm.h>
+#include <public/vcpu.h>
+#include <xen/cache.h>
+#include <xen/init.h>
+
+#define TRAP_TABLE_ENTRIES			8
+
+#define TRAP_RESET					0
+#define TRAP_UNDEFINED_INSTRUCTION	1
+#define TRAP_SOFTWARE_INTERRUPT		2
+#define TRAP_PREFETCH_ABORT			3
+#define TRAP_DATA_ABORT				4
+#define TRAP_RESERVED				5
+#define TRAP_INTERRUPT_REQUEST		6
+#define TRAP_FAST_INTERRUPT_REQUEST	7
+
+
+#define MAPHASH_ENTRIES 8
+#define MAPHASH_HASHFN(pfn) ((pfn) & (MAPHASH_ENTRIES-1))
+#define MAPHASHENT_NOTINUSE ((u16)~0U)
+struct mapcache_vcpu {
+    /* Shadow of mapcache_domain.epoch. */
+    unsigned int shadow_epoch;
+
+    /* Lock-free per-VCPU hash of recently-used mappings. */
+    struct vcpu_maphash_entry {
+        unsigned long mfn;
+        uint16_t      idx;
+        uint16_t      refcnt;
+    } hash[MAPHASH_ENTRIES];
+};
+
+#define MAPCACHE_ORDER   10
+#define MAPCACHE_ENTRIES (1 << MAPCACHE_ORDER)
+struct mapcache_domain {
+    /* The PTEs that provide the mappings, and a cursor into the array. */
+    pte_t *table;
+    unsigned int cursor;
+
+    /* Protects map_domain_page(). */
+    spinlock_t lock;
+
+    /* Garbage mappings are flushed from TLBs in batches called 'epochs'. */
+    unsigned int epoch;
+    u32 tlbflush_timestamp;
+
+    /* Which mappings are in use, and which are garbage to reap next epoch? */
+    unsigned long inuse[BITS_TO_LONGS(MAPCACHE_ENTRIES)];
+    unsigned long garbage[BITS_TO_LONGS(MAPCACHE_ENTRIES)];
+} __cacheline_aligned;
+
+void mapcache_domain_init(struct domain *);
+void mapcache_vcpu_init(struct vcpu *);
+
+struct p2m_domain;
+
+struct arch_domain
+{
+	/* I/O-port admin-specified access capabilities. */
+	struct rangeset *ioport_caps;
+	struct mapcache_domain mapcache;
+    struct p2m_domain *p2m;
+} __cacheline_aligned;
+
+struct arch_vcpu
+{
+	unsigned long	flags;
+	unsigned long	guest_table;		/* (MA) guest notion of cr3 */
+	unsigned long	*guest_vtable;		/* virtual address of pagetable */
+	unsigned long	guest_pstart;		/* guest OS physical start address */
+	unsigned long	guest_vstart;		/* guest OS virtual start address */
+	unsigned long	trap_table[TRAP_TABLE_ENTRIES];
+    struct cpu_user_regs user_regs;
+	struct mapcache_vcpu mapcache;
+	struct vcpu_guest_context	guest_context;
+} __cacheline_aligned;
+
+#endif /* __ARM_DOMAIN_H__ */
+
+/*
+ * Local variables:
+ * mode: C
+ * c-set-style: "BSD"
+ * c-basic-offset: 4
+ * tab-width: 4
+ * indent-tabs-mode: nil
+ * End:
+ */
diff --git a/xen/include/asm-arm/elf.h b/xen/include/asm-arm/elf.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/elf.h
@@ -0,0 +1,19 @@
+#ifndef __ARM_ELF_H__
+#define __ARM_ELF_H__
+
+typedef struct {
+    void *dummy;
+} crash_xen_core_t;
+
+typedef struct {
+    void *dummy;
+} ELF_Gregset;
+
+static inline void elf_core_save_regs(ELF_Gregset *core_regs,
+                                      crash_xen_core_t *xen_core_regs)
+{
+    BUG();
+}
+
+
+#endif /* __ARM_ELF_H__ */
diff --git a/xen/include/asm-arm/event.h b/xen/include/asm-arm/event.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/event.h
@@ -0,0 +1,42 @@
+/******************************************************************************
+ * event.h
+ *
+ * A nice interface for passing asynchronous events to guest OSes.
+ * (architecture-dependent part)
+ *
+ */
+
+#ifndef __ASM_EVENT_H__
+#define __ASM_EVENT_H__
+
+#include <xen/shared.h>
+
+void vcpu_mark_events_pending(struct vcpu *v);
+
+/* No arch specific virq definition now. Default to global. */
+static inline int arch_virq_is_global(int virq)
+{
+    return 1;
+}
+
+/* Note: Bitwise operations result in fast code with no branches. */
+#define event_pending(v)                        \
+    (!!(v)->vcpu_info->evtchn_upcall_pending &  \
+      !(v)->vcpu_info->evtchn_upcall_mask)
+
+static inline int local_events_need_delivery(void)
+{
+    return event_pending(current);
+}
+
+static inline void local_event_delivery_disable(void)
+{
+    current->vcpu_info->evtchn_upcall_mask = 1;
+}
+
+static inline void local_event_delivery_enable(void)
+{
+    current->vcpu_info->evtchn_upcall_mask = 0;
+}
+
+#endif
diff --git a/xen/include/asm-arm/fault.h b/xen/include/asm-arm/fault.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/fault.h
@@ -0,0 +1,7 @@
+#ifndef __ASM_FAULT_H__
+#define __ASM_FAULT_H__
+
+#define FAULT_STATUS_MASK		(0x0000000F)
+#define FAULT_DOMAIN_MASK		(0x000000F0)
+
+#endif
diff --git a/xen/include/asm-arm/fcse.h b/xen/include/asm-arm/fcse.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/fcse.h
@@ -0,0 +1,4 @@
+#ifndef __ASM_ASID_H__
+#define __ASM_ASID_H__
+
+#endif /* __ASM_ASID_H__ */
diff --git a/xen/include/asm-arm/flushtlb.h b/xen/include/asm-arm/flushtlb.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/flushtlb.h
@@ -0,0 +1,44 @@
+/******************************************************************************
+ * flushtlb.c
+ * based on x86 flushtlb.h
+ *
+ * Copyright (c) 2006 Isaku Yamahata <yamahata at valinux co jp>
+ *                    VA Linux Systems Japan K.K.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ *
+ */
+
+#ifndef __ASM_FLUSHTLB_H__
+#define __ASM_FLUSHTLB_H__
+
+#define tlbflush_current_time()                 (0)
+#define tlbflush_clock_inc_and_return()         (0)
+#define tlbflush_update_time(time, timestamp)   do {(void)timestamp;} while (0)
+#define NEED_FLUSH(obj_stamp, lastuse_stamp)    (1)
+
+#define tlbflush_filter(x,y) ((void)0)
+
+#endif /* __ASM_FLUSHTLB_H__ */
+
+/*
+ * Local variables:
+ * mode: C
+ * c-set-style: "BSD"
+ * c-basic-offset: 4
+ * tab-width: 4
+ * indent-tabs-mode: nil
+ * End:
+ */
diff --git a/xen/include/asm-arm/grant_table.h b/xen/include/asm-arm/grant_table.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/grant_table.h
@@ -0,0 +1,72 @@
+/******************************************************************************
+ * include/asm-arm/grant_table.h
+ *
+ * Copyright (c) 2004-2005 K A Fraser
+ * Copyright (c) 2011 Andrei Warkentin <andreiw@motorola.com>
+ */
+
+#ifndef __ARM_GRANT_TABLE_H__
+#define __ARM_GRANT_TABLE_H__
+
+#include <asm/page.h>
+
+#define INITIAL_NR_GRANT_FRAMES 4
+
+/*
+ * Caller must own caller's BIGLOCK, is responsible for flushing the TLB, and
+ * must hold a reference to the page.
+ */
+int create_grant_host_mapping(uint64_t addr, unsigned long frame,
+			      unsigned int flags, unsigned int cache_flags);
+int replace_grant_host_mapping(
+    uint64_t addr, unsigned long frame, uint64_t new_addr, unsigned int flags);
+
+#define gnttab_create_shared_page(d, t, i)                               \
+    do {                                                                 \
+        share_xen_page_with_guest(                                       \
+            virt_to_page((char *)(t)->shared_raw[i]),                    \
+            (d), XENSHARE_writable);                                     \
+    } while ( 0 )
+
+#define gnttab_create_status_page(d, t, i)                               \
+    do {                                                                 \
+        share_xen_page_with_guest(                                       \
+           virt_to_page((char *)(t)->status[i]),                         \
+            (d), XENSHARE_writable);                                     \
+    } while ( 0 )
+
+
+#define gnttab_shared_mfn(d, t, i)                      \
+    ((virt_to_maddr((t)->shared_raw[i]) >> PAGE_SHIFT))
+
+#define gnttab_shared_gmfn(d, t, i)                     \
+    (mfn_to_gmfn(d, gnttab_shared_mfn(d, t, i)))
+
+
+#define gnttab_status_mfn(t, i)                         \
+    ((virt_to_maddr((t)->status[i]) >> PAGE_SHIFT))
+
+#define gnttab_status_gmfn(d, t, i)                     \
+    (mfn_to_gmfn(d, gnttab_status_mfn(t, i)))
+
+#define gnttab_mark_dirty(d, f) ((void)f)
+
+static inline void gnttab_clear_flag(unsigned long nr, uint16_t *addr)
+{
+    clear_bit(nr, (unsigned long *)addr);
+}
+
+/* Foreign mappings of HHVM-guest pages do not modify the type count. */
+#define gnttab_host_mapping_get_page_type(op, ld, rd)   \
+    (!((op)->flags & GNTMAP_readonly) &&                \
+     (((ld) == (rd)) || !paging_mode_external(rd)))
+
+/* Done implicitly when page tables are destroyed. */
+#define gnttab_release_host_mappings(domain) ( paging_mode_external(domain) )
+
+static inline int replace_grant_supported(void)
+{
+    return 1;
+}
+
+#endif /* __ASM_GRANT_TABLE_H__ */
diff --git a/xen/include/asm-arm/guest_access.h b/xen/include/asm-arm/guest_access.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/guest_access.h
@@ -0,0 +1,129 @@
+/*
+ * Copyright (C) 2006 Hollis Blanchard <hollisb@us.ibm.com>, IBM Corporation
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
+ *
+ */
+
+#ifndef __ARM_GUEST_ACCESS_H__
+#define __ARM_GUEST_ACCESS_H__
+
+#include <asm/uaccess.h>
+#include <xen/paging.h>
+
+/* Raw access functions: no type checking. */
+#define raw_copy_to_guest(dst, src, len)        \
+     copy_to_user((dst), (src), (len))
+#define raw_copy_from_guest(dst, src, len)      \
+     copy_from_user((dst), (src), (len))
+#define __raw_copy_to_guest(dst, src, len)      \
+     __copy_to_user((dst), (src), (len))
+#define __raw_copy_from_guest(dst, src, len)    \
+     __copy_from_user((dst), (src), (len))
+
+/* Is the guest handle a NULL reference? */
+#define guest_handle_is_null(hnd)        ((hnd).p == NULL)
+
+/* Offset the given guest handle into the array it refers to. */
+#define guest_handle_add_offset(hnd, nr) ((hnd).p += (nr))
+#define guest_handle_subtract_offset(hnd, nr) ((hnd).p -= (nr))
+
+/* Cast a guest handle to the specified type of handle. */
+#define guest_handle_cast(hnd, type) ({         \
+    type *_x = (hnd).p;                         \
+    (XEN_GUEST_HANDLE(type)) { _x };            \
+})
+
+#define guest_handle_from_ptr(ptr, type)        \
+    ((XEN_GUEST_HANDLE(type)) { (type *)ptr })
+#define const_guest_handle_from_ptr(ptr, type)  \
+    ((XEN_GUEST_HANDLE(const_##type)) { (const type *)ptr })
+
+/*
+ * Copy an array of objects to guest context via a guest handle,
+ * specifying an offset into the guest array.
+ */
+#define copy_to_guest_offset(hnd, off, ptr, nr) ({      \
+    const typeof(*(ptr)) *_s = (ptr);                   \
+    char (*_d)[sizeof(*_s)] = (void *)(hnd).p;          \
+    ((void)((hnd).p == (ptr)));                         \
+    raw_copy_to_guest(_d+(off), _s, sizeof(*_s)*(nr));  \
+})
+
+/*
+ * Copy an array of objects from guest context via a guest handle,
+ * specifying an offset into the guest array.
+ */
+#define copy_from_guest_offset(ptr, hnd, off, nr) ({    \
+    const typeof(*(ptr)) *_s = (hnd).p;                 \
+    typeof(*(ptr)) *_d = (ptr);                         \
+    raw_copy_from_guest(_d, _s+(off), sizeof(*_d)*(nr));\
+})
+
+/* Copy sub-field of a structure to guest context via a guest handle. */
+#define copy_field_to_guest(hnd, ptr, field) ({         \
+    const typeof(&(ptr)->field) _s = &(ptr)->field;     \
+    void *_d = &(hnd).p->field;                         \
+    ((void)(&(hnd).p->field == &(ptr)->field));         \
+    raw_copy_to_guest(_d, _s, sizeof(*_s));             \
+})
+
+/* Copy sub-field of a structure from guest context via a guest handle. */
+#define copy_field_from_guest(ptr, hnd, field) ({       \
+    const typeof(&(ptr)->field) _s = &(hnd).p->field;   \
+    typeof(&(ptr)->field) _d = &(ptr)->field;           \
+    raw_copy_from_guest(_d, _s, sizeof(*_d));           \
+})
+
+/*
+ * Pre-validate a guest handle.
+ * Allows use of faster __copy_* functions.
+ */
+#define guest_handle_okay(hnd, nr)                      \
+    (paging_mode_external(current->domain) ||           \
+     array_access_ok((hnd).p, (nr), sizeof(*(hnd).p)))
+#define guest_handle_subrange_okay(hnd, first, last)    \
+    (paging_mode_external(current->domain) ||           \
+     array_access_ok((hnd).p + (first),                 \
+                     (last)-(first)+1,                  \
+                     sizeof(*(hnd).p)))
+
+#define __copy_to_guest_offset(hnd, off, ptr, nr) ({    \
+    const typeof(*(ptr)) *_s = (ptr);                   \
+    char (*_d)[sizeof(*_s)] = (void *)(hnd).p;          \
+    ((void)((hnd).p == (ptr)));                         \
+    __raw_copy_to_guest(_d+(off), _s, sizeof(*_s)*(nr));\
+})
+
+#define __copy_from_guest_offset(ptr, hnd, off, nr) ({  \
+    const typeof(*(ptr)) *_s = (hnd).p;                 \
+    typeof(*(ptr)) *_d = (ptr);                         \
+    __raw_copy_from_guest(_d, _s+(off), sizeof(*_d)*(nr));\
+})
+
+#define __copy_field_to_guest(hnd, ptr, field) ({       \
+    const typeof(&(ptr)->field) _s = &(ptr)->field;     \
+    void *_d = &(hnd).p->field;                         \
+    ((void)(&(hnd).p->field == &(ptr)->field));         \
+    __raw_copy_to_guest(_d, _s, sizeof(*_s));           \
+})
+
+#define __copy_field_from_guest(ptr, hnd, field) ({     \
+    const typeof(&(ptr)->field) _s = &(hnd).p->field;   \
+    typeof(&(ptr)->field) _d = &(ptr)->field;           \
+    __raw_copy_from_guest(_d, _s, sizeof(*_d));         \
+})
+
+#endif
diff --git a/xen/include/asm-arm/hardirq.h b/xen/include/asm-arm/hardirq.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/hardirq.h
@@ -0,0 +1,20 @@
+#ifndef __ASM_HARDIRQ_H__
+#define __ASM_HARDIRQ_H__
+
+#include <xen/config.h>
+#include <xen/cache.h>
+
+typedef struct irq_cpu_stat {
+	unsigned long __softirq_pending;
+	unsigned long __local_irq_count;
+	unsigned long __nmi_count;
+} __cacheline_aligned irq_cpustat_t;
+
+#include <xen/irq_cpustat.h>    /* Standard mappings for irq_cpustat_t above */
+
+#define in_irq() 	(local_irq_count(smp_processor_id()) != 0)
+
+#define irq_enter()     (local_irq_count(smp_processor_id())++)
+#define irq_exit()      (local_irq_count(smp_processor_id())--)
+
+#endif
diff --git a/xen/include/asm-arm/hypercall.h b/xen/include/asm-arm/hypercall.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/hypercall.h
@@ -0,0 +1,100 @@
+#ifndef __ASM_ARM_HYPERCALL_H__
+#define __ASM_ARM_HYPERCALL_H__
+
+#include <public/physdev.h>
+#include <public/domctl.h> /* for arch_do_domctl */
+#include <xen/types.h>
+
+/*
+ * Both do_mmuext_op() and do_mmu_update():
+ * We steal the m.s.b. of the @count parameter to indicate whether this
+ * invocation of do_mmu_update() is resuming a previously preempted call.
+ */
+#define MMU_UPDATE_PREEMPTED          (~(~0U>>1))
+
+extern long
+do_event_channel_op_compat(
+    XEN_GUEST_HANDLE(evtchn_op_t) uop);
+
+extern long
+do_set_trap_table(
+    XEN_GUEST_HANDLE(const_trap_info_t) traps);
+
+extern int
+do_mmu_update(
+    XEN_GUEST_HANDLE(mmu_update_t) ureqs,
+    unsigned int count,
+    XEN_GUEST_HANDLE(uint) pdone,
+    unsigned int foreigndom);
+
+extern long
+do_stack_switch(
+    unsigned long ss,
+    unsigned long esp);
+
+extern long
+do_fpu_taskswitch(
+    int set);
+
+extern long
+do_set_debugreg(
+    int reg,
+    unsigned long value);
+
+extern unsigned long
+do_get_debugreg(
+    int reg);
+
+extern long
+do_update_descriptor(
+    u64 pa,
+    u64 desc);
+
+extern int
+do_update_va_mapping(
+    unsigned long va,
+    u64 val64,
+    unsigned long flags);
+
+extern long
+do_physdev_op(
+    int cmd, XEN_GUEST_HANDLE(void) arg);
+
+extern int
+do_update_va_mapping_otherdomain(
+    unsigned long va,
+    u64 val64,
+    unsigned long flags,
+    domid_t domid);
+
+extern int
+do_mmuext_op(
+    XEN_GUEST_HANDLE(mmuext_op_t) uops,
+    unsigned int count,
+    XEN_GUEST_HANDLE(uint) pdone,
+    unsigned int foreigndom);
+
+extern unsigned long
+do_iret(
+    void);
+
+struct vcpu;
+extern long
+arch_do_vcpu_op(
+    int cmd, struct vcpu *v, XEN_GUEST_HANDLE(void) arg);
+
+extern long
+arch_do_domctl(
+    struct xen_domctl *domctl,
+    XEN_GUEST_HANDLE(xen_domctl_t) u_domctl);
+
+extern int
+do_kexec(
+    unsigned long op, unsigned arg1, XEN_GUEST_HANDLE(void) uarg);
+
+extern long
+do_set_callbacks(
+    unsigned long event_address,
+    unsigned long failsafe_address);
+
+#endif
diff --git a/xen/include/asm-arm/init.h b/xen/include/asm-arm/init.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/init.h
@@ -0,0 +1,4 @@
+#ifndef __ARM_INIT_H__
+#define __ARM_INIT_H__
+
+#endif /* _XEN_ASM_INIT_H */
diff --git a/xen/include/asm-arm/io.h b/xen/include/asm-arm/io.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/io.h
@@ -0,0 +1,92 @@
+#ifndef __ASM_ARM_IO_H
+#define __ASM_ARM_IO_H
+
+#include <asm/page.h>
+
+/*
+ * Generic IO read/write.  These perform native-endian accesses.  Note
+ * that some architectures will want to re-define __raw_{read,write}w.
+ */
+extern void __raw_writesb(void __iomem *addr, const void *data, int bytelen);
+extern void __raw_writesw(void __iomem *addr, const void *data, int wordlen);
+extern void __raw_writesl(void __iomem *addr, const void *data, int longlen);
+
+extern void __raw_readsb(void __iomem *addr, void *data, int bytelen);
+extern void __raw_readsw(void __iomem *addr, void *data, int wordlen);
+extern void __raw_readsl(void __iomem *addr, void *data, int longlen);
+
+/*
+ * Overriding the raw address access macros.
+ */
+#define __raw_writeb(v,a)	(*(volatile unsigned char *)(a) = (v))
+#define __raw_writew(v,a)	(*(volatile unsigned short *)(a) = (v))
+#define __raw_writel(v,a)	(*(volatile unsigned int *)(a) = (v))
+
+#define __raw_readb(a)		(*(volatile unsigned char *)(a))
+#define __raw_readw(a)		(*(volatile unsigned short *)(a))
+#define __raw_readl(a)		(*(volatile unsigned int *)(a))
+
+/*
+ * Now, pick up the machine-defined IO definitions
+ */
+#include <asm/plat/io.h>
+
+#define readb(c) 		({ unsigned int __v = __raw_readb(c); __v; })
+#define readw(c) 		({ unsigned int __v = le16_to_cpu(__raw_readw(c)); __v; })
+#define readl(c)		({ unsigned int __v = le32_to_cpu(__raw_readl(c)); __v; })
+#define readb_relaxed(addr) readb(addr)
+#define readw_relaxed(addr) readw(addr)
+#define readl_relaxed(addr) readl(addr)
+
+#define readsb(p,d,l)		__raw_readsb(p,d,l)
+#define readsw(p,d,l)		__raw_readsw(p,d,l)
+#define readsl(p,d,l)		__raw_readsl(p,d,l)
+
+#define writeb(v,c)		__raw_writeb(v,c)
+#define writew(v,c)		__raw_writew(cpu_to_le16(v),c)
+#define writel(v,c)		__raw_writel(cpu_to_le32(v),c)
+
+#define writesb(p,d,l)		__raw_writesb(p,d,l)
+#define writesw(p,d,l)		__raw_writesw(p,d,l)
+#define writesl(p,d,l)		__raw_writesl(p,d,l)
+
+/**
+ *  virt_to_phys    -   map virtual addresses to physical
+ *  @address: address to remap
+ *
+ *  The returned physical address is the physical (CPU) mapping for
+ *  the memory address given. It is only valid to use this function on
+ *  addresses directly mapped or allocated via xmalloc.
+ *
+ *  This function does not give bus mappings for DMA transfers. In
+ *  almost all conceivable cases a device driver should not be using
+ *  this function
+ */
+static inline unsigned long virt_to_phys(volatile void * address)
+{
+	return __pa(address);
+}
+/**
+ *  phys_to_virt    -   map physical address to virtual
+ *  @address: address to remap
+ *
+ *  The returned virtual address is a current CPU mapping for
+ *  the memory address given. It is only valid to use this function on
+ *  addresses that have a kernel mapping
+ *
+ *  This function does not handle bus mappings for DMA transfers. In
+ *  almost all conceivable cases a device driver should not be using
+ *  this function
+ */
+static inline void * phys_to_virt(unsigned long address)
+{
+	return __va(address);
+}
+
+/*
+ * Change "struct page_info" to physical address.
+ */
+#define page_to_pfn(_page)  ((unsigned long)((_page + min_page) - frame_table ))
+#define page_to_phys(page)  (page_to_pfn(page) << PAGE_SHIFT)
+
+#endif	/* __ASM_ARM_IO_H */
diff --git a/xen/include/asm-arm/iocap.h b/xen/include/asm-arm/iocap.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/iocap.h
@@ -0,0 +1,26 @@
+/******************************************************************************
+ * iocap.h
+ *
+ * Architecture-specific per-domain I/O capabilities.
+ */
+
+#ifndef __ARM_IOCAP_H__
+#define __ARM_IOCAP_H__
+
+#define ioports_permit_access(d, s, e)                  \
+    rangeset_add_range((d)->arch.ioport_caps, s, e)
+#define ioports_deny_access(d, s, e)                    \
+    rangeset_remove_range((d)->arch.ioport_caps, s, e)
+#define ioports_access_permitted(d, s, e)               \
+    rangeset_contains_range((d)->arch.ioport_caps, s, e)
+
+#define cache_flush_permitted(d)                        \
+	(!rangeset_is_empty((d)->iomem_caps) ||		\
+	 !rangeset_is_empty((d)->arch.ioport_caps))
+
+#define multipage_allocation_permitted(d, order)        \
+	(((order) == 0) ||				\
+	 !rangeset_is_empty((d)->iomem_caps) ||		\
+	 !rangeset_is_empty((d)->arch.ioport_caps))
+
+#endif /* __ARM_IOCAP_H__ */
diff --git a/xen/include/asm-arm/irq.h b/xen/include/asm-arm/irq.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/irq.h
@@ -0,0 +1,7 @@
+#ifndef _ARM_HW_IRQ_H
+#define _ARM_HW_IRQ_H
+
+struct irq_desc;
+extern struct irq_desc *irq_desc;
+
+#endif /* _ASM_HW_IRQ_H */
diff --git a/xen/include/asm-arm/linkage.h b/xen/include/asm-arm/linkage.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/linkage.h
@@ -0,0 +1,12 @@
+#ifndef __ASM_ARM_LINKAGE_H__
+#define __ASM_ARM_LINKAGE_H__
+
+#ifdef __ASSEMBLY__
+#define __ALIGN .align 0
+#define __ALIGN_STR ".align 0"
+#endif
+
+#define HYPERCALL_HANDLER	__attribute__((interrupt("SWI")))
+#define INTERRUPT_HANDLER	__attribute__((interrupt("IRQ")))
+#define NAKED				__attribute__((naked))
+#endif
diff --git a/xen/include/asm-arm/memmap.h b/xen/include/asm-arm/memmap.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/memmap.h
@@ -0,0 +1,130 @@
+/***************************************************************************
+ * include/xen-arm/memmap.h 
+ *
+ * system memory map (replacement of e820.h)
+ *
+ * sungkwan heo <sk.heo@samsung.com>
+ *
+ */
+
+#ifndef __XEN_ASM_MEMMAP_HEADER
+#define __XEN_ASM_MEMMAP_HEADER
+
+#include <asm/page.h>
+
+#define MEMMAP_ENTRY_MAX	16
+
+#define MEMMAP_DRAM		1
+#define MEMMAP_NOR		4
+#define MEMMAP_IO		16
+#define MEMEAP_XENSTORE		18
+
+#define MT_CACHECLEAN		0
+#define MT_VECTOR		1
+#define MT_RAM			2
+#define MT_ROM			3
+#define MT_IO			4
+
+#ifndef  __ASSEMBLY__
+
+struct map_desc {
+	unsigned long virtual;
+	unsigned long physical;
+	unsigned long length;
+	unsigned long type;
+};
+
+struct memmap_entry {
+  unsigned int	addr;
+  unsigned int	size;
+  unsigned int	type;
+};
+
+struct system_memmap {
+  int	nr_map;
+  struct memmap_entry map[MEMMAP_ENTRY_MAX];
+};
+
+extern unsigned long 	init_memmap(void);
+extern void		print_memmap(void);
+
+extern struct system_memmap memmap;
+
+#endif /* !__ASSEMBLY__ */
+
+#ifdef __ASSEMBLY__
+#define MAP_ENTRY(va, pa, size, attr)           \
+	.word   size                            ;\
+	.word   4 * ((va) >> 20)                ;\
+	.word   (pa) | (attr)                   ;
+#endif
+
+#define PFN_DOWN(x)	( (x)>> PAGE_SHIFT )
+#define PFN_UP(x)	( ((x)+PAGE_SIZE-1) >> PAGE_SHIFT )
+
+
+/*
+ *  Physical memory map 
+ */
+
+#define MEMMAP_XEN_START_PADDR				MEMMAP_DRAM_ADDR
+#define MEMMAP_XEN_SIZE					0x00200000		// 2MB
+#define MEMMAP_XEN_END_PADDR				(MEMMAP_XEN_START_PADDR + MEMMAP_XEN_SIZE)
+
+#define MEMMAP_GUEST_0_START_PADDR			MEMMAP_XEN_END_PADDR
+#define MEMMAP_GUEST_0_SIZE				(CONFIG_MEMMAP_GUEST_0_SIZE - MEMMAP_XEN_SIZE) // Dom0 size = size - xen size
+#define MEMMAP_GUEST_0_END_PADDR			(MEMMAP_GUEST_0_START_PADDR + MEMMAP_GUEST_0_SIZE)
+
+#define MEMMAP_GUEST_1_START_PADDR			MEMMAP_GUEST_0_END_PADDR
+#define MEMMAP_GUEST_1_SIZE				CONFIG_MEMMAP_GUEST_1_SIZE
+#define MEMMAP_GUEST_1_END_PADDR			(MEMMAP_GUEST_1_START_PADDR + MEMMAP_GUEST_1_SIZE)
+
+#define MEMMAP_GUEST_2_START_PADDR                      MEMMAP_GUEST_1_END_PADDR
+#define MEMMAP_GUEST_2_SIZE                             CONFIG_MEMMAP_GUEST_2_SIZE
+#define MEMMAP_GUEST_2_END_PADDR                        (MEMMAP_GUEST_2_START_PADDR + MEMMAP_GUEST_2_SIZE)
+
+#define MEMMAP_GUEST_3_START_PADDR                      MEMMAP_GUEST_2_END_PADDR
+#define MEMMAP_GUEST_3_SIZE                             CONFIG_MEMMAP_GUEST_3_SIZE
+#define MEMMAP_GUEST_3_END_PADDR                        (MEMMAP_GUEST_3_START_PADDR + MEMMAP_GUEST_3_SIZE)
+
+// when using ramfs
+#define MEMMAP_GUEST_0_ELF_MAX_SIZE		        CONFIG_MEMMAP_GUEST_0_ELF_MAX_SIZE
+#define MEMMAP_GUEST_1_ELF_MAX_SIZE		        CONFIG_MEMMAP_GUEST_1_ELF_MAX_SIZE
+#define MEMMAP_GUEST_2_ELF_MAX_SIZE		        CONFIG_MEMMAP_GUEST_2_ELF_MAX_SIZE
+#define MEMMAP_GUEST_3_ELF_MAX_SIZE		        CONFIG_MEMMAP_GUEST_3_ELF_MAX_SIZE
+
+// when using ramdisk
+#define MEMMAP_GUEST_0_RAMDISK_SIZE	                CONFIG_MEMMAP_GUEST_0_RAMDISK_SIZE	
+#define MEMMAP_GUEST_1_RAMDISK_SIZE		        CONFIG_MEMMAP_GUEST_1_RAMDISK_SIZE
+#define MEMMAP_GUEST_2_RAMDISK_SIZE		        CONFIG_MEMMAP_GUEST_2_RAMDISK_SIZE
+#define MEMMAP_GUEST_3_RAMDISK_SIZE		        CONFIG_MEMMAP_GUEST_3_RAMDISK_SIZE
+
+
+#ifndef XEN_GUEST_IMAGES_IN_FLASH			
+	#define MEMMAP_XEN_BIN_IMAGE_PADDR			(MEMMAP_DRAM_ADDR + 0x00008000)
+	#define MEMMAP_GUEST_0_ELF_IMAGE_PADDR		(MEMMAP_GUEST_0_END_PADDR       - MEMMAP_GUEST_0_ELF_MAX_SIZE)
+	#define MEMMAP_GUEST_0_RAMDISK_IMAGE_PADDR	(MEMMAP_GUEST_0_ELF_IMAGE_PADDR - MEMMAP_GUEST_0_RAMDISK_SIZE)
+	#define MEMMAP_GUEST_1_ELF_IMAGE_PADDR		(MEMMAP_GUEST_1_END_PADDR       - MEMMAP_GUEST_1_ELF_MAX_SIZE)
+	#define MEMMAP_GUEST_1_RAMDISK_IMAGE_PADDR	(MEMMAP_GUEST_1_ELF_IMAGE_PADDR - MEMMAP_GUEST_1_RAMDISK_SIZE)
+        #define MEMMAP_GUEST_2_ELF_IMAGE_PADDR          (MEMMAP_GUEST_2_END_PADDR       - MEMMAP_GUEST_2_ELF_MAX_SIZE)
+        #define MEMMAP_GUEST_2_RAMDISK_IMAGE_PADDR      (MEMMAP_GUEST_2_ELF_IMAGE_PADDR - MEMMAP_GUEST_2_RAMDISK_SIZE)
+        #define MEMMAP_GUEST_3_ELF_IMAGE_PADDR          (MEMMAP_GUEST_3_END_PADDR       - MEMMAP_GUEST_3_ELF_MAX_SIZE)
+        #define MEMMAP_GUEST_3_RAMDISK_IMAGE_PADDR      (MEMMAP_GUEST_3_ELF_IMAGE_PADDR - MEMMAP_GUEST_3_RAMDISK_SIZE)
+
+#else
+	#define MEMMAP_NOR_FLASH_BASE_PADDR			MEMMAP_NOR_ADDR
+	/* NOR  -  blob: 16KB,   param: 16KB,   xen: 432KB,   dom0: 1536KB,   root fs: 30MB */
+	/* NAND -  dom1: 2048KB, root fs: 30MB, dom2: 2048KB, root fs: 30MB */
+	#define MEMMAP_BLOB_PADDR					(MEMMAP_NOR_FLASH_BASE_PADDR + 0x00000000)	
+	#define MEMMAP_BLOB_PARAM_PADDR				(MEMMAP_NOR_FLASH_BASE_PADDR + 0x00010000)
+	#define MEMMAP_XEN_BIN_IMAGE_PADDR			(MEMMAP_NOR_FLASH_BASE_PADDR + 0x00014000)
+	#define MEMMAP_GUEST_0_ELF_IMAGE_PADDR		(MEMMAP_NOR_FLASH_BASE_PADDR + 0x00080000)
+	#define MEMMAP_GUEST_0_RAMDISK_IMAGE_PADDR	(MEMMAP_NOR_FLASH_BASE_PADDR + 0x00200000)
+	#define MEMMAP_GUEST_1_ELF_IMAGE_PADDR		// undefined 
+	#define MEMMAP_GUEST_1_RAMDISK_IMAGE_PADDR	// undefined
+#endif /* XEN_GUEST_IMAGES_IN_FLASH */
+
+
+#endif /* !__XEN_ASM_MEMMAP_HEADER */
+
+
diff --git a/xen/include/asm-arm/memory.h b/xen/include/asm-arm/memory.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/memory.h
@@ -0,0 +1,41 @@
+#ifndef __ASM_MEMORY_H__
+#define __ASM_MEMORY_H__
+
+#include <asm/config.h>
+
+#ifdef ARCH_NR_BANKS
+#define NR_BANKS	ARCH_NR_BANKS
+#else
+#define NR_BANKS	4
+#endif
+
+struct memory_bank {
+	unsigned long	base;
+	unsigned long	size;
+	int		node;
+};
+
+
+struct meminfo {
+	unsigned long nr_banks;
+	struct memory_bank banks[NR_BANKS];
+};
+
+extern struct meminfo system_memory;
+void register_memory_bank(unsigned long base, unsigned long size);
+
+static inline void consistent_write(void *ptr, unsigned long value)
+{
+	__asm__ __volatile__(
+			"str        %1, [%0]                								\n"
+			"nop																\n"
+			"bic		%0, %0, #0x1f											\n"
+			"mcr        p15, 0, %0, c7, c10, 1		@ clean D entry				\n"
+			"mcr        p15, 0, %2, c7, c10, 4  	@ drain WB					\n"
+			:
+			: "r"(ptr), "r"(value), "r"(0)
+			: "memory");
+}
+
+#endif
+
diff --git a/xen/include/asm-arm/mm.h b/xen/include/asm-arm/mm.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/mm.h
@@ -0,0 +1,300 @@
+/*
+ * mm.h
+ *
+ * Copyright (C) 2008 Samsung Electronics
+ *          JaeMin Ryu  <jm77.ryu@samsung.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public version 2 of License as published by
+ * the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef __ARM_MM_H__
+#define __ARM_MM_H__
+
+#include <xen/cpumask.h>
+#include <xen/list.h>
+#include <asm/system.h>
+#include <asm/io.h>
+#include <asm/types.h>
+#include <asm/pgtable.h>
+#include <asm/page.h>
+#include <asm/tlb.h>
+#include <asm/config.h>
+#include <asm/atomic.h>
+#include <asm/page.h>
+#include <asm/cpu-ops.h>
+#include <asm/cpu-domain.h>
+#include <asm/domain.h>
+#include <public/xen.h>
+
+extern unsigned long xenheap_phys_end;
+
+#undef  machine_to_phys_mapping
+#define machine_to_phys_mapping  ((unsigned long *)RDWR_MPT_VIRT_START)
+#define INVALID_MFN             (~0UL)
+#define INVALID_M2P_ENTRY		(~0UL)
+#define VALID_M2P(_e)            (!((_e) & (1UL<<(BITS_PER_LONG-1))))
+#define SHARED_M2P_ENTRY         (~0UL - 1UL)
+#define SHARED_M2P(_e)           ((_e) == SHARED_M2P_ENTRY)
+
+#define PFN_ORDER(_pfn)			((_pfn)->u.free.order)
+
+#define PAGE_TYPE(page)			(((page)->u.inuse.type_info) & PGT_type_mask )
+
+#define PRtype_info				"08lx"
+
+#define page_get_owner(_p)                                              \
+    ((struct domain *)((_p)->u.inuse._domain ?                          \
+                       pdx_to_virt((_p)->u.inuse._domain) : NULL))
+#define page_set_owner(_p,_d)                                           \
+    ((_p)->u.inuse._domain = (_d) ? virt_to_pdx(_d) : 0)
+
+#define XENSHARE_writable 		0
+#define XENSHARE_readonly 		1
+
+#define set_gpfn_from_mfn(mfn, pfn) do { } while(0)
+#define get_gpfn_from_mfn(mfn)      ((mfn))
+
+#define mfn_to_gmfn(_d, mfn)	(mfn)
+
+#define gmfn_to_mfn(_d, gpfn)	(gpfn)
+
+#define write_ptbase(v)		cpu_switch_ttb((v)->arch.guest_table, 1);
+
+#define IS_XEN_HEAP_FRAME(_pfn) (page_to_phys(_pfn) < xenheap_phys_end)
+
+typedef unsigned int __pdx_t;
+
+/*
+ * Per-page-frame information.
+ *
+ * Every architecture must ensure the following:
+ *  1. 'struct page_info' contains a 'struct list_head list'.
+ *  2. Provide a PFN_ORDER() macro for accessing the order of a free page.
+ */
+struct page_info
+{
+    /* Each frame can be threaded onto a doubly-linked list. */
+    struct page_list_entry list;
+
+    /* Reference count and various PGC_xxx flags and fields. */
+    u32 count_info;
+
+    /* Context-dependent fields follow... */
+    union {
+
+        /* Page is in use: ((count_info & PGC_count_mask) != 0). */
+        struct {
+            /* Type reference count and various PGT_xxx flags and fields. */
+            unsigned long type_info;
+
+            /* Owner of this page (NULL if page is anonymous). */
+            __pdx_t _domain;
+        } inuse;
+
+        /* Page is on a free list: ((count_info & PGC_count_mask) == 0). */
+        struct {
+            /* Order-size of the free chunk this page is the head of. */
+            u32 order;
+
+            /* Do TLBs need flushing for safety before next page use? */
+	    bool_t need_tlbflush;
+        } free;
+    } u;
+
+    /* Timestamp from 'TLB clock', used to reduce need for safety flushes. */
+    u32 tlbflush_timestamp;
+};
+
+#define set_page_count(p,v) 	atomic_set(&(p)->_count, v - 1)
+
+/*
+ * Still small set of flags defined by far on ARM.
+ */
+#define PG_shift(idx)   (BITS_PER_LONG - (idx))
+#define PG_mask(x, idx) (x ## UL << PG_shift(idx))
+
+/* The following page types are MUTUALLY EXCLUSIVE. */
+#define PGT_none          PG_mask(0, 3) /* no special uses of this page */
+#define PGT_l1_page_table PG_mask(1, 3) /* using as an L1 page table? */
+#define PGT_l2_page_table PG_mask(2, 3) /* using as an L2 page table? */
+#define PGT_l3_page_table PG_mask(3, 3) /* using as an L3 page table? */
+#define PGT_l4_page_table PG_mask(4, 3) /* using as an L4 page table? */
+ /* Value 5 reserved. See asm-x86/mm.h */
+ /* Value 6 reserved. See asm-x86/mm.h */
+#define PGT_writable_page PG_mask(7, 3) /* has writable mappings? */
+#define PGT_type_mask     PG_mask(7, 3) /* Bits 29-31. */
+
+ /* Owning guest has pinned this page to its current type? */
+#define _PGT_pinned       PG_shift(4)
+#define PGT_pinned        PG_mask(1, 4)
+ /* Has this page been validated for use as its current type? */
+#define _PGT_validated    PG_shift(5)
+#define PGT_validated     PG_mask(1, 5)
+
+ /* Count of uses of this frame as its current type. */
+#define PGT_count_width   PG_shift(7)
+#define PGT_count_mask    ((1UL<<PGT_count_width)-1)
+
+ /* Cleared when the owning guest 'frees' this page. */
+#define _PGC_allocated    PG_shift(1)
+#define PGC_allocated     PG_mask(1, 1)
+ /* Page is Xen heap? */
+# define _PGC_xen_heap    PG_shift(2)
+# define PGC_xen_heap     PG_mask(1, 2)
+ /* bit PG_shift(3) reserved. See asm-x86/mm.h */
+ /* PG_mask(7, 6) reserved. See asm-x86/mm.h*/
+
+ /* Page is broken? */
+#define _PGC_broken       PG_shift(7)
+#define PGC_broken        PG_mask(1, 7)
+
+ /* Mutually-exclusive page states: { inuse, offlining, offlined, free }. */
+#define PGC_state         PG_mask(3, 9)
+#define PGC_state_inuse   PG_mask(0, 9)
+#define PGC_state_offlining PG_mask(1, 9)
+#define PGC_state_offlined PG_mask(2, 9)
+#define PGC_state_free    PG_mask(3, 9)
+#define page_state_is(pg, st) (((pg)->count_info&PGC_state) == PGC_state_##st)
+
+ /* Count of references to this frame. */
+#define PGC_count_width   PG_shift(9)
+#define PGC_count_mask    ((1UL<<PGC_count_width)-1)
+
+#ifdef MEMORY_GUARD
+void *memguard_init(void *heap_start);
+void memguard_guard_stack(void *p);
+void memguard_guard_range(void *p, unsigned long l);
+void memguard_unguard_range(void *p, unsigned long l);
+#else
+#define memguard_init(_s)              (_s)
+#define memguard_guard_stack(_p)       ((void)0)
+#define memguard_guard_range(_p,_l)    ((void)0)
+#define memguard_unguard_range(_p,_l)  ((void)0)
+#endif /* MEMORY_GUARD */
+
+#define frame_table ((struct page_info *) FRAMETABLE_VIRT_START)
+
+static inline struct page_info *__virt_to_page(const void *v)
+{
+	unsigned long va = (unsigned long) v;
+
+	ASSERT(va - DIRECTMAP_VIRT_START < DIRECTMAP_VIRT_END);
+	return frame_table + ((va - DIRECTMAP_VIRT_START) >> PAGE_SHIFT);
+}
+
+static inline void *__page_to_virt(const struct page_info *pg)
+{
+    ASSERT((unsigned long)pg - FRAMETABLE_VIRT_START < FRAMETABLE_VIRT_END);
+    return (void *)(DIRECTMAP_VIRT_START +
+                    ((unsigned long)pg - FRAMETABLE_VIRT_START) /
+                    (sizeof(*pg) / (sizeof(*pg) & -sizeof(*pg))) *
+                    (PAGE_SIZE / (sizeof(*pg) & -sizeof(*pg))));
+}
+
+#define is_xen_heap_page(page) is_xen_heap_mfn(page_to_mfn(page))
+#define is_xen_heap_mfn(mfn) ({                         \
+    unsigned long _mfn = (mfn);                         \
+    (_mfn < paddr_to_pfn(xenheap_phys_end));            \
+})
+#define is_xen_fixed_mfn(mfn) is_xen_heap_mfn(mfn)
+
+extern pde_t *idle_pgd;
+
+extern unsigned long min_page, max_page;
+extern unsigned long total_pages;
+
+void init_frametable(void);
+
+void share_xen_page_with_guest(struct page_info *page, struct domain *d, int readonly);
+void share_xen_page_with_privileged_guests(struct page_info *page, int readonly);
+
+int alloc_page_type(struct page_info *page, unsigned long type);
+void free_page_type(struct page_info *page, unsigned long type);
+
+void zap_low_mappings(pde_t *base);
+void arch_init_memory(void);
+void paging_init(void);
+
+struct domain *page_get_owner_and_reference(struct page_info *page);
+
+int get_page(struct page_info *page, struct domain *domain);
+void put_page(struct page_info *page);
+void put_page_type(struct page_info *page);
+int  get_page_type(struct page_info *page, unsigned long type);
+
+static inline void put_page_and_type(struct page_info *page)
+{
+    put_page_type(page);
+    put_page(page);
+}
+
+static inline int get_page_and_type(struct page_info *page,
+                                    struct domain *domain,
+                                    unsigned long type)
+{
+    int rc = get_page(page, domain);
+
+    if ( likely(rc) && unlikely(!get_page_type(page, type)) )
+    {
+        put_page(page);
+        rc = 0;
+    }
+
+    return rc;
+}
+
+#ifndef NDEBUG
+#define TYPE_SAFETY 1
+#endif
+
+#ifdef TYPE_SAFETY
+#define TYPE_SAFE(_type,_name)                                  \
+typedef struct { _type _name; } _name##_t;                      \
+static inline _name##_t _##_name(_type n) { return (_name##_t) { n }; } \
+static inline _type _name##_x(_name##_t n) { return n._name; }
+#else
+#define TYPE_SAFE(_type,_name)                                          \
+typedef _type _name##_t;                                                \
+static inline _name##_t _##_name(_type n) { return n; }                 \
+static inline _type _name##_x(_name##_t n) { return n; }
+#endif
+
+TYPE_SAFE(unsigned long,mfn);
+
+/* Macro for printk formats: use as printk("%"PRI_mfn"\n", mfn_x(foo)); */
+#define PRI_mfn "05lx"
+
+extern struct domain *dom_xen, *dom_io, *dom_cow;	/* for vmcoreinfo */
+int is_iomem_page(unsigned long mfn);
+
+int steal_page(
+    struct domain *d, struct page_info *page, unsigned int memflags);
+int donate_page(
+    struct domain *d, struct page_info *page, unsigned int memflags);
+
+#define domain_clamp_alloc_bitsize(d, b) (b)
+
+unsigned long domain_get_maximum_gpfn(struct domain *d);
+
+int guest_physmap_mark_populate_on_demand(struct domain *d, unsigned long gfn,
+                                          unsigned int order);
+
+int
+p2m_pod_decrease_reservation(struct domain *d,
+                             xen_pfn_t gpfn, unsigned int order);
+
+/* Arch-specific portion of memory_op hypercall. */
+long arch_memory_op(int op, XEN_GUEST_HANDLE(void) arg);
+
+#endif /* __ASM_MM_H__ */
diff --git a/xen/include/asm-arm/multicall.h b/xen/include/asm-arm/multicall.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/multicall.h
@@ -0,0 +1,6 @@
+#ifndef __ASM_ARM_MULTICALL_H__
+#define __ASM_ARM_MULTICALL_H__
+
+#define do_multicall_call(_call)
+
+#endif /* __ASM_ARM_MULTICALL_H__ */
diff --git a/xen/include/asm-arm/nmi.h b/xen/include/asm-arm/nmi.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/nmi.h
@@ -0,0 +1,7 @@
+#ifndef ASM_NMI_H
+#define ASM_NMI_H
+
+#define register_guest_nmi_callback(a)  (-ENOSYS)
+#define unregister_guest_nmi_callback() (-ENOSYS)
+
+#endif /* ASM_NMI_H */
diff --git a/xen/include/asm-arm/numa.h b/xen/include/asm-arm/numa.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/numa.h
@@ -0,0 +1,45 @@
+#ifndef _ASM_ARM_NUMA_H
+#define _ASM_ARM_NUMA_H
+
+#include <xen/cpumask.h>
+
+extern cpumask_t node_to_cpumask[];
+extern unsigned char cpu_to_node[];
+
+#define cpu_to_node(cpu)		(cpu_to_node[cpu])
+#define parent_node(node)		(node)
+#define node_to_first_cpu(node)  (__ffs(node_to_cpumask[node]))
+#define node_to_cpumask(node)    (node_to_cpumask[node])
+
+/* Simple perfect hash to map pdx to node numbers */
+extern int memnode_shift;
+extern unsigned long memnodemapsize;
+extern u8 *memnodemap;
+
+struct node_data {
+    unsigned long node_start_pfn;
+    unsigned long node_spanned_pages;
+    unsigned int  node_id;
+};
+
+extern struct node_data node_data[];
+
+#define VIRTUAL_BUG_ON(x)
+
+static inline __attribute__((pure)) int phys_to_nid(paddr_t addr)
+{
+	unsigned nid;
+	VIRTUAL_BUG_ON((paddr_to_pdx(addr) >> memnode_shift) >= memnodemapsize);
+	nid = memnodemap[paddr_to_pdx(addr) >> memnode_shift];
+	VIRTUAL_BUG_ON(nid >= MAX_NUMNODES || !node_data[nid]);
+	return nid;
+}
+
+#define NODE_DATA(nid)		(&(node_data[nid]))
+
+#define node_start_pfn(nid)	(NODE_DATA(nid)->node_start_pfn)
+#define node_spanned_pages(nid)	(NODE_DATA(nid)->node_spanned_pages)
+#define node_end_pfn(nid)       (NODE_DATA(nid)->node_start_pfn + \
+				 NODE_DATA(nid)->node_spanned_pages)
+
+#endif
diff --git a/xen/include/asm-arm/p2m.h b/xen/include/asm-arm/p2m.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/p2m.h
@@ -0,0 +1,55 @@
+/******************************************************************************
+ * include/asm-x86/paging.h
+ *
+ * physical-to-machine mappings for automatically-translated domains.
+ *
+ * Copyright (c) 2007 Advanced Micro Devices (Wei Huang)
+ * Parts of this code are Copyright (c) 2006-2007 by XenSource Inc.
+ * Parts of this code are Copyright (c) 2006 by Michael A Fetterman
+ * Parts based on earlier work by Michael A Fetterman, Ian Pratt et al.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef _XEN_P2M_H
+#define _XEN_P2M_H
+
+#include <xen/config.h>
+#include <xen/paging.h>
+#include <asm/page.h>    /* for pagetable_t */
+
+/* Scan pod cache when offline/broken page triggered */
+static inline int
+p2m_pod_offline_or_broken_hit(struct page_info *p)
+{
+    return 0;
+}
+
+/* Replace pod cache when offline/broken page triggered */
+static inline void
+p2m_pod_offline_or_broken_replace(struct page_info *p)
+{
+}
+
+#endif /* _XEN_P2M_H */
+
+/*
+ * Local variables:
+ * mode: C
+ * c-set-style: "BSD"
+ * c-basic-offset: 4
+ * indent-tabs-mode: nil
+ * End:
+ */
diff --git a/xen/include/asm-arm/page.h b/xen/include/asm-arm/page.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/page.h
@@ -0,0 +1,114 @@
+#ifndef __ARM_PAGE_H__
+#define __ARM_PAGE_H__
+
+#include <asm/config.h>
+#include <asm/types.h>
+#include <asm/pgtable.h>
+
+/*
+ * It is important that the masks are signed quantities. This ensures that
+ * the compiler sign-extends a 32-bit mask to 64 bits if that is required.
+ */
+#define PAGE_SHIFT		12
+#ifndef __ASSEMBLY__
+#define PAGE_SIZE           (1L << PAGE_SHIFT)
+#else
+#define PAGE_SIZE           (1 << PAGE_SHIFT)
+#endif
+#define PAGE_MASK           (~(PAGE_SIZE-1))
+#define PAGE_FLAG_MASK      (~0)
+
+#define PAGE_ALIGN(x) (((x) + PAGE_SIZE - 1) & PAGE_MASK)
+
+#ifndef __ASSEMBLY__
+#include <asm/types.h>
+#include <xen/lib.h>
+
+static inline unsigned long __virt_to_maddr(unsigned long va)
+{
+    ASSERT(va >= DIRECTMAP_VIRT_START && va < DIRECTMAP_VIRT_END);
+    return va - DIRECTMAP_VIRT_START;
+}
+
+static inline void *__maddr_to_virt(unsigned long ma)
+{
+    ASSERT(ma < DIRECTMAP_VIRT_END - DIRECTMAP_VIRT_START);
+    return (void *)(ma + DIRECTMAP_VIRT_START);
+}
+
+#define clear_page(_p)      (void) memset((void *)(_p), 0, PAGE_SIZE)
+#define copy_page(_t,_f)    (void) memcpy(_t, _f, PAGE_SIZE))
+
+/* Convert between Xen-heap virtual addresses and machine addresses. */
+#define __pa(x)             (virt_to_maddr(x))
+#define __va(x)             (maddr_to_virt(x))
+
+/* Convert between Xen-heap virtual addresses and machine frame numbers. */
+#define __virt_to_mfn(va)   (virt_to_maddr(va) >> PAGE_SHIFT)
+#define __mfn_to_virt(mfn)  (maddr_to_virt((paddr_t)(mfn) << PAGE_SHIFT))
+
+/* Convert between machine frame numbers and page-info structures. */
+#define __mfn_to_page(mfn)  (frame_table + pfn_to_pdx(mfn))
+#define __page_to_mfn(pg)   pdx_to_pfn((unsigned long)((pg) - frame_table))
+
+/* Convert between machine addresses and page-info structures. */
+#define __maddr_to_page(ma) __mfn_to_page((ma) >> PAGE_SHIFT)
+#define __page_to_maddr(pg) ((paddr_t)__page_to_mfn(pg) << PAGE_SHIFT)
+
+/* Convert between frame number and address formats.  */
+#define __pfn_to_paddr(pfn) ((paddr_t)(pfn) << PAGE_SHIFT)
+#define __paddr_to_pfn(pa)  ((unsigned long)((pa) >> PAGE_SHIFT))
+
+#define mfn_valid(mfn)      (((mfn) >= min_page) && ((mfn) <= max_page))
+#define virt_to_mfn(va)     __virt_to_mfn(va)
+#define mfn_to_virt(mfn)    __mfn_to_virt(mfn)
+#define virt_to_maddr(va)   __virt_to_maddr((unsigned long)(va))
+#define maddr_to_virt(ma)   __maddr_to_virt((unsigned long)(ma))
+#define mfn_to_page(mfn)    __mfn_to_page(mfn)
+#define page_to_mfn(pg)     __page_to_mfn(pg)
+#define maddr_to_page(ma)   __maddr_to_page(ma)
+#define page_to_maddr(pg)   __page_to_maddr(pg)
+#define virt_to_page(va)    __virt_to_page(va)
+#define page_to_virt(pg)    __page_to_virt(pg)
+#define pfn_to_paddr(pfn)   __pfn_to_paddr(pfn)
+#define paddr_to_pfn(pa)    __paddr_to_pfn(pa)
+#define paddr_to_pdx(pa)    pfn_to_pdx(paddr_to_pfn(pa))
+
+#define max_pdx                 max_page
+#define pfn_to_pdx(pfn)         (pfn)
+#define pdx_to_pfn(pdx)         (pdx)
+
+#define virt_to_pdx(va)         virt_to_mfn(va)
+#define pdx_to_virt(pdx)        mfn_to_virt(pdx)
+
+static inline int get_order_from_bytes(paddr_t size)
+{
+    int order;
+    size = (size-1) >> PAGE_SHIFT;
+    for ( order = 0; size; order++ )
+        size >>= 1;
+    return order;
+}
+
+static inline int get_order_from_pages(unsigned long nr_pages)
+{
+    int order;
+    nr_pages--;
+    for ( order = 0; nr_pages; order++ )
+        nr_pages >>= 1;
+    return order;
+}
+
+typedef struct { u32 pfn; } pagetable_t;
+
+typedef u64 intpte_t;
+#define PRIpte "016llx"
+
+typedef struct { intpte_t l1; } l1_pgentry_t;
+typedef struct { intpte_t l2; } l2_pgentry_t;
+typedef struct { intpte_t l3; } l3_pgentry_t;
+typedef l3_pgentry_t root_pgentry_t;
+
+#endif /* !defined(__ASSEMBLY__) */
+
+#endif /* __ARM_PAGE_H__ */
diff --git a/xen/include/asm-arm/percpu.h b/xen/include/asm-arm/percpu.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/percpu.h
@@ -0,0 +1,23 @@
+#ifndef __ARM_PERCPU_H__
+#define __ARM_PERCPU_H__
+
+#ifndef __ASSEMBLY__
+extern char __per_cpu_start[], __per_cpu_data_end[];
+extern unsigned long __per_cpu_offset[NR_CPUS];
+void percpu_init_areas(void);
+#endif
+
+/* Separate out the type, so (int[3], foo) works. */
+#define __DEFINE_PER_CPU(type, name, suffix)                    \
+    __attribute__((__section__(".bss.percpu" #suffix)))         \
+    __typeof__(type) per_cpu_##name
+
+/* var is in discarded region: offset to particular copy we want */
+#define per_cpu(var, cpu)  \
+    (*RELOC_HIDE(&per_cpu__##var, __per_cpu_offset[cpu]))
+#define __get_cpu_var(var) \
+    (*RELOC_HIDE(&per_cpu__##var, get_cpu_info()->per_cpu_offset))
+
+#define DECLARE_PER_CPU(type, name) extern __typeof__(type) per_cpu__##name
+
+#endif /* __ARM_PERCPU_H__ */
diff --git a/xen/include/asm-arm/pgtable.h b/xen/include/asm-arm/pgtable.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/pgtable.h
@@ -0,0 +1,135 @@
+#ifndef __ARM_PGTABLE_H__
+#define __ARM_PGTABLE_H__
+
+#include <asm/cpu-domain.h>
+
+#define PDE_FLAG_MASK			(0x3FF)
+
+#define PDE_TYPE_FAULT          (0x10)
+#define PDE_TYPE_COARSE         (0x11)
+#define PDE_TYPE_SECTION        (0x12)
+#define PDE_TYPE_FINE           (0x13)
+#define PDE_TYPE_MASK			(0x03)
+
+#define PDE_BIT4				(1 << 4)
+
+#define PDE_AP_SRW_UNO          (0x01 << 10)
+#define PDE_AP_SRW_URO          (0x02 << 10)
+#define PDE_AP_SRW_URW          (0x03 << 10)
+
+#define PDE_BUFFERABLE			(0x04)
+#define PDE_CACHEABLE			(0x08)
+
+#define PDE_WRITEBACK			(PDE_CACHEABLE | PDE_BUFFERABLE)
+#define PDE_WRITETHROUGH		(PDE_CACHEABLE)
+#define PDE_SHARED				(0)
+
+#define PDE_DOMAIN_HYPERVISOR   (DOMAIN_HYPERVISOR << 5)
+#define PDE_DOMAIN_SUPERVISOR	(DOMAIN_SUPERVISOR << 5)
+#define PDE_DOMAIN_USER         (DOMAIN_USER << 5)
+#define PDE_DOMAIN_IO           (DOMAIN_IO << 5)
+
+#define PDE_TYPE_HYPERVISOR		(PDE_TYPE_SECTION | PDE_DOMAIN_HYPERVISOR | PDE_AP_SRW_UNO | PDE_WRITEBACK)
+#define PDE_TYPE_IO				(PDE_TYPE_SECTION | PDE_DOMAIN_IO | PDE_AP_SRW_URW)
+
+/*
+ * Definition for Page Table Entries
+ */
+
+#define PTE_FLAG_MASK			(0xFFF)
+
+#define PTE_TYPE_FAULT          (0x00)
+#define PTE_TYPE_LARGE          (0x01)
+#define PTE_TYPE_SMALL          (0x02)
+#define PTE_TYPE_TINY           (0x03)
+#define PTE_TYPE_EXT			(0x03)
+
+#define PTE_TYPE_MASK			(0x03)
+
+#define PTE_BUFFERABLE          (0x04)
+#define PTE_CACHEABLE           (0x08)
+
+#define SECTION_SHIFT			(20)
+#define SECTION_SIZE            (1 << SECTION_SHIFT)
+#define SECTION_MASK			(~(SECTION_SIZE - 1))
+
+#define PGD_SHIFT               (20)
+#define PGT_SHIFT               (12)
+
+#define PGD_SIZE				(PAGE_SIZE * 4)
+
+#define PGD_ALIGN(x)			((x + (0x4000 - 1)) & ~(0x4000 - 1))
+#define PGT_ALIGN(x)			((x + (0x1000 - 1)) & ~(0x1000 - 1))
+
+#define PTE_SMALL_AP_MASK		(0xff << 4)
+#define PTE_SMALL_AP_UNO_SRO	(0x00 << 4)
+#define PTE_SMALL_AP_UNO_SRW	(0x55 << 4)
+#define PTE_SMALL_AP_URO_SRW	(0xaa << 4)
+#define PTE_SMALL_AP_URW_SRW	(0xff << 4)
+
+#define PTE_EXT_XN				(1 << 0)
+#define PTE_EXT_AP_MASK			(3 << 4)
+#define PTE_EXT_AP0				(1 << 4)
+#define PTE_EXT_AP1				(2 << 4)
+#define PTE_EXT_AP_UNO_SRO		(0 << 4)
+#define PTE_EXT_AP_UNO_SRW		(PTE_EXT_AP0)
+#define PTE_EXT_AP_URO_SRW		(PTE_EXT_AP1)
+#define PTE_EXT_AP_URW_SRW		(PTE_EXT_AP1|PTE_EXT_AP0)
+#define PTE_EXT_TEX(x)			((x) << 6)
+#define PTE_EXT_APX				(1 << 9)
+#define PTE_EXT_COHERENT		(1 << 9)
+#define PTE_EXT_SHARED			(1 << 10)
+#define PTE_EXT_NG				(1 << 11)
+
+#define PGD_ORDER				12
+#define PGT_ORDER				8
+
+#define PGD_ENTRIES				(1 << PGD_ORDER)
+#define PGT_ENTRIES				(1 << PGT_ORDER)
+
+#ifdef CONFIG_CPU_XSCALE
+#define PTE_GUEST_AP_MASK		PTE_EXT_AP_MASK
+#define PTE_GUEST_AP_NO			PTE_EXT_AP_UNO_SRW
+#define PTE_GUEST_AP_RO			PTE_EXT_AP_URO_SRW
+#define PTE_GUEST_AP_RW			PTE_EXT_AP_URW_SRW
+#else
+#define PTE_GUEST_AP_MASK		PTE_SMALL_AP_MASK
+#define PTE_GUEST_AP_NO			PTE_SMALL_AP_UNO_SRW
+#define PTE_GUEST_AP_RO			PTE_SMALL_AP_URO_SRW
+#define PTE_GUEST_AP_RW			PTE_SMALL_AP_URW_SRW
+#endif
+
+#define PDE_GUEST_TABLE					(PDE_TYPE_COARSE | PDE_DOMAIN_SUPERVISOR)
+#define PDE_VECTOR_TABLE				(PDE_TYPE_COARSE | PDE_DOMAIN_SUPERVISOR)
+
+#define PTE_GUEST_PAGE					(PTE_TYPE_SMALL | PTE_SMALL_AP_URW_SRW | PTE_BUFFERABLE | PTE_CACHEABLE)
+#define PTE_VECTOR_PAGE					(PTE_TYPE_SMALL | PTE_SMALL_AP_URO_SRW | PTE_BUFFERABLE | PTE_CACHEABLE)
+
+#define GRANT_PTE_FLAGS					(PTE_TYPE_SMALL | PTE_BUFFERABLE | PTE_CACHEABLE | PTE_GUEST_AP_RW)
+
+#define PTE_FLAG_SHARED_INFO	(PTE_TYPE_SMALL | PTE_BUFFERABLE | PTE_CACHEABLE | PTE_SMALL_AP_URW_SRW)
+#define SHARED_INFO_SHADOW_PTE_FLAGS	(PTE_TYPE_SMALL | PTE_BUFFERABLE | PTE_CACHEABLE | PTE_SMALL_AP_UNO_SRW)
+#ifndef __ASSEMBLY__
+
+#include <asm/types.h>
+
+#define MK_PTE(x, flags)	((pte_t) { ((x) & (~PTE_FLAG_MASK)) | flags } )
+#define MK_PDE(x, flags)	((pde_t) { ((x) & (~PDE_FLAG_MASK)) | flags } )
+
+#define PGT_IDX(x)			(((x) >> PGT_SHIFT) & (PGT_ENTRIES - 1))
+#define PGD_IDX(x)			(((x) >> PGD_SHIFT) & (PGD_ENTRIES - 1))
+
+#define PTE_NONE(pte)		(!pte_val(pte))
+#define PTE_PRESENT(pte)	(pte_val(pte) & PTE_TYPE_MASK)
+#define PTE_CLEAR(pte)		(pte_val(*(pte)) = 0UL)
+
+#define PDE_NONE(pde)		(!pde_val(pde))
+#define PDE_PRESENT(pde)	(pde_val(pde) & PDE_TYPE_MASK)
+#define PDE_CLEAR(pde)		(pde_val(*(pde)) = 0UL)
+
+typedef struct { unsigned long pte; } pte_t;
+typedef struct { unsigned long pgd; } pde_t;
+
+#endif /* __ASSEMBLY__ */
+
+#endif /* _ASMARM_PGTABLE_H */
diff --git a/xen/include/asm-arm/plat b/xen/include/asm-arm/plat
new file mode 120000
--- /dev/null
+++ b/xen/include/asm-arm/plat
@@ -0,0 +1,1 @@
+/home/fjnh84/src/xen-unstable.hg/xen/include/asm/tegra
\ No newline at end of file
diff --git a/xen/include/asm-arm/processor.h b/xen/include/asm-arm/processor.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/processor.h
@@ -0,0 +1,57 @@
+/*
+ *  processor.h
+ *
+ * Copyright (C) 2008 Samsung Electronics
+ *          JaeMin Ryu  <jm77.ryu@samsung.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public version 2 of License as published by
+ * the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+#ifndef __ASM_PROCESSOR_H__
+#define __ASM_PROCESSOR_H__
+
+#define user_mode(regs)					\
+    (((regs)->spsr & 0xf) == 0)
+
+#define thumb_mode(regs)				\
+	(((regs)->spsr & PSR_T_BIT))
+
+#define processor_mode(regs)			\
+	((regs)->spsr & PSR_MODE_MASK)
+
+#define interrupts_enabled(regs)		\
+	(!((regs)->spsr & PSR_I_BIT))
+
+#define fast_interrupts_enabled(regs)	\
+	(!((regs)->spsr & PSR_F_BIT))
+
+#define condition_codes(regs)			\
+	((regs)->spsr & (PSR_V_BIT | PSR_C_BIT | PSR_Z_BIT | PSR_N_BIT))
+
+void show_execution_state(struct cpu_user_regs *regs);
+void dump_stack(void);
+
+#define ARCH_HAS_PREFETCH
+static inline void prefetch(const void *ptr)
+{
+        __asm__ __volatile__(
+                "pld\t%a0"
+                :
+                : "p" (ptr)
+                : "cc");
+}
+
+#define cpu_to_core(cpu)    0
+#define cpu_to_socket(cpu)  0
+
+#endif /* __ASM_PROCESSOR_H__ */
diff --git a/xen/include/asm-arm/profile.h b/xen/include/asm-arm/profile.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/profile.h
@@ -0,0 +1,45 @@
+#ifndef __PROFILER_H__
+#define __PROFILER_H__
+
+#include <asm/types.h>
+
+#define MAX_LOG_ENTRIES				8192
+
+#define LOG_ORIGIN_RESET_ENTRY		0
+#define LOG_ORIGIN_RESET_EXIT		1
+#define LOG_ORIGIN_UND_ENTRY		2
+#define LOG_ORIGIN_DABT_ENTRY		3
+#define LOG_ORIGIN_DABT_EXIT		4
+#define LOG_ORIGIN_PABT_ENTRY		5
+#define LOG_ORIGIN_PABT_EXIT		6
+#define LOG_ORIGIN_IRQ_ENTRY		7
+#define LOG_ORIGIN_IRQ_EXIT			8
+#define LOG_ORIGIN_FIQ_ENTRY		9
+#define LOG_ORIGIN_FIQ_EXIT			10
+#define LOG_ORIGIN_SYSCALL_ENTRY	11
+#define LOG_ORIGIN_HYPERCALL_ENTRY	12
+#define LOG_ORIGIN_HYPERCALL_EXIT	13
+#define LOG_ORIGIN_UPCALL_ENTRY		14
+#define LOG_ORIGIN_UPCALL_EXIT		15
+#define LOG_ORIGIN_VMM_EXIT			16
+#define LOG_ORIGIN_SCHEDULER_ENTRY	17
+#define LOG_ORIGIN_SCHEDULER_EXIT	18
+#define LOG_ORIGIN_SOFTIRQ_ENTRY	19
+#define LOG_ORIGIN_SOFTIRQ_EXIT		20
+
+#ifndef __ASSEMBLY__
+struct log_entry {
+	u32		timestamp;
+	u32		origin;
+	u32		event;
+	u32		dummy;
+};
+
+extern u32 idx;
+extern struct log_entry profile_data[MAX_LOG_ENTRIES];
+void event_logging(u32 origin, u32 event);
+
+#endif
+
+#endif
+
diff --git a/xen/include/asm-arm/regs.h b/xen/include/asm-arm/regs.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/regs.h
@@ -0,0 +1,15 @@
+#ifndef __ASM_ARM_REGS_H__
+#define __ASM_ARM_REGS_H__
+
+#include <xen/types.h>
+#include <public/xen.h>
+
+#define return_reg(v) ((v)->arch.user_regs.r0)
+
+#define guest_mode(r)				\
+	({					\
+		BUG();				\
+		0;				\
+	})
+
+#endif
diff --git a/xen/include/asm-arm/shadow.h b/xen/include/asm-arm/shadow.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/shadow.h
@@ -0,0 +1,40 @@
+/******************************************************************************
+ * include/asm-ia64/shadow.h
+ *
+ * Copyright (c) 2006 Isaku Yamahata <yamahata at valinux co jp>
+ *                    VA Linux Systems Japan K.K.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ *
+ */
+
+#ifndef _XEN_SHADOW_H
+#define _XEN_SHADOW_H
+
+#include <xen/config.h>
+#include <xen/paging.h>
+
+#endif // _XEN_SHADOW_H
+
+/*
+ * Local variables:
+ * mode: C
+ * c-set-style: "BSD"
+ * c-basic-offset: 4
+ * tab-width: 4
+ * indent-tabs-mode: nil
+ * End:
+ */
+
diff --git a/xen/include/asm-arm/smp.h b/xen/include/asm-arm/smp.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/smp.h
@@ -0,0 +1,25 @@
+#ifndef __ARM_SMP_H__
+#define __ARM_SMP_H__
+
+#ifndef __ASSEMBLY__
+#include <xen/cpumask.h>
+#endif
+
+#include <asm/current.h>
+
+/*
+ * This function is needed by all SMP systems. It must _always_ be valid
+ * from the initial startup. We map APIC_BASE very early in page_setup(),
+ * so this is correct in the x86 case.
+ */
+#define raw_smp_processor_id() (get_processor_id())
+
+#define NO_PROC_ID 0xFF /* No processor magic marker */
+
+DECLARE_PER_CPU(cpumask_t, cpu_sibling_map);
+DECLARE_PER_CPU(cpumask_t, cpu_core_map);
+
+#define cpu_is_offline(cpu) unlikely(!cpu_online(cpu))
+
+
+#endif /* __ARM_SMP_H__ */
diff --git a/xen/include/asm-arm/softirq.h b/xen/include/asm-arm/softirq.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/softirq.h
@@ -0,0 +1,6 @@
+#ifndef __ARM_SOFTIRQ_H__
+#define __ARM_SOFTIRQ_H__
+
+#define NR_ARCH_SOFTIRQS       0
+
+#endif /* __ASM_SOFTIRQ_H__ */
diff --git a/xen/include/asm-arm/spinlock.h b/xen/include/asm-arm/spinlock.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/spinlock.h
@@ -0,0 +1,152 @@
+#ifndef __ASM_SPINLOCK_H
+#define __ASM_SPINLOCK_H
+
+#include <xen/config.h>
+#include <xen/lib.h>
+#include <asm/atomic.h>
+
+typedef struct {
+    volatile unsigned int lock;
+} raw_spinlock_t;
+
+static inline void dsb_sev(void)
+{
+	__asm__ __volatile__ (
+		"dsb\n"
+		"sev"
+	);
+}
+
+/*
+ * ARMv7 Spin-locking.
+ *
+ * We exclusively read the old value.  If it is zero, we may have
+ * won the lock, so we try exclusively storing it.  A memory barrier
+ * is required after we get a lock, and before we release it, because
+ * V7 CPUs are assumed to have weakly ordered memory.
+ *
+ * Unlocked value: 0
+ * Locked value: 1
+ */
+
+
+#define _RAW_SPIN_LOCK_UNLOCKED /*(raw_spinlock_t)*/ { 1 }
+
+#define _raw_spin_is_locked(x)		((x)->lock != 0)
+
+static inline void _raw_spin_unlock(raw_spinlock_t *lock)
+{
+	unsigned long tmp;
+
+	__asm__ __volatile__(
+"1:	ldrex	%0, [%1]\n"
+"	teq	%0, #0\n"
+"	strexeq	%0, %2, [%1]\n"
+"	teqeq	%0, #0\n"
+"	bne	1b"
+	: "=&r" (tmp)
+	: "r" (&lock->lock), "r" (1)
+	: "cc");
+
+	smp_mb();
+}
+
+static inline int _raw_spin_trylock(raw_spinlock_t *lock)
+{
+	unsigned long tmp;
+
+	__asm__ __volatile__(
+"	ldrex	%0, [%1]\n"
+"	teq	%0, #0\n"
+"	strexeq	%0, %2, [%1]"
+	: "=&r" (tmp)
+	: "r" (&lock->lock), "r" (1)
+	: "cc");
+
+	if (tmp == 0) {
+		smp_mb();
+		return 1;
+	} else {
+		return 0;
+	}
+}
+
+typedef struct {
+    volatile int lock;
+} raw_rwlock_t;
+
+#define _RAW_RW_LOCK_UNLOCKED /*(raw_rwlock_t)*/ { 0 }
+
+static inline int _raw_read_trylock(raw_rwlock_t *rw)
+{
+	unsigned long tmp, tmp2 = 1;
+
+	__asm__ __volatile__(
+"1:	ldrex	%0, [%2]\n"
+"	adds	%0, %0, #1\n"
+"	strexpl	%1, %0, [%2]\n"
+	: "=&r" (tmp), "+r" (tmp2)
+	: "r" (&rw->lock)
+	: "cc");
+
+	smp_mb();
+	return tmp2 == 0;
+}
+
+static inline int _raw_write_trylock(raw_rwlock_t *rw)
+{
+	unsigned long tmp;
+
+	__asm__ __volatile__(
+"1:	ldrex	%0, [%1]\n"
+"	teq	%0, #0\n"
+"	strexeq	%0, %2, [%1]"
+	: "=&r" (tmp)
+	: "r" (&rw->lock), "r" (0x80000000)
+	: "cc");
+
+	if (tmp == 0) {
+		smp_mb();
+		return 1;
+	} else {
+		return 0;
+	}
+}
+
+static inline void _raw_read_unlock(raw_rwlock_t *rw)
+{
+	unsigned long tmp, tmp2;
+
+	smp_mb();
+
+	__asm__ __volatile__(
+"1:	ldrex	%0, [%2]\n"
+"	sub	%0, %0, #1\n"
+"	strex	%1, %0, [%2]\n"
+"	teq	%1, #0\n"
+"	bne	1b"
+	: "=&r" (tmp), "=&r" (tmp2)
+	: "r" (&rw->lock)
+	: "cc");
+
+	if (tmp == 0)
+		dsb_sev();
+}
+
+static inline void _raw_write_unlock(raw_rwlock_t *rw)
+{
+	smp_mb();
+
+	__asm__ __volatile__(
+	"str	%1, [%0]\n"
+	:
+	: "r" (&rw->lock), "r" (0)
+	: "cc");
+
+	dsb_sev();
+}
+
+#define _raw_rw_is_locked(x) ((x)->lock != 0)
+#define _raw_rw_is_write_locked(x) ((x)->lock == 0x80000000)
+
+#endif /* __ASM_SPINLOCK_H */
diff --git a/xen/include/asm-arm/string.h b/xen/include/asm-arm/string.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/string.h
@@ -0,0 +1,15 @@
+#ifndef __ASM_STRING_H__
+#define __ASM_STRING_H__
+
+#include <xen/config.h>
+
+#define __HAVE_ARCH_MEMCPY
+#define memcpy(t,f,n) (__builtin_memcpy((t),(f),(n)))
+
+#define __HAVE_ARCH_MEMMOVE
+#define memmove(t,f,n) (__builtin_memcpy((t),(f),(n)))
+
+#define __HAVE_ARCH_MEMSET
+#define memset(s,c,n) (__builtin_memset((s),(c),(n)))
+
+#endif /* __ASM_STRING_H__ */
diff --git a/xen/include/asm-arm/system.h b/xen/include/asm-arm/system.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/system.h
@@ -0,0 +1,262 @@
+#ifndef __ASM_SYSTEM_H
+#define __ASM_SYSTEM_H
+
+#include <xen/lib.h>
+#include <asm/types.h>
+#include <asm/percpu.h>
+#include <asm/processor.h>
+#include <asm/plat/cache.h>
+
+#define nop() \
+    asm volatile ( "nop" )
+
+/*
+ * PSR bits
+ */
+#define PSR_MODE_USR26			0x00000000
+#define PSR_MODE_FIQ26			0x00000001
+#define PSR_MODE_IRQ26			0x00000002
+#define PSR_MODE_SVC26			0x00000003
+#define PSR_MODE_USR			0x00000010
+#define PSR_MODE_FIQ			0x00000011
+#define PSR_MODE_IRQ			0x00000012
+#define PSR_MODE_SVC			0x00000013
+#define PSR_MODE_ABT			0x00000017
+#define PSR_MODE_UND			0x0000001b
+#define PSR_MODE_SYS			0x0000001f
+#define PSR_MODE_MASK			0x0000001f
+#define PSR_T_BIT			0x00000020
+#define PSR_F_BIT			0x00000040
+#define PSR_I_BIT			0x00000080
+#define PSR_J_BIT			0x01000000
+#define PSR_Q_BIT			0x08000000
+#define PSR_V_BIT			0x10000000
+#define PSR_C_BIT			0x20000000
+#define PSR_Z_BIT			0x40000000
+#define PSR_N_BIT			0x80000000
+#define PCMASK				0
+
+/*
+ * Groups of PSR bits
+ */
+#define PSR_MASK_FLAGS          0xff000000      /* Flags                */
+#define PSR_MASK_STATUS         0x00ff0000      /* Status               */
+#define PSR_MASK_EXTENSION      0x0000ff00      /* Extension            */
+#define PSR_MASK_CONTROL        0x000000ff      /* Control              */
+
+/*
+ * CR1 bits (CP#15 CR1)
+ */
+#define CR_M	(1 << 0)	/* MMU enable				*/
+#define CR_A	(1 << 1)	/* Alignment abort enable		*/
+#define CR_C	(1 << 2)	/* Dcache enable			*/
+#define CR_W	(1 << 3)	/* Write buffer enable			*/
+#define CR_P	(1 << 4)	/* 32-bit exception handler		*/
+#define CR_D	(1 << 5)	/* 32-bit data address range		*/
+#define CR_L	(1 << 6)	/* Implementation defined		*/
+#define CR_B	(1 << 7)	/* Big endian				*/
+#define CR_S	(1 << 8)	/* System MMU protection		*/
+#define CR_R	(1 << 9)	/* ROM MMU protection			*/
+#define CR_F	(1 << 10)	/* Implementation defined		*/
+#define CR_Z	(1 << 11)	/* Implementation defined		*/
+#define CR_I	(1 << 12)	/* Icache enable			*/
+#define CR_V	(1 << 13)	/* Vectors relocated to 0xffff0000	*/
+#define CR_RR	(1 << 14)	/* Round Robin cache replacement	*/
+#define CR_L4	(1 << 15)	/* LDR pc can set T bit			*/
+#define CR_DT	(1 << 16)
+#define CR_IT	(1 << 18)
+#define CR_ST	(1 << 19)
+#define CR_FI	(1 << 21)	/* Fast interrupt (lower latency mode)	*/
+#define CR_U	(1 << 22)	/* Unaligned access operation		*/
+#define CR_XP	(1 << 23)	/* Extended page tables			*/
+#define CR_VE	(1 << 24)	/* Vectored interrupts			*/
+
+#ifndef __ASSEMBLY__
+#define cpu_relax() barrier()
+
+#define isb() __asm__ __volatile__ ("isb" : : : "memory")
+#define dsb() __asm__ __volatile__ ("dsb" : : : "memory")
+#define dmb() __asm__ __volatile__ ("dmb" : : : "memory")
+
+/* TODO: Wrap similar to linux-arm system.h code. */
+#define mb()		do { dsb(); outer_sync(); } while (0)
+#define rmb()		dmb()
+#define wmb()		mb()
+
+#ifndef CONFIG_SMP
+#define smp_mb()	barrier()
+#define smp_rmb()	barrier()
+#define smp_wmb()	barrier()
+#else
+#define smp_mb()	dmb()
+#define smp_rmb()	dmb()
+#define smp_wmb()	dmb()
+#endif
+
+/*
+ * Save the current interrupt enable state & disable IRQs
+ */
+#define local_irq_save(x)				\
+	({						\
+		unsigned long temp;			\
+		(void) (&temp == &x);			\
+		__asm__ __volatile__(			\
+			"mrs %0, cpsr\n"		\
+			"orr %1, %0, #128\n"		\
+			"msr cpsr_c, %1"			\
+			: "=r" (x), "=r" (temp)		\
+			:				\
+			: "memory", "cc");		\
+	})
+
+/*
+ * Enable IRQs
+ */
+#define local_irq_enable()				\
+	({						\
+		unsigned long temp;			\
+		__asm__ __volatile__(			\
+			"mrs %0, cpsr\n"		\
+			"bic %0, %0, #128\n"		\
+			"msr cpsr_c, %0"		\
+		: "=r" (temp)				\
+		:					\
+		: "memory", "cc");			\
+	})
+
+/*
+ * Disable IRQs
+ */
+#define local_irq_disable()				\
+	({						\
+		unsigned long temp;			\
+		__asm__ __volatile__(			\
+			"mrs %0, cpsr\n"		\
+			"orr %0, %0, #128\n"		\
+			"msr cpsr_c, %0"		\
+			: "=r" (temp)			\
+			:				\
+			: "memory", "cc");		\
+	})
+
+/*
+ * Enable FIQs
+ */
+#define local_fiq_enable()				\
+	({						\
+		unsigned long temp;			\
+		__asm__ __volatile__(			\
+			"mrs %0, cpsr\n"		\
+			"bic %0, %0, #64\n"		\
+			"msr cpsr_c, %0"		\
+			: "=r" (temp)			\
+			:				\
+			: "memory", "cc");		\
+	})
+
+/*
+ * Disable FIQs
+ */
+#define local_fiq_disable()				\
+	({						\
+		unsigned long temp;			\
+		__asm__ __volatile__(			\
+			"mrs %0, cpsr\n"		\
+			"orr %0, %0, #64\n"		\
+			"msr cpsr_c, %0"		\
+			: "=r" (temp)			\
+			:				\
+			: "memory", "cc");		\
+	})
+
+
+/*
+ * Save the current interrupt enable state.
+ */
+#define local_save_flags(x)				\
+	({						\
+		__asm__ __volatile__(			\
+			"mrs %0, cpsr\n"		\
+			: "=r" (x) : : "memory", "cc");	\
+	})
+
+/*
+ * restore saved IRQ & FIQ state
+ */
+#define local_irq_restore(x)					\
+	({							\
+		__asm__ __volatile__(				\
+			"msr cpsr_c, %0\n"			\
+		:						\
+		: "r" (x)					\
+		: "memory", "cc");				\
+	})
+
+#define irqs_disabled()						\
+	({							\
+		unsigned long flags;				\
+		local_save_flags(flags);			\
+		flags & PSR_I_BIT;				\
+	})
+
+#define local_irq_is_enabled()	(!irqs_disabled())
+
+static inline unsigned int get_cr(void)
+{
+	unsigned int val;
+	asm("mrc p15, 0, %0, c1, c0, 0" : "=r"(val) : : "cc");
+
+	return val;
+}
+
+static inline void set_cr(unsigned int val)
+{
+	asm volatile("mcr p15, 0, %0, c1, c0, 0" : : "r"(val) : "cc");
+
+	isb();
+}
+
+static inline unsigned long __xchg(unsigned long x, volatile void * ptr, int size)
+{
+	unsigned long ret;
+
+	switch (size) {
+		case 1:
+			__asm__ __volatile__(
+				"swpb	%0, %1, [%2]"
+				: "=&r" (ret)
+				: "r" (x), "r" (ptr)
+				: "memory", "cc");
+			break;
+		case 4:
+			__asm__ __volatile__(
+				"  swp	%0, %1, [%2]"
+				: "=&r" (ret)
+				: "r" (x), "r" (ptr)
+				: "memory", "cc");
+			break;
+		default:
+			ret = 0;
+			break;
+	}
+
+	return ret;
+}
+
+#define cmpxchg(ptr, old, new)						\
+	({								\
+		__typeof__(*(ptr)) prev;				\
+		unsigned long flags;					\
+		local_irq_save(flags);					\
+		prev = *((__typeof__(*(ptr)) *)ptr);			\
+		if(prev == old)						\
+			*((__typeof__(*(ptr)) *)ptr) = (__typeof__(*(ptr)))new; \
+		local_irq_restore(flags);				\
+		prev;							\
+	})
+
+#define xchg(ptr,v)							\
+	((__typeof__(*(ptr)))__xchg((unsigned long)(v),(ptr),sizeof(*(ptr))))
+
+#endif /* __ASSEMBLY__ */
+#endif
diff --git a/xen/include/asm-arm/tegra/cache.h b/xen/include/asm-arm/tegra/cache.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/tegra/cache.h
@@ -0,0 +1,7 @@
+#ifndef __ARM_TEGRA_CACHE_H__
+#define __ARM_TEGRA_CACHE_H__
+
+/* For now... */
+#define outer_sync()
+
+#endif
diff --git a/xen/include/asm-arm/tegra/config.h b/xen/include/asm-arm/tegra/config.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/tegra/config.h
@@ -0,0 +1,18 @@
+#ifndef __IMX21ADS_CONFIG_H__
+#define __IMX21ADS_CONFIG_H__
+
+
+#define HZ			100
+
+//#define KERNEL_START		(0xC0008000UL)
+#define PHYS_OFFSET   		(0xc0000000UL)
+
+#define IDLE_PG_TABLE_ADDR	(0xC0004000UL)
+#define __PAGE_OFFSET           (0x3F000000UL)
+
+#define MEMMAP_DRAM_ADDR	PHYS_OFFSET
+#define MEMMAP_DRAM_SIZE	0x04000000
+#define MEMMAP_NOR_ADDR		0xC8000000
+#define MEMMAP_NOR_SIZE		0x02000000
+
+#endif
diff --git a/xen/include/asm-arm/tegra/dma.h b/xen/include/asm-arm/tegra/dma.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/tegra/dma.h
@@ -0,0 +1,350 @@
+#ifndef __IMX21ADS_DMA_H
+#define __IMX21ADS_DMA_H
+
+#include <asm/arch/imx-regs.h>
+
+#define IMX21ADS_DMA_CHANNELS	16
+#define MAX_DMA_CHANNELS	IMX21ADS_DMA_CHANNELS
+
+
+#define DMAC_BASE_ADDR		0x10001000           /* Base Add */
+
+/* Base address for DMA channel registers */
+#define DMAC_BASE_CHANNEL_ADDR	0x10001080
+/* DMA definitions with variable channel numbers (range: 0 - 15) */
+#define DMAC_CHANNEL_MAX	16
+#define DMAC_CHANNEL_STRIDE	0x0040
+
+/* DMAC_DCR - DMA Control Register field definitions */
+#define DMAC_DCR_DAM            (1 << 2)        /* DMA Access Mode */
+#define DMAC_DCR_DRST           (1 << 1)        /* DMA Soft Reset */
+#define DMAC_DCR_DEN            (1 << 0)        /* DMA Enable */
+
+/* DMAC_DISR - DMA Interrupt Status Register - bits 0-15 = Channels 1-16 */
+#define DMAC_DISR_CH(channel)   (1 << (channel))
+
+/* DMAC_DIMR - DMA Interrupt Mask Register */
+#define DMAC_DIMR_CH(channel)   (1 << (channel))
+
+/* DMAC_DBTOSR - DMA Burst Time-Out Status Register */
+#define DMAC_DBTOSR_CH(channel) (1 << (channel))
+
+/* DMAC_DRTOSR - DMA Request Time-Out Status Register */
+#define DMAC_DRTOSR_CH(channel) (1 << (channel))
+
+/* DMAC_DSESR - DMA Transfer Error Status Register */
+#define DMAC_DSESR_CH(channel)  (1 << (channel))
+
+/* DMAC_DBOSR - DMA Buffer Overflow Status Register */
+#define DMAC_DBOSR_CH(channel)  (1 << (channel))
+
+/* DMAC_DBTOCR - DMA Burst Time-Out Control Register */
+#define DMAC_DBTOCR_EN          (1 << 15)
+#define DMAC_DBTOCR_CNT(x)      ((x) & 0x7FFF)
+
+/* DMAC_WSRA WSRB - W-Size Register A W-Size Register B */
+#define DMAC_WSRA WSRB_WS(x)    ((x) & 0xFFFF)
+
+/* DMAC_XSRA XSRB - X-Size Register A X-Size Register B */
+#define DMAC_XSRA XSRB_XS(x)    ((x) & 0xFFFF)
+
+/* DMAC_YSRA YSRB - Y-Size Register A Y-Size Register B */
+#define DMAC_YSRA YSRB_YS(x)    ((x) & 0xFFFF)
+
+/* DMAC Channel Control Register bit field definitions */
+#define DMAC_CCR_ACRPT          (1 << 14)       /* Auto Clear RPT */
+#define DMAC_CCR_DMOD(x)        (((x)>>12)&0x3) /* Dest Mode- 2D, linear, etc */
+#define DMAC_CCR_SMOD(x)        (((x)>>10)&0x3) /* Source Mode */
+#define DMAC_CCR_MDIR           (1 << 9)        /* Memory Direction */
+#define DMAC_CCR_MSEL           (1 << 8)        /* Memory Select */
+#define DMAC_CCR_DSIZ(x)        (((x)>>6)&0x3)  /* Dest Size - 8,16,32 */
+#define DMAC_CCR_SSIZ(x)        (((x)>>4)&0x3)  /* Source Size */
+#define DMAC_CCR_REN            (1 << 3)        /* Request Enable */
+#define DMAC_CCR_RPT            (1 << 2)        /* Repeat */
+#define DMAC_CCR_FRC            (1 << 1)        /* Force DMA Cycle */
+#define DMAC_CCR_CEN            (1 << 0)        /* Channel Enable */
+
+#define DMAC_CCR_SET_SSIZ(x,value)      ((x)|=(value<<4))
+#define DMAC_CCR_SET_DSIZ(x,value)      ((x)|=(value<<6))
+#define DMAC_CCR_SET_SMOD(x,value)      ((x)|=(value<<10))
+#define DMAC_CCR_SET_DMOD(x,value)      ((x)|=(value<<12))
+
+
+#define DMA_MEM_SIZE_8  	0x1
+#define DMA_MEM_SIZE_16 	0x2
+#define DMA_MEM_SIZE_32 	0x0
+
+#define DMA_TYPE_LINEAR 	0x0
+#define DMA_TYPE_2D             0x01
+#define DMA_TYPE_FIFO   	0x2
+#define DMA_TYPE_EBE    	0x3
+#define DMA_MEM_SIZE_8          0x1
+#define DMA_MEM_SIZE_16         0x2
+#define DMA_MEM_SIZE_32         0x0
+
+#define DMA_DONE                0x1000
+#define DMA_BURST_TIMEOUT       0x1
+#define DMA_REQUEST_TIMEOUT     0x2
+#define DMA_TRANSFER_ERROR      0x4
+#define DMA_BUFFER_OVERFLOW     0x8
+
+#define DMA_REQ_CSI_RX          31
+#define DMA_REQ_CSI_STAT        30
+#define DMA_REQ_BMI_RX          29
+#define DMA_REQ_BMI_TX          28
+#define DMA_REQ_UART1_TX        27
+#define DMA_REQ_UART1_RX        26
+#define DMA_REQ_UART2_TX        25
+#define DMA_REQ_UART2_RX        24
+#define DMA_REQ_UART3_TX        23
+#define DMA_REQ_UART3_RX        22
+#define DMA_REQ_UART4_TX        21
+#define DMA_REQ_UART4_RX        20
+#define DMA_REQ_CSPI1_TX        19
+#define DMA_REQ_CSPI1_RX        18
+#define DMA_REQ_CSPI2_TX        17
+#define DMA_REQ_CSPI2_RX        16
+#define DMA_REQ_SSI1_TX1        15
+#define DMA_REQ_SSI1_RX1        14
+#define DMA_REQ_SSI1_TX0        13
+#define DMA_REQ_SSI1_RX0        12
+#define DMA_REQ_SSI2_TX1        11
+#define DMA_REQ_SSI2_RX1        10
+#define DMA_REQ_SSI2_TX0        9
+#define DMA_REQ_SSI2_RX0        8
+#define DMA_REQ_SDHC1           7
+#define DMA_REQ_SDHC2           6
+#define DMA_FIRI_TX             5
+#define DMA_FIRI_RX             4
+#define DMA_EX                  3
+#define DMA_REQ_CSPI3_TX        2
+#define DMA_REQ_CSPI3_RX        1
+
+#define DMA_CTL_CEN		0x1
+#define DMA_CTL_FRC		0x2
+#define DMA_CTL_RPT		0x4
+#define DMA_CTL_REN		0x8
+
+#define DMA_CTL_SSIZ		(0x10|0x20)
+#define DMA_CTL_DSIZ		(0x40|0x80)
+
+#define DMA_CTL_MSEL		0x100
+#define DMA_CTL_MDIR		0x200
+#define DMA_CTL_SMOD		(0x400|0x800)
+#define DMA_CTL_DMOD		(0x1000|0x2000)
+#define DMA_CTL_ACRPT		0x4000
+
+#define DMA_CTL_GET_SSIZ(x)	(((x)>>4)&0x3)
+#define DMA_CTL_GET_DSIZ(x)	(((x)>>6)&0x3)
+#define DMA_CTL_GET_SMOD(x)	(((x)>>10)&0x3)
+#define DMA_CTL_GET_DMOD(x)	(((x)>>12)&0x3)
+
+
+#define DMA_REQ_CSI_RX		31
+#define DMA_REQ_CSI_STAT	30
+#define DMA_REQ_BMI_RX		29
+#define DMA_REQ_BMI_TX		28
+#define DMA_REQ_UART1_TX	27
+#define DMA_REQ_UART1_RX	26
+#define DMA_REQ_UART2_TX	25
+#define DMA_REQ_UART2_RX	24
+#define DMA_REQ_UART3_TX	23
+#define DMA_REQ_UART3_RX	22
+#define DMA_REQ_UART4_TX	21
+#define DMA_REQ_UART4_RX	20
+#define DMA_REQ_CSPI1_TX	19
+#define DMA_REQ_CSPI1_RX	18
+#define DMA_REQ_CSPI2_TX	17
+#define DMA_REQ_CSPI2_RX	16
+#define DMA_REQ_SSI1_TX1	15
+#define DMA_REQ_SSI1_RX1	14
+#define DMA_REQ_SSI1_TX0	13
+#define DMA_REQ_SSI1_RX0	12
+#define DMA_REQ_SSI2_TX1	11
+#define DMA_REQ_SSI2_RX1	10
+#define DMA_REQ_SSI2_TX0	9
+#define DMA_REQ_SSI2_RX0	8
+#define DMA_REQ_SDHC1		7
+#define DMA_REQ_SDHC2		6
+#define DMA_FIRI_TX		5
+#define DMA_FIRI_RX		4
+#define DMA_EX			3
+
+
+#define DMA_CTL_SET_SSIZ(x,value)		\
+	do{					\
+		(x)&=~(0x3<<4);			\
+                (x)|=(value)<<4;                \
+	}while(0)
+
+#define DMA_CTL_SET_DSIZ(x,value)		\
+	do{					\
+		(x)&=~(0x3<<6); 		\
+		(x)|=(value)<<6;                \
+	}while(0)
+
+#define DMA_CTL_SET_SMOD(x,value)		\
+	do{ 					\
+		(x)&=~(0x3<<10); 		\
+		(x)|=(value)<<10;               \
+	}while(0)
+
+#define DMA_CTL_SET_DMOD(x,value)		\
+	do{ 					\
+		(x)&=~(0x3<<12);		\
+		(x)|=(value)<<12;               \
+	}while(0)
+
+
+typedef enum {
+	IMX21ADS_DMA_PRIO_HIGH = 0,
+	IMX21ADS_DMA_PRIO_MEDIUM = 3,
+	IMX21ADS_DMA_PRIO_LOW = 6
+} imx21ads_dma_priority;
+
+static inline void imx21ads_get_dma_status(unsigned long channel, struct dma_status *status)
+{
+	status->interrupt	= DISR;
+	status->request_timeout = DRTOSR;
+	status->burst_timeout	= DBTOSR;
+	status->transfer_error	= DSESR;
+	status->buffer_overflow = DBOSR;
+}
+
+static inline void imx21ads_ack_dma_int(unsigned long channel)
+{
+	DISR    = DMAC_DISR_CH(channel);
+	DRTOSR  = DMAC_DRTOSR_CH(channel);
+	DBTOSR  = DMAC_DBTOSR_CH(channel);
+	DSESR   = DMAC_DSESR_CH(channel);
+	DBOSR   = DMAC_DBOSR_CH(channel);
+}
+
+static inline void imx21ads_set_dma_config(unsigned long channel, struct dma_config *config)
+{
+
+	BLR(channel)  = config->length;
+	SAR(channel)  = config->source_address;
+	DAR(channel)  = config->destination_address;
+	RSSR(channel) = config->request;
+	CNTR(channel) = config->count;
+
+        if(config->direction)
+		CCR(channel) |=DMAC_CCR_MDIR;
+	else
+		CCR(channel) &=~DMAC_CCR_MDIR;
+
+	if(config->repeat)
+		CCR(channel) |=DMAC_CCR_RPT;
+	else
+		CCR(channel) &=~DMAC_CCR_RPT;
+
+	DMAC_CCR_SET_SMOD(CCR(channel), config->source_type);
+	DMAC_CCR_SET_SSIZ(CCR(channel), config->source_port);
+	DMAC_CCR_SET_DMOD(CCR(channel), config->destination_type);
+	DMAC_CCR_SET_DSIZ(CCR(channel), config->destination_port);
+
+}
+
+static inline void imx21ads_get_dma_config(unsigned long channel, struct dma_config *config)
+{
+	config->direction		= CCR(channel)& DMAC_CCR_MDIR ? 1:0;
+	config->length			= BLR(channel);
+	config->repeat			= CCR(channel) & DMAC_CCR_RPT ? 1:0;
+	config->source_type		= DMAC_CCR_SMOD(CCR(channel));
+	config->source_address		= SAR(channel);
+	config->source_port		= DMAC_CCR_SSIZ(CCR(channel));
+	config->destination_type	= DMAC_CCR_DMOD(CCR(channel));
+	config->destination_address	= DAR(channel);
+	config->destination_port	= DMAC_CCR_DSIZ(CCR(channel));
+	config->request			= RSSR(channel);
+	config->count			= CNTR(channel);
+}
+
+static inline void imx21ads_set_dma_count(unsigned long channel, unsigned long count)
+{
+	CNTR(channel) = count;
+}
+
+static inline void imx21ads_set_dma_address(unsigned long channel, unsigned long addr, unsigned int flag)
+{
+	if(flag) {
+		SAR(channel) = addr;
+	} else {
+		DAR(channel) = addr;
+	}
+}
+
+static inline void imx21ads_disable_dma(unsigned long channel)
+{
+	CCR(channel) &= ~DMAC_CCR_CEN;
+}
+
+static inline void imx21ads_start_dma(unsigned long channel)
+{
+	DISR    = DMAC_DISR_CH(channel);
+	DRTOSR  = DMAC_DRTOSR_CH(channel);
+	DBTOSR  = DMAC_DBTOSR_CH(channel);
+	DSESR   = DMAC_DSESR_CH(channel);
+	DBOSR   = DMAC_DBOSR_CH(channel);
+
+	CCR(channel) &= ~DMAC_CCR_CEN;
+	CCR(channel) &= ~DMAC_CCR_REN;
+
+	if(DMAC_CCR_SMOD(CCR(channel)) == DMA_TYPE_FIFO) {
+		CCR(channel) |= DMAC_CCR_REN;
+	}
+
+	if(DMAC_CCR_DMOD(CCR(channel)) == DMA_TYPE_FIFO) {
+		CCR(channel) |= DMAC_CCR_REN;
+	}
+
+
+	CCR(channel) |= DMAC_CCR_CEN;	
+}
+
+
+static inline void imx21ads_enable_dma(unsigned long channel)
+{
+	DISR		= DMAC_DISR_CH(channel);
+	DBTOSR		= DMAC_DBTOSR_CH(channel);
+	DRTOSR		= DMAC_DRTOSR_CH(channel);
+	DSESR		= DMAC_DSESR_CH(channel);
+	DBOSR		= DMAC_DBOSR_CH(channel);
+
+	CCR(channel) 	&= ~DMAC_CCR_CEN;
+	CCR(channel) 	|= DMAC_CCR_CEN;
+}
+
+static inline void imx21ads_get_dma_residue(unsigned long channel, unsigned long *residue)
+{
+	*residue = (CNTR(channel) - CCNR(channel));
+}
+
+static inline void imx21ads_request_dma(unsigned long channel)
+{
+	DIMR &= ~(DMAC_DIMR_CH(channel));
+	DBTOCR = (1 << 15) + 0x500;
+
+	DCR |= DMAC_DCR_DEN;
+
+}
+
+static inline void imx21ads_release_dma(unsigned long channel)
+{
+	DIMR |= DMAC_DIMR_CH(channel);
+}
+
+#define arch_enable_dma		imx21ads_enable_dma
+#define arch_disable_dma	imx21ads_disable_dma
+#define arch_start_dma		imx21ads_start_dma
+#define arch_request_dma	imx21ads_request_dma
+#define arch_release_dma	imx21ads_release_dma
+#define arch_ack_dma_int	imx21ads_ack_dma_int
+#define arch_set_dma_count	imx21ads_set_dma_count
+#define arch_set_dma_address	imx21ads_set_dma_address
+#define arch_set_dma_config	imx21ads_set_dma_config
+#define arch_get_dma_status	imx21ads_get_dma_status
+#define arch_get_dma_residue	imx21ads_get_dma_residue
+#define arch_get_dma_config	imx21ads_get_dma_config
+#endif
diff --git a/xen/include/asm-arm/tegra/entry-macro.S b/xen/include/asm-arm/tegra/entry-macro.S
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/tegra/entry-macro.S
@@ -0,0 +1,32 @@
+/*
+ * include/asm-arm/arch-imx/entry-macro.S
+ *
+ * Low-level IRQ helper macros for iMX-based platforms
+ *
+ * This file is licensed under  the terms of the GNU General Public
+ * License version 2. This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#include <asm/arch/imx-regs.h>
+
+		.macro	disable_fiq
+		.endm
+#define AITC_NIVECSR   0x40
+		.macro	get_irqnr_and_base, irqnr, irqstat, base, tmp
+		ldr	\irqstat, =IO_ADDRESS(IMX_AITC_BASE)
+		@ Load offset & priority of the highest priority
+		@ interrupt pending.
+		ldr	\irqnr, [\irqstat, #AITC_NIVECSR]
+		@ Shift off the priority leaving the offset or
+		@ "interrupt number"
+		mov	\irqnr, \irqnr, lsr #16
+ 		ldr	\irqstat, =1	@ dummy compare
+		ldr	\base, =0xFFFF		// invalid interrupt
+		cmp	\irqnr, \base
+		bne	1001f
+		ldr	\irqstat, =0
+1001:
+		tst	\irqstat, #1	@ to make the condition code = TRUE
+		.endm
+
diff --git a/xen/include/asm-arm/tegra/hardware.h b/xen/include/asm-arm/tegra/hardware.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/tegra/hardware.h
@@ -0,0 +1,88 @@
+/*
+ *  linux/include/asm-arm/arch-imx/hardware.h
+ *
+ *  Copyright (C) 1999 ARM Limited.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+#ifndef __ASM_ARCH_HARDWARE_H
+#define __ASM_ARCH_HARDWARE_H
+
+#include "imx-regs.h"
+#include "mx2ads.h"
+
+#ifndef __ASSEMBLY__
+# define __REG(x)	(*((volatile u32 *)IO_ADDRESS(x))) 
+# define __REG16(x)    (*((volatile u16 *)IO_ADDRESS(x)))
+
+// gcc version 4.1.1 error
+#if 0
+# define __REG2(x,y)	\
+	( __builtin_constant_p(y) ? (__REG((x) + (y))) \
+			  : (*(volatile u32 *)((u32)&__REG(x) + (y))) ) 
+#endif
+# define __REG2(x,y)	(*(volatile u32 *)((u32)&__REG(x) + (y)))
+#endif
+
+#define IMX_IO_PHYS        0x10000000
+#define IMX_IO_SIZE        0x00100000
+#define IMX_IO_BASE        0xe0000000
+
+#define IMX_CS0_PHYS       0xc8000000
+#define IMX_CS0_SIZE       0x02000000
+#define IMX_CS0_VIRT       0xe8000000
+
+#define IMX_CS1_PHYS       0xcc000000
+#define IMX_CS1_SIZE       0x01000000
+#define IMX_CS1_VIRT       0xec000000
+
+#define IMX_EMI_PHYS       0xdf000000
+#define IMX_EMI_SIZE       0x00004000
+#define IMX_EMI_VIRT       0xeb000000
+
+
+#define IMX_FB_VIRT        0xF1000000
+#define IMX_FB_SIZE        (256*1024)
+
+/* macro to get at IO space when running virtually */
+#define IO_ADDRESS(x) ((x) | IMX_IO_BASE)
+
+#ifndef __ASSEMBLY__
+/*
+ * Handy routine to set GPIO functions
+ */
+extern void imx_gpio_mode( int gpio_mode );
+
+/* get frequencies in Hz */
+extern unsigned int imx21_get_system_clk(void);
+extern unsigned int imx21_get_mcu_clk(void);
+extern unsigned int imx21_get_perclk1(void); /* UART[12], Timer[12], PWM */
+extern unsigned int imx21_get_perclk2(void); /* LCD, SD, SPI[12]         */
+extern unsigned int imx21_get_perclk3(void); /* SSI                      */
+extern unsigned int imx21_get_hclk(void);    /* SDRAM, CSI, Memory Stick,*/
+/* I2C, DMA                 */
+#endif
+
+
+#define MAXIRQNUM                       62
+#define MAXFIQNUM                       62
+#define MAXSWINUM                       62
+
+/*
+ * Use SDRAM for memory
+ */
+#define MEM_SIZE		0x01000000
+
+#endif
diff --git a/xen/include/asm-arm/tegra/imx-dma.h b/xen/include/asm-arm/tegra/imx-dma.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/tegra/imx-dma.h
@@ -0,0 +1,157 @@
+/*
+ *  linux/include/asm-arm/imxads/dma.h
+ *
+ *  Copyright (C) 1997,1998 Russell King
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#include <asm/dma.h>
+
+#ifndef __ASM_ARCH_IMX_DMA_H
+#define __ASM_ARCH_IMX_DMA_H
+
+#define IMX_DMA_CHANNELS  16
+
+#define IMX_DMA_WIDTH_8        1
+#define IMX_DMA_WIDTH_16       2
+#define IMX_DMA_WIDTH_32       3
+
+/*
+ * struct imx_dma_channel - i.MX specific DMA extension
+ * @name: name specified by DMA client
+ * @irq_handler: client callback for end of transfer
+ * @err_handler: client callback for error condition
+ * @data: clients context data for callbacks
+ * @dma_mode: direction of the transfer %DMA_MODE_READ or %DMA_MODE_WRITE
+ * @sg: pointer to the actual read/written chunk for scatter-gather emulation
+ * @sgbc: counter of processed bytes in the actual read/written chunk
+ * @sgcount: number of chunks to be read/written
+ *
+ * Structure is used for IMX DMA processing. It would be probably good
+ * @struct dma_struct in the future for external interfacing and use
+ * @struct imx_dma_channel only as extension to it.
+ */
+
+struct imx_dma_channel {
+	const char *name;
+	void (*irq_handler) (int, void *, struct pt_regs *);
+	void (*err_handler) (int, void *, struct pt_regs *);
+	void *data;
+	dmamode_t  dma_mode;
+	struct scatterlist *sg;
+	unsigned int sgbc;
+	unsigned int sgcount;
+	int dma_num;
+};
+
+extern struct imx_dma_channel imx_dma_channels[IMX_DMA_CHANNELS];
+
+
+/* This is there to check unintentional mixing of iteger and DMA hadnle values
+ * I want to ensure to check separation of these in the dma.c, bacause it would be
+ * required, if we try to move i.MX DMA to the generic DMA infrastructure one day.
+ */
+#define IMX_DMACH_T_RESTRICT
+
+#ifdef IMX_DMACH_T_RESTRICT
+typedef struct {
+	int dma_num;
+} imx_dmach_t;
+
+#else /*IMX_DMACH_T_RESTRICT*/
+typedef int imx_dmach_t;
+#endif /*IMX_DMACH_T_RESTRICT*/
+
+/*
+ * The functions below could be used to strictly check, what is real DMA channel number
+ * and what are handles to DMA only
+ */
+#ifdef IMX_DMACH_T_RESTRICT
+/* This is there to check unintentional mixing of values */
+#define IMX_DMA_CH(x) ({imx_dmach_t dma_ch={x};dma_ch;})
+
+/* Channel handle to channel number */
+static inline int imx_dma_c2n(imx_dmach_t dma_ch)
+{
+	return dma_ch.dma_num;
+}
+
+/* Channel handle to channel to imx specific structure  */
+static inline struct imx_dma_channel *imx_dma_c2i(imx_dmach_t dma_ch)
+{
+	return &imx_dma_channels[dma_ch.dma_num];
+}
+
+/* Channel number to channel handle */
+static inline imx_dmach_t imx_dma_n2c(int dma_num)
+{
+	imx_dmach_t dma_ch;
+	dma_ch.dma_num=dma_num;
+	return dma_ch;
+}
+
+#else /*IMX_DMACH_T_RESTRICT*/
+#define IMX_DMA_CH(x) (x)
+
+static inline int imx_dma_c2n(imx_dmach_t dma_ch)
+{
+	return dma_ch;
+}
+
+static inline struct imx_dma_channel *imx_dma_c2i(imx_dmach_t dma_ch)
+{
+	return &imx_dma_channels[dma_ch];
+}
+
+static inline imx_dmach_t imx_dma_n2c(int dma_num)
+{
+	return dma_num;
+}
+#endif /*IMX_DMACH_T_RESTRICT*/
+
+
+
+
+unsigned int
+imx_dma_setup_mem2dev_ccr(imx_dmach_t dma_ch, dmamode_t dmamode,
+		int devwidth, unsigned int imx_mode);
+
+int
+imx_dma_setup_single2dev(imx_dmach_t dma_ch, dma_addr_t dma_address,
+		unsigned int dma_length, unsigned int dev_addr, dmamode_t dmamode);
+
+int
+imx_dma_setup_sg2dev(imx_dmach_t dma_ch,
+		 struct scatterlist *sg, unsigned int sgcount,
+		 unsigned int dev_addr, dmamode_t dmamode);
+
+int
+imx_dma_setup_handlers(imx_dmach_t dma_ch,
+		void (*irq_handler) (int, void *, struct pt_regs *),
+		void (*err_handler) (int, void *, struct pt_regs *), void *data);
+
+void imx_dma_enable(imx_dmach_t dma_ch);
+
+void imx_dma_disable(imx_dmach_t dma_ch);
+
+int imx_dma_request(imx_dmach_t dma_ch, const char *name);
+
+void imx_dma_free(imx_dmach_t dma_ch);
+
+int imx_dma_request_by_prio(imx_dmach_t *pdma_ch, const char *name, imx_dma_prio prio);
+
+
+#endif				/* _ASM_ARCH_IMX_DMA_H */
diff --git a/xen/include/asm-arm/tegra/imx-regs.h b/xen/include/asm-arm/tegra/imx-regs.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/tegra/imx-regs.h
@@ -0,0 +1,630 @@
+#ifndef _IMX_REGS_H
+#define _IMX_REGS_H
+/* ------------------------------------------------------------------------
+ *  Motorola IMX system registers
+ * ------------------------------------------------------------------------
+ *
+ */
+
+#include <asm/arch/hardware.h>
+
+#define TIMER_BASE IMX_TIM1_BASE
+
+/*
+ *  Register BASEs, based on OFFSETs
+ *
+ */
+#define IMX_AIPI1_BASE             (0x00000 + IMX_IO_BASE)
+#define IMX_DMAC_BASE              (0x01000 + IMX_IO_BASE)
+#define IMX_WDT_BASE               (0x02000 + IMX_IO_BASE)
+#define IMX_TIM1_BASE              (0x03000 + IMX_IO_BASE)
+#define IMX_TIM2_BASE              (0x04000 + IMX_IO_BASE)
+#define IMX_TIM3_BASE              (0x05000 + IMX_IO_BASE)
+#define IMX_PWM_BASE               (0x06000 + IMX_IO_BASE)
+#define IMX_RTC_BASE               (0x07000 + IMX_IO_BASE)
+#define IMX_KPP_BASE               (0x08000 + IMX_IO_BASE)
+#define IMX_OWIRE_BASE             (0x09000 + IMX_IO_BASE)
+#define IMX_UART1_BASE             (0x0A000 + IMX_IO_BASE)
+#define IMX_UART2_BASE             (0x0B000 + IMX_IO_BASE)
+#define IMX_UART3_BASE             (0x0C000 + IMX_IO_BASE)
+#define IMX_UART4_BASE             (0x0D000 + IMX_IO_BASE)
+#define IMX_CSPI1_BASE             (0x0E000 + IMX_IO_BASE)
+#define IMX_CSPI2_BASE             (0x0F000 + IMX_IO_BASE)
+#define IMX_SSI1_BASE              (0x10000 + IMX_IO_BASE)
+#define IMX_SSI2_BASE              (0x11000 + IMX_IO_BASE)
+#define IMX_I2C_BASE               (0x12000 + IMX_IO_BASE)
+#define IMX_SDHC1_BASE             (0x13000 + IMX_IO_BASE)
+#define IMX_SDHC2_BASE             (0x14000 + IMX_IO_BASE)
+#define IMX_GPIO_BASE              (0x15000 + IMX_IO_BASE)
+#define IMX_AUDMUX_BASE            (0x16000 + IMX_IO_BASE)
+#define IMX_CSPI3_BASE             (0x17000 + IMX_IO_BASE)
+#define IMX_AIPI2_BASE             (0x20000 + IMX_IO_BASE)
+#define IMX_LCDC_BASE              (0x21000 + IMX_IO_BASE)
+#define IMX_SLCDC_BASE             (0x22000 + IMX_IO_BASE)
+#define IMX_SAHARA_BASE            (0x23000 + IMX_IO_BASE)
+#define IMX_USBOTG_BASE            (0x24000 + IMX_IO_BASE)
+#define IMX_EMMA_BASE              (0x26000 + IMX_IO_BASE)
+#define IMX_CRM_BASE               (0x27000 + IMX_IO_BASE)
+#define IMX_FIRI_BASE              (0x28000 + IMX_IO_BASE)
+#define IMX_RNGA_BASE              (0x29000 + IMX_IO_BASE)
+#define IMX_RTIC_BASE              (0x2A000 + IMX_IO_BASE)
+#define IMX_JAM_BASE               (0x3E000 + IMX_IO_BASE)
+#define IMX_MAX_BASE               (0x3F000 + IMX_IO_BASE)
+#define IMX_AITC_BASE              (0x40000 + IMX_IO_BASE)
+
+#define CSCR                    __REG(IMX_CRM_BASE + 0x0)
+#define CSCR_PRESC_MASK         (0x7<<29)
+#define CSCR_PRESC(x)           (((x) & 0x7) << 29)
+#define CSCR_USB_DIV_MASK       (0x7<<26)
+#define CSCR_USB_DIV(x)         (((x) & 0x7) << 26)
+#define CSCR_SD_CNT_MASK        (0x3<<24)
+#define CSCR_SD_CNT(x)          (((x) & 0x3) << 24)
+#define CSCR_SPLL_RESTART       (1<<22)
+#define CSCR_MPLL_RESTART       (1<<21)
+#define CSCR_SSI2_SEL           (1<<20)
+#define CSCR_SSI1_SEL           (1<<19)
+#define CSCR_FIR_SEL            (1<<18)
+#define CSCR_SP_SEL             (1<<17)
+#define CSCR_MCU_SEL            (1<<16)
+#define CSCR_BCLKDIV_MASK       (0xf<<10)
+#define CSCR_BCLKDIV(x)         (((x) & 0xf) << 10)
+#define CSCR_IPDIV              (1<<9)
+#define CSCR_OSC26M_DIV1P5      (1<<4)
+#define CSCR_OSC28M_DIS         (1<<3)
+#define CSCR_FPM_EN             (1<<2)
+#define CSCR_SPEN               (1<<1)
+#define CSCR_MPEN               (1<<0)
+  
+#define MPCTL0                  __REG(IMX_CRM_BASE + 0x4)
+#define MPCTL0_CPLM             (1<<31)
+#define MPCTL0_PD(x)            (((x) & 0xf) << 26)
+#define MPCTL0_MFD(x)           (((x) & 0x3ff) << 16)
+#define MPCTL0_MFI(x)           (((x) & 0xf) << 10)
+#define MPCTL0_MFN(x)           (((x) & 0x3ff) << 0)
+  
+#define MPCTL1                   __REG(IMX_CRM_BASE + 0x8)
+#define MPCTL1_LF               (1<<15)
+#define MPCTL1_BRMO             (1<<6)
+  
+#define SPCTL0                  __REG(IMX_CRM_BASE + 0xc)
+#define SPCTL0_CPLM             (1<<31)
+#define SPCTL0_PD(x)            (((x) & 0xf) << 26)
+#define SPCTL0_MFD(x)           (((x) & 0x3ff) << 16)
+#define SPCTL0_MFI(x)           (((x) & 0xf) << 10)
+#define SPCTL0_MFN(x)           (((x) & 0x3ff) << 0)
+  
+#define SPCTL1                  __REG(IMX_CRM_BASE + 0x10)
+#define SPCTL1_LF               (1<<15)
+#define SPCTL1_BRMO             (1<<6)
+#define OSC26MCTL               __REG(IMX_CRM_BASE + 0x14)
+#define OSC26MCTL_OSC26M_PEAK   (0x2<<16)
+#define OSC25MCTL_AGC(x)        (((x) & 0x3f) << 8)
+  
+#define PCDR0                   __REG(IMX_CRM_BASE + 0x18)
+#define PCDR0_SSI2DIV(x)        (((x) & 0x3f) << 26)
+#define PCDR0_SSI2DIV_MASK      (0x3f << 26)
+#define PCDR0_SSI1DIV(x)        (((x) & 0x3f) << 16)
+#define PCDR0_SSI1DIV_MASK      (0x3f << 16)
+#define PCDR0_NFCDIV(x)         (((x) & 0xf) << 12)
+#define PCDR0_NFCDIV_MASK       (0xf << 12)
+#define PCDR0_CLKO_48MDIV(x)    (((x) & 0x7) << 5)
+#define PCDR0_FIRI_DIV(x)       (((x) & 0x1f) << 0)
+                 
+#define PCDR1                   __REG(IMX_CRM_BASE + 0x1c)
+#define PCDR1_PERDIV4_POS       24
+#define PCDR1_PERDIV4_MASK      (0x3f << PCDR1_PERDIV4_POS)
+#define PCDR1_PERDIV4(x)        (((x) << PCDR1_PERDIV4_POS) & \
+                                  PCDR1_PERDIV4_MASK)
+#define PCDR1_PERDIV3_POS       16
+#define PCDR1_PERDIV3_MASK      (0x3f << PCDR1_PERDIV3_POS)
+#define PCDR1_PERDIV3(x)        (((x) << PCDR1_PERDIV3_POS) & \
+                                  PCDR1_PERDIV3_MASK)
+#define PCDR1_PERDIV2_POS       8
+#define PCDR1_PERDIV2_MASK      (0x3f << PCDR1_PERDIV2_POS)
+#define PCDR1_PERDIV2(x)        (((x) << PCDR1_PERDIV2_POS) & \
+                                  PCDR1_PERDIV2_MASK)
+#define PCDR1_PERDIV1_POS       0
+#define PCDR1_PERDIV1_MASK      (0x3f << PCDR1_PERDIV1_POS)
+#define PCDR1_PERDIV1(x)        (((x) << PCDR1_PERDIV1_POS) & \
+                                  PCDR1_PERDIV1_MASK)
+  
+#define PCCR0                   __REG(IMX_CRM_BASE + 0x20) 
+#define PCCR0_HCLK_CSI_EN       (1<<31)
+#define PCCR0_HCLK_DMA_EN       (1<<30)
+#define PCCR0_HCLK_BROM_EN      (1<<28)
+#define PCCR0_HCLK_EMMA_EN      (1<<27)
+#define PCCR0_HCLK_LCDC_EN      (1<<26)
+#define PCCR0_HCLK_SLCDC_EN     (1<<25)
+#define PCCR0_HCLK_USBOTG_EN    (1<<24)
+#define PCCR0_HCLK_BMI_EN       (1<<23)
+#define PCCR0_PERCLK4_EN        (1<<22)
+#define PCCR0_SLCDC_EN          (1<<21)
+#define PCCR0_FIRI_BAUD_EN      (1<<20)
+#define PCCR0_NFC_EN            (1<<19)
+#define PCCR0_PERCLK3_EN        (1<<18)
+#define PCCR0_SSI1_BAUD_EN      (1<<17)
+#define PCCR0_SSI2_BAUD_EN      (1<<16)
+#define PCCR0_EMMA_EN           (1<<15)
+#define PCCR0_USBOTG_EN         (1<<14)
+#define PCCR0_DMA_EN            (1<<13)
+#define PCCR0_I2C_EN            (1<<12)
+#define PCCR0_GPIO_EN           (1<<11)
+#define PCCR0_SDHC2_EN          (1<<10)
+#define PCCR0_SDHC1_EN          (1<<9)
+#define PCCR0_FIRI_EN           (1<<8)
+#define PCCR0_SSI2_EN           (1<<7)
+#define PCCR0_SSI1_EN           (1<<6)
+#define PCCR0_CSPI2_EN          (1<<5)
+#define PCCR0_CSPI1_EN          (1<<4)
+#define PCCR0_UART4_EN          (1<<3)
+#define PCCR0_UART3_EN          (1<<2)
+#define PCCR0_UART2_EN          (1<<1)
+#define PCCR0_UART1_EN          (1<<0)
+  
+#define PCCR1                   __REG(IMX_CRM_BASE + 0x24)
+#define PCCR1_OWIRE_EN          (1<<31)
+#define PCCR1_KPP_EN            (1<<30)
+#define PCCR1_RTC_EN            (1<<29)
+#define PCCR1_PWM_EN            (1<<28)
+#define PCCR1_GPT3_EN           (1<<27)
+#define PCCR1_GPT2_EN           (1<<26)
+#define PCCR1_GPT1_EN           (1<<25)
+#define PCCR1_WDT_EN            (1<<24)
+#define PCCR1_CSPI3_EN          (1<<23)
+#define PCCR1_RTIC_EN           (1<<22)
+#define PCCR1_RNGA_EN           (1<<21)
+  
+#define CCSR                    __REG(IMX_CRM_BASE + 0x28)
+#define CCSR_32K_SR             (1<<15)
+#define CCSR_CLK0_SEL(x)        (((x) & 0x1f) << 0)
+
+#define WKGDCTL                 __REG(IMX_CRM_BASE + 0x34)
+#define WKGDCTL_WKDG_EN         (1<<0)
+
+
+/*
+ *  GPIO Module and I/O Multiplexer
+ *  x = 0..3 for reg_A, reg_B, reg_C, reg_D, reg_E, reg_F
+ */
+#define DDIR(x)    __REG2(IMX_GPIO_BASE + 0x00, ((x) & 7) << 8)
+#define OCR1(x)    __REG2(IMX_GPIO_BASE + 0x04, ((x) & 7) << 8)
+#define OCR2(x)    __REG2(IMX_GPIO_BASE + 0x08, ((x) & 7) << 8)
+#define ICONFA1(x) __REG2(IMX_GPIO_BASE + 0x0c, ((x) & 7) << 8)
+#define ICONFA2(x) __REG2(IMX_GPIO_BASE + 0x10, ((x) & 7) << 8)
+#define ICONFB1(x) __REG2(IMX_GPIO_BASE + 0x14, ((x) & 7) << 8)
+#define ICONFB2(x) __REG2(IMX_GPIO_BASE + 0x18, ((x) & 7) << 8)
+#define DR(x)      __REG2(IMX_GPIO_BASE + 0x1c, ((x) & 7) << 8)
+#define GIUS(x)    __REG2(IMX_GPIO_BASE + 0x20, ((x) & 7) << 8)
+#define SSR(x)     __REG2(IMX_GPIO_BASE + 0x24, ((x) & 7) << 8)
+#define ICR1(x)    __REG2(IMX_GPIO_BASE + 0x28, ((x) & 7) << 8)
+#define ICR2(x)    __REG2(IMX_GPIO_BASE + 0x2c, ((x) & 7) << 8)
+#define IMR(x)     __REG2(IMX_GPIO_BASE + 0x30, ((x) & 7) << 8) 
+#define ISR(x)     __REG2(IMX_GPIO_BASE + 0x34, ((x) & 7) << 8)
+#define GPR(x)     __REG2(IMX_GPIO_BASE + 0x38, ((x) & 7) << 8)
+#define SWR(x)     __REG2(IMX_GPIO_BASE + 0x3c, ((x) & 7) << 8)
+#define PUEN(x)    __REG2(IMX_GPIO_BASE + 0x40, ((x) & 7) << 8)
+#define PMASK      __REG(IMX_GPIO_BASE + 0x600)
+
+
+#define GPIO_MODE_OUT   (1<<7)
+#define GPIO_MODE_IN    (0<<7)
+#define GPIO_MODE_PUEN  (1<<8)
+
+#define GPIO_MODE_PF    (0<<9)
+#define GPIO_MODE_AF    (1<<9)
+
+#define GPIO_MODE_OCR_SHIFT 10
+#define GPIO_MODE_OCR_MASK (3<<10)
+#define GPIO_MODE_AIN   (0<<10)
+#define GPIO_MODE_BIN   (1<<10)
+#define GPIO_MODE_CIN   (2<<10)
+#define GPIO_MODE_DR    (3<<10)
+
+#define GPIO_MODE_AOUT_SHIFT 12
+#define GPIO_MODE_AOUT_MASK (3<<12)
+#define GPIO_MODE_AOUT     (0<<12)
+#define GPIO_MODE_AOUT_ISR (1<<12)
+#define GPIO_MODE_AOUT_0   (2<<12)
+#define GPIO_MODE_AOUT_1   (3<<12)
+
+#define GPIO_MODE_BOUT_SHIFT 14
+#define GPIO_MODE_BOUT_MASK (3<<14)
+#define GPIO_MODE_BOUT      (0<<14)
+#define GPIO_MODE_BOUT_ISR  (1<<14)
+#define GPIO_MODE_BOUT_0    (2<<14)
+#define GPIO_MODE_BOUT_1    (3<<14)
+#define GPIO_MODE_GIUS      (1<<16)
+
+#define GPIO_PORTA              (0<<5)
+#define GPIO_PORTB              (1<<5)
+#define GPIO_PORTC              (2<<5)
+#define GPIO_PORTD              (3<<5)
+#define GPIO_PORTE              (4<<5)
+#define GPIO_PORTF              (5<<5)
+
+
+#if 0
+#define GPIO_PORTA(bit) (0+(bit))
+#define GPIO_PORTB(bit) (32*1 + (bit))
+#define GPIO_PORTC(bit) (32*2 + (bit))
+#define GPIO_PORTD(bit) (32*3 + (bit))
+#define GPIO_PORTE(bit) (32*4 + (bit))
+#define GPIO_PORTF(bit) (32*5 + (bit))
+#endif
+
+#if 0
+/*
+ *  GPIO Mode
+ *
+ *  The pin, port, data direction, pull-up enable, primary/alternate
+ *  function, output configuration, and input configuration are encoded in a 
+ *  single word as follows.
+ *
+ *  4:0 Pin (31-0)
+ *  7:5 Port (F-A)
+ *  8 Direction
+ *  9 PUEN
+ *  10:11 Primary Function,Alternate Function
+ *  13:12 OCR
+ *  15:14 ICONF
+ * 
+ *  [ 15 14 | 13 12 | 11 10 | 9  |  8  | 7 6 5 | 4 3 2 1 0 ]
+ *  [ ICONF |  OCR  | P/A   | PU | Dir | Port  |    Pin    ]
+ */
+
+#define GPIO_PIN_MASK           0x1f
+#define GPIO_PORT_POS           5
+#define GPIO_PORT_MASK          (0x3 << GPIO_PORT_POS)
+
+#define GPIO_PORTA              (0<<GPIO_PORT_POS)
+#define GPIO_PORTB              (1<<GPIO_PORT_POS)
+#define GPIO_PORTC              (2<<GPIO_PORT_POS)
+#define GPIO_PORTD              (3<<GPIO_PORT_POS)
+#define GPIO_PORTE              (4<<GPIO_PORT_POS)
+#define GPIO_PORTF              (5<<GPIO_PORT_POS)
+
+#define GPIO_DIR_MASK           (1<<8)
+#define GPIO_IN                 (0<<8)
+#define GPIO_OUT                (1<<8)
+
+#define GPIO_PU_MASK            (1<<9)
+#define GPIO_PUDIS              (0<<9)
+#define GPIO_PUEN               (1<<9)
+
+#define GPIO_FUNC_MASK          (0x3<<10)
+#define GPIO_PF                 (0<<10)
+#define GPIO_AF                 (1<<10)
+
+#define GPIO_OCR_POS            12
+#define GPIO_OCR_MASK           (3<<GPIO_OCR_POS)
+#define GPIO_AIN                (0<<GPIO_OCR_POS)
+#define GPIO_BIN                (1<<GPIO_OCR_POS)
+#define GPIO_CIN                (2<<GPIO_OCR_POS)
+#define GPIO_GPIO               (3<<GPIO_OCR_POS)
+
+#define GPIO_ICONF_MASK         (0x3<<14)
+#define GPIO_AOUT               (1<<14)
+#define GPIO_BOUT               (2<<14)
+
+/*
+ *  The GPIO pin naming convention was developed by the original 
+ *  unknown author.  Although using defines for variables is always 
+ *  a good idea for portability,  in this case the names are as specific 
+ *  as the values, and thus lose their portability. Ultimately the pin 
+ *  names should be changed to reflect the signal name only.  
+ *
+ *  The current naming convention is as follows.
+ *
+ *  P(port)(pin)_(function)_(signal)
+ *
+ *  port = (A-F)
+ *  pin = (0-31)
+ *  function = (PF|AF|AIN|BIN|CIN|DR|AOUT|BOUT)
+ *  signal = signal name from datasheet
+ *
+ *  Remember that when in GPIO mode, AIN, BIN, CIN, and DR are inputs to 
+ *  the GPIO peripheral module and represent outputs to the pin. 
+ *  Similarly AOUT, and BOUT are outputs from the GPIO peripheral 
+ *  module and represent inputs to the physical  pin in question. 
+ *  Refer to the multiplexing table in the section titled "Signal 
+ *  Descriptions and Pin Assignments" in the reference manual.
+ */
+
+
+/* FIXME: This list is not completed. The correct directions are
+ * missing on some (many) pins
+ */
+
+#define PE14_PF_UART1_CTS       ( GPIO_PORTE | 14 | GPIO_PF | GPIO_OUT )
+#define PE15_PF_UART1_RTS       ( GPIO_PORTE | 15 | GPIO_PF | GPIO_IN )
+#define PE12_PF_UART1_TXD       ( GPIO_PORTE | 12 | GPIO_PF | GPIO_OUT )
+#define PE13_PF_UART1_RXD       ( GPIO_PORTE | 13 | GPIO_PF | GPIO_IN )
+
+#define PA5_PF_LSCLK            ( GPIO_PORTA | 5 | GPIO_PF | GPIO_OUT )
+#define PA6_PF_LD0              ( GPIO_PORTA | 6 | GPIO_PF | GPIO_OUT )
+#define PA7_PF_LD1              ( GPIO_PORTA | 7 | GPIO_PF | GPIO_OUT )
+#define PA8_PF_LD2              ( GPIO_PORTA | 8 | GPIO_PF | GPIO_OUT )
+#define PA9_PF_LD3              ( GPIO_PORTA | 9 | GPIO_PF | GPIO_OUT )
+#define PA10_PF_LD4             ( GPIO_PORTA | 10 | GPIO_PF | GPIO_OUT )
+#define PA11_PF_LD5             ( GPIO_PORTA | 11 | GPIO_PF | GPIO_OUT )
+#define PA12_PF_LD6             ( GPIO_PORTA | 12 | GPIO_PF | GPIO_OUT )
+#define PA13_PF_LD7             ( GPIO_PORTA | 13 | GPIO_PF | GPIO_OUT )
+#define PA14_PF_LD8             ( GPIO_PORTA | 14 | GPIO_PF | GPIO_OUT )
+#define PA15_PF_LD9             ( GPIO_PORTA | 15 | GPIO_PF | GPIO_OUT )
+#define PA16_PF_LD10            ( GPIO_PORTA | 16 | GPIO_PF | GPIO_OUT )
+#define PA17_PF_LD11            ( GPIO_PORTA | 17 | GPIO_PF | GPIO_OUT )
+#define PA18_PF_LD12            ( GPIO_PORTA | 18 | GPIO_PF | GPIO_OUT )
+#define PA19_PF_LD13            ( GPIO_PORTA | 19 | GPIO_PF | GPIO_OUT )
+#define PA20_PF_LD14            ( GPIO_PORTA | 20 | GPIO_PF | GPIO_OUT )
+#define PA21_PF_LD15            ( GPIO_PORTA | 21 | GPIO_PF | GPIO_OUT )
+#define PA22_PF_LD16            ( GPIO_PORTA | 22 | GPIO_PF | GPIO_OUT )
+#define PA23_PF_LD17            ( GPIO_PORTA | 23 | GPIO_PF | GPIO_OUT )
+#define PA24_PF_REV             ( GPIO_PORTA | 24 | GPIO_PF | GPIO_OUT )
+#define PA25_PF_CLS             ( GPIO_PORTA | 25 | GPIO_PF | GPIO_OUT )
+#define PA26_PF_PS              ( GPIO_PORTA | 26 | GPIO_PF | GPIO_OUT )
+#define PA27_PF_SPL_SPR         ( GPIO_PORTA | 27 | GPIO_PF | GPIO_OUT )
+#define PA28_PF_LP_HSYNC        ( GPIO_PORTA | 28 | GPIO_PF | GPIO_OUT )
+#define PA29_PF_FLM_VSYNC       ( GPIO_PORTA | 29 | GPIO_PF | GPIO_OUT )
+#define PA30_PF_CONTRAST        ( GPIO_PORTA | 30 | GPIO_PF | GPIO_OUT )
+#define PA31_PF_ACD_OE          ( GPIO_PORTA | 31 | GPIO_PF | GPIO_OUT )
+#define PE18_PF_SD_DAT0   ( GPIO_PORTE | GPIO_OUT | GPIO_PF | GPIO_PUEN | 18 )
+#define PE19_PF_SD_DAT1   ( GPIO_PORTE | GPIO_OUT | GPIO_PF | GPIO_PUEN | 19 )
+#define PE20_PF_SD_DAT2   ( GPIO_PORTE | GPIO_OUT | GPIO_PF | GPIO_PUEN | 20 )
+#define PE21_PF_SD_DAT3   ( GPIO_PORTE | GPIO_OUT | GPIO_PF | GPIO_PUEN | 21 )
+#define PE23_PF_SD_CLK    ( GPIO_PORTE | GPIO_OUT | GPIO_PF | 23 )
+#define PE22_PF_SD_CMD    ( GPIO_PORTE | GPIO_OUT | GPIO_PF | GPIO_PUEN | 22 )
+#endif
+
+/*
+ *  Watchdog Timer
+ */
+#define WCR         __REG16(IMX_WDT_BASE + 0x00)
+#define WSR         __REG16(IMX_WDT_BASE + 0x02)
+#define WRSR        __REG16(IMX_WDT_BASE + 0x04)
+#define WCR_WT(x)   (((x) & 0xff) << 8)
+#define WCR_WT_MASK (0xff << 8)
+#define WCR_WDA     (1 << 5)
+#define WCR_SRS     (1 << 4)
+#define WCR_WRE     (1 << 3)
+#define WCR_WDE     (1 << 2)
+#define WCR_WDBG    (1 << 1)
+#define WCR_WDZST   (1 << 0)
+#define WRSR_PWR    (1 << 4)
+#define WRSR_EXT    (1 << 3)
+#define WRSR_TOUT   (1 << 1)
+#define WRSR_SFTW   (1 << 0)
+
+/*
+ *  DMA Controller
+ */
+#define DCR       __REG(IMX_DMAC_BASE +0x00)	/* DMA Control Register */
+#define DISR      __REG(IMX_DMAC_BASE +0x04)	/* DMA Interrupt status Register */
+#define DIMR      __REG(IMX_DMAC_BASE +0x08)	/* DMA Interrupt mask Register */
+#define DBTOSR    __REG(IMX_DMAC_BASE +0x0c)	/* DMA Burst timeout status Register */
+#define DRTOSR    __REG(IMX_DMAC_BASE +0x10)	/* DMA Request timeout Register */
+#define DSESR     __REG(IMX_DMAC_BASE +0x14)	/* DMA Transfer Error Status Register */
+#define DBOSR     __REG(IMX_DMAC_BASE +0x18)	/* DMA Buffer overflow status Register */
+#define DBTOCR    __REG(IMX_DMAC_BASE +0x1c)	/* DMA Burst timeout control Register */
+#define WSRA      __REG(IMX_DMAC_BASE +0x40)	/* W-Size Register A */
+#define XSRA      __REG(IMX_DMAC_BASE +0x44)	/* X-Size Register A */
+#define YSRA      __REG(IMX_DMAC_BASE +0x48)	/* Y-Size Register A */
+#define WSRB      __REG(IMX_DMAC_BASE +0x4c)	/* W-Size Register B */
+#define XSRB      __REG(IMX_DMAC_BASE +0x50)	/* X-Size Register B */
+#define YSRB      __REG(IMX_DMAC_BASE +0x54)	/* Y-Size Register B */
+#define SAR(x)    __REG2( IMX_DMAC_BASE + 0x80, (x) << 6)	/* Source Address Registers */
+#define DAR(x)    __REG2( IMX_DMAC_BASE + 0x84, (x) << 6)	/* Destination Address Registers */
+#define CNTR(x)   __REG2( IMX_DMAC_BASE + 0x88, (x) << 6)	/* Count Registers */
+#define CCR(x)    __REG2( IMX_DMAC_BASE + 0x8c, (x) << 6)	/*Control Registers */
+#define RSSR(x)   __REG2( IMX_DMAC_BASE + 0x90, (x) << 6)	/* Request source select Registers */
+#define BLR(x)    __REG2( IMX_DMAC_BASE + 0x94, (x) << 6)	/* Burst length Registers */
+#define RTOR(x)   __REG2( IMX_DMAC_BASE + 0x98, (x) << 6)	/* Request timeout Registers */
+#define BUCR(x)   __REG2( IMX_DMAC_BASE + 0x98, (x) << 6)	/* Bus Utilization Registers */
+#define CHCNTR(x) __REG2( IMX_DMAC_BASE + 0x9c, (x) << 6)  /* On IMX21 only */
+#define CCNR(x)   __REG2( IMX_DMAC_BASE + 0x9C, (x) << 6) 
+#define DMA_CH_BASE(x)  (IMX_DMAC_BASE+0x080+0x040*(x))
+
+#define DCR_DAM            (1<<2)  /* On IMX21 only */
+#define DCR_DRST           (1<<1)
+#define DCR_DEN            (1<<0)
+#define DBTOCR_EN          (1<<15)
+#define DBTOCR_CNT(x)      ((x) & 0x7fff )
+#define CNTR_CNT(x)        ((x) & 0xffffff )
+#define CCR_ACRPT          ( 0x1 << 14 )  /* On IMX21 only */
+#define CCR_DMOD_LINEAR    ( 0x0 << 12 )
+#define CCR_DMOD_2D        ( 0x1 << 12 )
+#define CCR_DMOD_FIFO      ( 0x2 << 12 )
+#define CCR_DMOD_EOBFIFO   ( 0x3 << 12 )
+#define CCR_SMOD_LINEAR    ( 0x0 << 10 )
+#define CCR_SMOD_2D        ( 0x1 << 10 )
+#define CCR_SMOD_FIFO      ( 0x2 << 10 )
+#define CCR_SMOD_EOBFIFO   ( 0x3 << 10 )
+#define CCR_MDIR_INC       (0<<9)
+#define CCR_MDIR_DEC       (1<<9)
+#define CCR_MSEL_A         (0<<8)
+#define CCR_MSEL_B         (1<<8)
+#define CCR_DSIZ_32        ( 0x0 << 6 )
+#define CCR_DSIZ_8         ( 0x1 << 6 )
+#define CCR_DSIZ_16        ( 0x2 << 6 )
+#define CCR_SSIZ_32        ( 0x0 << 4 )
+#define CCR_SSIZ_8         ( 0x1 << 4 )
+#define CCR_SSIZ_16        ( 0x2 << 4 )
+#define CCR_REN            (1<<3)
+#define CCR_RPT            (1<<2)
+#define CCR_FRC            (1<<1)
+#define CCR_CEN            (1<<0)
+#define RTOR_EN            (1<<15)
+#define RTOR_CLK           (1<<14)
+#define RTOR_PSC           (1<<13)
+
+/*
+ *  General purpose timers
+ */
+#define IMX_TCTL(x)        __REG( 0x00 + (x))
+#define TCTL_SWR           (1<<15)
+#define TCTL_FRR           (1<<8)
+#define TCTL_CAP_RIS       (1<<6)
+#define TCTL_CAP_FAL       (2<<6)
+#define TCTL_CAP_RIS_FAL   (3<<6)
+#define TCTL_OM            (1<<5)
+#define TCTL_IRQEN         (1<<4)
+#define TCTL_CLK_PCLK1     (1<<1)
+#define TCTL_CLK_PCLK1_16  (2<<1)
+#define TCTL_CLK_TIN       (3<<1)
+#define TCTL_CLK_32        (4<<1)
+#define TCTL_TEN           (1<<0)
+
+#define IMX_TPRER(x)       __REG( 0x04 + (x))
+#define IMX_TCMP(x)        __REG( 0x08 + (x))
+#define IMX_TCR(x)         __REG( 0x0C + (x))
+#define IMX_TCN(x)         __REG( 0x10 + (x))
+#define IMX_TSTAT(x)       __REG( 0x14 + (x))
+#define TSTAT_CAPT         (1<<1)
+#define TSTAT_COMP         (1<<0)
+
+/*
+ *  Uart controller registers 
+ */
+
+#define UART_1  (IMX_UART1_BASE)
+#define UART_2  (IMX_UART2_BASE)
+#define UART_3  (IMX_UART3_BASE)
+#define UART_4  (IMX_UART4_BASE)
+
+
+#define URXD(x) __REG( 0x0 + (x)) /* Receiver Register */
+#define UTXD(x) __REG( 0x40 + (x)) /* Transmitter Register */
+#define UCR1(x)  __REG( 0x80 + (x)) /* Control Register 1 */
+#define UCR2(x)  __REG( 0x84 + (x)) /* Control Register 2 */
+#define UCR3(x)  __REG( 0x88 + (x)) /* Control Register 3 */
+#define UCR4(x)  __REG( 0x8c + (x)) /* Control Register 4 */
+#define UFCR(x)  __REG( 0x90 + (x)) /* FIFO Control Register */
+#define USR1(x)  __REG( 0x94 + (x)) /* Status Register 1 */
+#define USR2(x)  __REG( 0x98 + (x)) /* Status Register 2 */
+#define UESC(x)  __REG( 0x9c + (x)) /* Escape Character Register */
+#define UTIM(x)  __REG( 0xa0 + (x)) /* Escape Timer Register */
+#define UBIR(x)  __REG( 0xa4 + (x)) /* BRM Incremental Register */
+#define UBMR(x)  __REG( 0xa8 + (x)) /* BRM Modulator Register */
+#define UBRC(x)  __REG( 0xac + (x)) /* Baud Rate Count Register */
+#define ONMES(x) __REG( 0xb0 + (x)) /* One Millisecond Register */
+#define UTS(x)   __REG( 0xb4 + (x)) /* UART Test Register */
+
+
+
+/* UART Control Register Bit Fields.*/
+#define  URXD_CHARRDY    (1<<15)
+#define  URXD_ERR        (1<<14)
+#define  URXD_OVRRUN     (1<<13)
+#define  URXD_FRMERR     (1<<12)
+#define  URXD_BRK        (1<<11)
+#define  URXD_PRERR      (1<<10)
+
+#define  UCR1_ADEN       (1<<15) /* Auto dectect interrupt */
+#define  UCR1_ADBR       (1<<14) /* Auto detect baud rate */
+#define  UCR1_TRDYEN     (1<<13) /* Transmitter ready interrupt enable */
+#define  UCR1_IDEN       (1<<12) /* Idle condition interrupt */
+#define  UCR1_RRDYEN     (1<<9)  /* Recv ready interrupt enable */
+#define  UCR1_RDMAEN     (1<<8)  /* Recv ready DMA enable */
+#define  UCR1_IREN       (1<<7)  /* Infrared interface enable */
+#define  UCR1_TXMPTYEN   (1<<6)  /* Transimitter empty interrupt enable */
+#define  UCR1_RTSDEN     (1<<5)  /* RTS delta interrupt enable */
+#define  UCR1_SNDBRK     (1<<4)  /* Send break */
+#define  UCR1_TDMAEN     (1<<3)  /* Transmitter ready DMA enable */
+// not on mx21 #define  UCR1_UARTCLKEN  (1<<2)   /* UART clock enabled */
+#define  UCR1_DOZE       (1<<1)  /* Doze */
+#define  UCR1_UARTEN     (1<<0)  /* UART enabled */
+
+#define  UCR2_ESCI       (1<<15) /* Escape seq interrupt enable */
+#define  UCR2_IRTS       (1<<14) /* Ignore RTS pin */
+#define  UCR2_CTSC       (1<<13) /* CTS pin control */
+#define  UCR2_CTS        (1<<12) /* Clear to send */
+#define  UCR2_ESCEN      (1<<11) /* Escape enable */
+#define  UCR2_PREN       (1<<8)  /* Parity enable */
+#define  UCR2_PROE       (1<<7)  /* Parity odd/even */
+#define  UCR2_STPB       (1<<6)  /* Stop */
+#define  UCR2_WS         (1<<5)  /* Word size */
+#define  UCR2_RTSEN      (1<<4)  /* Request to send interrupt enable */
+#define  UCR2_ATEN       (1<<3)  /* Aging Timer Enable */
+#define  UCR2_TXEN       (1<<2)  /* Transmitter enabled */
+#define  UCR2_RXEN       (1<<1)  /* Receiver enabled */
+#define  UCR2_SRST       (1<<0)  /* SW reset */
+
+#define  UCR3_DTREN      (1<<13) /* DTR interrupt enable */
+#define  UCR3_PARERREN   (1<<12) /* Parity enable */
+#define  UCR3_FRAERREN   (1<<11) /* Frame error interrupt enable */
+#define  UCR3_DSR        (1<<10) /* Data set ready */
+#define  UCR3_DCD        (1<<9)  /* Data carrier detect */
+#define  UCR3_RI         (1<<8)  /* Ring indicator */
+#define  UCR3_ADNIMP     (1<<7)  /* Timeout interrupt enable */
+#define  UCR3_RXDSEN     (1<<6)  /* Receive status interrupt enable */
+#define  UCR3_AIRINTEN   (1<<5)  /* Async IR wake interrupt enable */
+#define  UCR3_AWAKEN     (1<<4)  /* Async wake interrupt enable */
+// not on mx21 #define  UCR3_REF25       (1<<3)  /* Ref freq 25 MHz */
+#define  UCR3_RXDMUXSEL  (1<<2)  /* RXD Mux Input Select */
+#define  UCR3_INVT       (1<<1)  /* Inverted Infrared transmission */
+#define  UCR3_ACIEN      (1<<0)  /* Autobaud Counter  Interrupt Enable */
+#define  UCR4_INVR       (1<<9)  /* Inverted infrared reception */
+#define  UCR4_ENIRI      (1<<8)  /* Serial infrared interrupt enable */
+#define  UCR4_WKEN       (1<<7)  /* Wake interrupt enable */
+// not on mx21 #define  UCR4_REF16       (1<<6)  /* Ref freq 16 MHz */
+#define  UCR4_IRSC       (1<<5)  /* IR special case */
+#define  UCR4_LPBYP      (1<<5)  /* Low Power Bypass */
+#define  UCR4_TCEN       (1<<3)  /* Transmit complete interrupt enable */
+#define  UCR4_BKEN       (1<<2)  /* Break condition interrupt enable */
+#define  UCR4_OREN       (1<<1)  /* Receiver overrun interrupt enable */
+#define  UCR4_DREN       (1<<0)  /* Recv data ready interrupt enable */
+
+/* UART_UFCR - UART FIFO Control Register - fields */
+#define UFCR_TXTL(x)  (((x) & 0x3F) << 10) /* Transmitter Trigger Level */
+#define UFCR_RFDIV(x) (((x) & 0x7) <<  7)  /* Reference Frequency Divider */
+#define UFCR_RFDIV_2       (4<<7)
+#define UFCR_TXTL_2        (2<<10)
+#define UFCR_RXTL_1        (1<<0)
+#define UFCR_RFDIV_MASK    (0x7 <<  7)
+#define UFCR_RFDIV_SHIFT   (7)
+
+#define UFCR_DCEDTE   (1 <<  6)            /* DCE/DTE Mode Select */
+#define UFCR_RXTL(x)  (((x) & 0x3F) <<  0) /* Receiver Trigger Level */
+
+
+#define  USR1_PARITYERR  (1<<15) /* Parity error interrupt flag */
+#define  USR1_RTSS       (1<<14) /* RTS pin status */
+#define  USR1_TRDY       (1<<13) /* Transmitter ready interrupt/dma flag */
+#define  USR1_RTSD       (1<<12) /* RTS delta */
+#define  USR1_ESCF       (1<<11) /* Escape seq interrupt flag */
+#define  USR1_FRAMERR    (1<<10) /* Frame error interrupt flag */
+#define  USR1_RRDY       (1<<9)  /* Receiver ready interrupt/dma flag */
+#define  USR1_AGTIM      (1<<8)  /* Aging Timer Interrupt Flag */
+// not on mx21 #define  USR1_TIMEOUT    (1<<7)   /* Receive timeout interrupt status */
+#define  USR1_RXDS       (1<<6)  /* Receiver idle interrupt flag */
+#define  USR1_AIRINT     (1<<5)  /* Async IR wake interrupt flag */
+#define  USR1_AWAKE      (1<<4)  /* Aysnc wake interrupt flag */
+
+#define  USR2_ADET       (1<<15) /* Auto baud rate detect complete */
+#define  USR2_TXFE       (1<<14) /* Transmit buffer FIFO empty */
+#define  USR2_DTRF       (1<<13) /* DTR edge interrupt flag */
+#define  USR2_IDLE       (1<<12) /* Idle condition */
+#define  USR2_ACST       (1<<11) /* Autobaud Controller Stopped*/
+#define  USR2_RIDELT     (1<<10) /* Ring Indicator Delta */
+#define  USR2_RIIN       (1<<9)  /* Ring Indicator Input*/
+#define  USR2_IRINT      (1<<8)  /* Serial infrared interrupt flag */
+#define  USR2_WAKE       (1<<7)  /* Wake */
+#define  USR2_DCDDELT    (1<<6)  /* Data Carrier Delta Detect */
+#define  USR2_DCDIN      (1<<5)  /* Data Carrier Detect Input */
+#define  USR2_RTSF       (1<<4)  /* RTS edge interrupt flag */
+#define  USR2_TXDC       (1<<3)  /* Transmitter complete */
+#define  USR2_BRCD       (1<<2)  /* Break condition */
+#define  USR2_ORE        (1<<1)  /* Overrun error */
+#define  USR2_RDR        (1<<0)  /* Recv data ready */
+#define  UTS_FRCPERR     (1<<13) /* Force parity error */
+#define  UTS_LOOP        (1<<12) /* Loop tx and rx */
+#define  UTS_DBGEN       (1<<11) /* /Debug Enable */
+#define  UTS_LOOPIR      (1<<10) /* Loop tx and rx for IR */
+#define  UTS_RXFIFO      (1<<9)  /* RXFifo Debug */
+#define  UTS_TXEMPTY     (1<<6)  /* TxFIFO empty */
+#define  UTS_RXEMPTY     (1<<5)  /* RxFIFO empty */
+#define  UTS_TXFULL      (1<<4)  /* TxFIFO full */
+#define  UTS_RXFULL      (1<<3)  /* RxFIFO full */
+#define  UTS_SOFTRST     (1<<0)  /* Software reset */
+
+
+#endif				// _IMX_REGS_H
diff --git a/xen/include/asm-arm/tegra/io.h b/xen/include/asm-arm/tegra/io.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/tegra/io.h
@@ -0,0 +1,28 @@
+/*
+ *  linux/include/asm-arm/arch-imxads/io.h
+ *
+ *  Copyright (C) 1999 ARM Limited
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+#ifndef __ASM_ARM_ARCH_IO_H
+#define __ASM_ARM_ARCH_IO_H
+
+#define IO_SPACE_LIMIT 0xffffffff
+
+#define __io(a)		((void __iomem *)(a))
+#define __mem_pci(a)	(a)
+
+#endif
diff --git a/xen/include/asm-arm/tegra/irqs.h b/xen/include/asm-arm/tegra/irqs.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/tegra/irqs.h
@@ -0,0 +1,139 @@
+/*
+ *  linux/include/asm-arm/arch-imxads/irqs.h
+ *
+ *  Copyright (C) 1999 ARM Limited
+ *  Copyright (C) 2000 Deep Blue Solutions Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef __ARM_IRQS_H__
+#define __ARM_IRQS_H__
+
+/* Use the imx definitions */
+#include <asm/arch/hardware.h>
+
+/*
+ *  IMX Interrupt numbers
+ *
+ */
+#define INT_CSPI3                   6
+#define INT_SRCL                    7
+#define INT_GPIO                    8
+#define INT_FIRI                    9
+#define INT_SDHC2                   10
+#define INT_SDHC1                   11
+#define INT_I2C                     12
+#define INT_SSI2                    13
+#define INT_SSI1                    14
+#define INT_CSPI2                   15
+#define INT_CSPI1                   16
+#define INT_UART4                   17
+#define INT_UART3                   18
+#define INT_UART2                   19
+#define INT_UART1                   20
+#define INT_KPP_TX                  21
+#define INT_RTC_RX                  22
+#define INT_PWM                     23
+#define TIM3_INT                    24
+#define TIM2_INT                    25
+#define TIM1_INT                    26
+#define INT_WDOG                    27
+#define INT_PCMCIA                  28
+#define INT_NFC                     29
+#define INT_BMI                     30
+#define INT_CSI                     31
+#define INT_DMACH0                  32
+#define INT_DMACH1                  33
+#define INT_DMACH2                  34
+#define INT_DMACH3                  35
+#define INT_DMACH4                  36
+#define INT_DMACH5                  37
+#define INT_DMACH6                  38
+#define INT_DMACH7                  39
+#define INT_DMACH8                  40
+#define INT_DMACH9                  41
+#define INT_DMACH10                 42
+#define INT_DMACH11                 43
+#define INT_DMACH12                 44
+#define INT_DMACH13                 45
+#define INT_DMACH14                 46
+#define INT_DMACH15                 47
+#define DMA_INT(x)                  (INT_DMACH0 + ((x) & 0xf))
+#define INT_EMMAENC                 49
+#define INT_EMMADEC                 50
+#define INT_EMMAPRP                 51
+#define INT_EMMAPP                  52
+#define INT_USBWKUP                 53
+#define INT_USBMNP                  54
+#define INT_USBDMA                  55
+#define INT_USBFUNC                 56
+#define INT_USBHOST                 57
+#define INT_USBCTRL                 58
+#define INT_SAHARA                  59
+#define INT_SLCDC                   60
+#define INT_LCDC                    61
+
+#define IMX_IRQS                    (64)
+
+/* note: the IMX has four gpio ports (A-D), but only
+ *       the following pins are connected to the outside
+ *       world:
+ *
+ * PORT A: bits 0-31
+ * PORT B: bits 8-31
+ * PORT C: bits 3-17
+ * PORT D: bits 6-31
+ *
+ * We map these interrupts straight on. As a result we have
+ * several holes in the interrupt mapping. We do this for two
+ * reasons:
+ *   - mapping the interrupts without holes would get
+ *     far more complicated
+ *   - Motorola could well decide to bring some processor
+ *     with more pins connected
+ */
+
+#define IRQ_GPIOA(x)  (IMX_IRQS + x)
+#define IRQ_GPIOB(x)  (IRQ_GPIOA(32) + x)
+#define IRQ_GPIOC(x)  (IRQ_GPIOB(32) + x)
+#define IRQ_GPIOD(x)  (IRQ_GPIOC(32) + x)
+
+#define IRQ_GPIOE(x)  (IRQ_GPIOD(32) + x)
+#define IRQ_GPIOF(x)  (IRQ_GPIOE(32) + x)
+#define NR_IRQS (IRQ_GPIOF(32) + 1)
+
+
+/* decode irq number to use with IMR(x), ISR(x) and friends */
+#define IRQ_TO_REG(irq) ((irq - IMX_IRQS) >> 5)
+
+#define IRQ_GPIO(x)
+
+
+/* from include/asm-arm/irq.h */ 
+#define __IRQT_FALEDGE  (1 << 0)
+#define __IRQT_RISEDGE  (1 << 1)
+#define __IRQT_LOWLVL   (1 << 2)
+#define __IRQT_HIGHLVL  (1 << 3)
+
+#define IRQT_NOEDGE     (0)
+#define IRQT_RISING     (__IRQT_RISEDGE)
+#define IRQT_FALLING    (__IRQT_FALEDGE)
+#define IRQT_BOTHEDGE   (__IRQT_RISEDGE|__IRQT_FALEDGE)
+#define IRQT_LOW        (__IRQT_LOWLVL)
+#define IRQT_HIGH       (__IRQT_HIGHLVL)
+#define IRQT_PROBE      (1 << 4)
+
+#endif
diff --git a/xen/include/asm-arm/tegra/mx1ads.h b/xen/include/asm-arm/tegra/mx1ads.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/tegra/mx1ads.h
@@ -0,0 +1,36 @@
+/*
+ * linux/include/asm-arm/arch-imx/mx1ads.h
+ *
+ * Copyright (C) 2004 Robert Schwebel, Pengutronix
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ *
+ */
+
+#ifndef __ASM_ARCH_MX1ADS_H
+#define __ASM_ARCH_MX1ADS_H
+
+/* ------------------------------------------------------------------------ */
+/* Memory Map for the M9328MX1ADS (MX1ADS) Board                            */
+/* ------------------------------------------------------------------------ */
+
+#define MX1ADS_FLASH_PHYS		0x10000000
+#define MX1ADS_FLASH_SIZE		(16*1024*1024)
+
+#define IMX_FB_PHYS			(0x0C000000 - 0x40000)
+
+#define CLK32 32000
+
+#endif /* __ASM_ARCH_MX1ADS_H */
diff --git a/xen/include/asm-arm/tegra/mx2ads.h b/xen/include/asm-arm/tegra/mx2ads.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/tegra/mx2ads.h
@@ -0,0 +1,43 @@
+/*
+ * linux/include/asm-arm/arch-imx/mx2ads.h
+ *
+ * Copyright (C) 2004 Robert Schwebel, Pengutronix
+ *
+ * Modified By: Ron Melvin (ron.melvin@timesys.com)
+ * Copyright (C) 2005 TimeSys Corporation 
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ *
+ */
+
+#ifndef __ASM_ARCH_MX2ADS_H
+#define __ASM_ARCH_MX2ADS_H
+
+/* ------------------------------------------------------------------------ */
+/* Memory Map for the M9328IMX21ADS (IMX21ADS) Board                            */
+/* ------------------------------------------------------------------------ */
+
+#define MX2ADS_FLASH_PHYS		0xc8000000
+#define MX2ADS_FLASH_SIZE		(32*1024*1024)
+
+#define CLK32 32768
+
+#define MX2ADS_ETH_VIRT IMX_CS1_VIRT
+#define MX2ADS_ETH_PHYS IMX_CS1_PHYS
+#define MX2ADS_ETH_SIZE IMX_CS1_SIZE
+#define MX2ADS_ETH_IRQ  IRQ_GPIOE(11) //INT_UART3
+
+
+#endif /* __ASM_ARCH_MX2ADS_H */
diff --git a/xen/include/asm-arm/tegra/param.h b/xen/include/asm-arm/tegra/param.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/tegra/param.h
@@ -0,0 +1,19 @@
+/*
+ *  linux/include/asm-arm/arch-imx/param.h
+ *
+ *  Copyright (C) 1999 ARM Limited
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
diff --git a/xen/include/asm-arm/tegra/system.h b/xen/include/asm-arm/tegra/system.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/tegra/system.h
@@ -0,0 +1,43 @@
+/*
+ *  linux/include/asm-arm/arch-imxads/system.h
+ *
+ *  Copyright (C) 1999 ARM Limited
+ *  Copyright (C) 2000 Deep Blue Solutions Ltd
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+#ifndef __ASM_ARCH_SYSTEM_H
+#define __ASM_ARCH_SYSTEM_H
+
+static void
+arch_idle(void)
+{
+	/*
+	 * This should do all the clock switching
+	 * and wait for interrupt tricks
+	 */
+	cpu_do_idle();
+
+}
+
+static inline void
+arch_reset(char mode)
+{
+	/* Enable watchdog and assert reset */
+	PCCR1 |= PCCR1_WDT_EN;
+	WCR = WCR_WDE;
+}
+
+#endif
diff --git a/xen/include/asm-arm/tegra/timex.h b/xen/include/asm-arm/tegra/timex.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/tegra/timex.h
@@ -0,0 +1,37 @@
+/*
+ *  linux/include/asm-arm/imx/timex.h
+ *
+ *  Copyright (C) 1999 ARM Limited
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef _ASM_ARCH_TIMEX_H_
+#define _ASM_ARCH_TIMEX_H_
+
+#define PCLK1_TICK_RATE (CLK32 * 1000)
+#define ARCH_CLOCK_TICK_RATE CLK32
+
+extern u64 get_timebase(void);
+
+typedef u64 cycles_t;
+static inline cycles_t get_cycles(void)
+{
+        cycles_t c;
+        c = get_timebase();
+        return c;
+}
+
+#endif
diff --git a/xen/include/asm-arm/tegra/uart.h b/xen/include/asm-arm/tegra/uart.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/tegra/uart.h
@@ -0,0 +1,32 @@
+#ifndef __IMX21ADS_UART_H__
+#define __IMX21ADS_UART_H__
+
+/* These parity settings can be ORed directly into the LCR. */
+#define PARITY_NONE     (0<<3)
+#define PARITY_ODD      (1<<3)
+#define PARITY_EVEN     (3<<3)
+#define PARITY_MARK     (5<<3)
+#define PARITY_SPACE    (7<<3)
+
+/* Frequency of external clock source. This definition assumes PC platform. */
+#define UART_CLOCK_HZ   1843200
+
+struct imx21ads_uart{
+        int             baud;
+        int             data_bits;
+        int             parity;
+        int             stop_bits;
+        int             irq;
+        unsigned long   io_base;   /* I/O port or memory-mapped I/O address. */
+	char *remapped_io_base;  /* Remapped virtual address of mmap I/O.  */
+	/* UART with IRQ line: interrupt-driven I/O. */
+	// struct irqaction irqaction;
+	/* UART with no IRQ line: periodically-polled I/O. */
+	// struct timer timer;
+	unsigned int timeout_ms;
+};
+
+void imx21ads_uart_init(int index, struct ns16550_defaults *defaults);
+
+#endif
+
diff --git a/xen/include/asm-arm/tegra/vmalloc.h b/xen/include/asm-arm/tegra/vmalloc.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/tegra/vmalloc.h
@@ -0,0 +1,32 @@
+/*
+ *  linux/include/asm-arm/arch-imx/vmalloc.h
+ *
+ *  Copyright (C) 2000 Russell King.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+/*
+ * Just any arbitrary offset to the start of the vmalloc VM area: the
+ * current 8MB value just means that there will be a 8MB "hole" after the
+ * physical memory until the kernel virtual memory starts.  That means that
+ * any out-of-bounds memory accesses will hopefully be caught.
+ * The vmalloc() routines leaves a hole of 4kB between each vmalloced
+ * area for the same reason. ;)
+ */
+#define VMALLOC_OFFSET	  (8*1024*1024)
+#define VMALLOC_START	  (((unsigned long)high_memory + VMALLOC_OFFSET) & ~(VMALLOC_OFFSET-1))
+#define VMALLOC_VMADDR(x) ((unsigned long)(x))
+#define VMALLOC_END       (PAGE_OFFSET + 0x10000000)
diff --git a/xen/include/asm-arm/termbits.h b/xen/include/asm-arm/termbits.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/termbits.h
@@ -0,0 +1,171 @@
+#ifndef __ASM_ARM_TERMBITS_H
+#define __ASM_ARM_TERMBITS_H
+
+typedef unsigned char	cc_t;
+typedef unsigned int	speed_t;
+typedef unsigned int	tcflag_t;
+
+#define NCCS 19
+struct termios {
+	tcflag_t c_iflag;		/* input mode flags */
+	tcflag_t c_oflag;		/* output mode flags */
+	tcflag_t c_cflag;		/* control mode flags */
+	tcflag_t c_lflag;		/* local mode flags */
+	cc_t c_line;			/* line discipline */
+	cc_t c_cc[NCCS];		/* control characters */
+};
+
+/* c_cc characters */
+#define VINTR 0
+#define VQUIT 1
+#define VERASE 2
+#define VKILL 3
+#define VEOF 4
+#define VTIME 5
+#define VMIN 6
+#define VSWTC 7
+#define VSTART 8
+#define VSTOP 9
+#define VSUSP 10
+#define VEOL 11
+#define VREPRINT 12
+#define VDISCARD 13
+#define VWERASE 14
+#define VLNEXT 15
+#define VEOL2 16
+
+/* c_iflag bits */
+#define IGNBRK	0000001
+#define BRKINT	0000002
+#define IGNPAR	0000004
+#define PARMRK	0000010
+#define INPCK	0000020
+#define ISTRIP	0000040
+#define INLCR	0000100
+#define IGNCR	0000200
+#define ICRNL	0000400
+#define IUCLC	0001000
+#define IXON	0002000
+#define IXANY	0004000
+#define IXOFF	0010000
+#define IMAXBEL	0020000
+#define IUTF8	0040000
+
+/* c_oflag bits */
+#define OPOST	0000001
+#define OLCUC	0000002
+#define ONLCR	0000004
+#define OCRNL	0000010
+#define ONOCR	0000020
+#define ONLRET	0000040
+#define OFILL	0000100
+#define OFDEL	0000200
+#define NLDLY	0000400
+#define   NL0	0000000
+#define   NL1	0000400
+#define CRDLY	0003000
+#define   CR0	0000000
+#define   CR1	0001000
+#define   CR2	0002000
+#define   CR3	0003000
+#define TABDLY	0014000
+#define   TAB0	0000000
+#define   TAB1	0004000
+#define   TAB2	0010000
+#define   TAB3	0014000
+#define   XTABS	0014000
+#define BSDLY	0020000
+#define   BS0	0000000
+#define   BS1	0020000
+#define VTDLY	0040000
+#define   VT0	0000000
+#define   VT1	0040000
+#define FFDLY	0100000
+#define   FF0	0000000
+#define   FF1	0100000
+
+/* c_cflag bit meaning */
+#define CBAUD	0010017
+#define  B0	0000000		/* hang up */
+#define  B50	0000001
+#define  B75	0000002
+#define  B110	0000003
+#define  B134	0000004
+#define  B150	0000005
+#define  B200	0000006
+#define  B300	0000007
+#define  B600	0000010
+#define  B1200	0000011
+#define  B1800	0000012
+#define  B2400	0000013
+#define  B4800	0000014
+#define  B9600	0000015
+#define  B19200	0000016
+#define  B38400	0000017
+#define EXTA B19200
+#define EXTB B38400
+#define CSIZE	0000060
+#define   CS5	0000000
+#define   CS6	0000020
+#define   CS7	0000040
+#define   CS8	0000060
+#define CSTOPB	0000100
+#define CREAD	0000200
+#define PARENB	0000400
+#define PARODD	0001000
+#define HUPCL	0002000
+#define CLOCAL	0004000
+#define CBAUDEX 0010000
+#define    B57600 0010001
+#define   B115200 0010002
+#define   B230400 0010003
+#define   B460800 0010004
+#define   B500000 0010005
+#define   B576000 0010006
+#define   B921600 0010007
+#define  B1000000 0010010
+#define  B1152000 0010011
+#define  B1500000 0010012
+#define  B2000000 0010013
+#define  B2500000 0010014
+#define  B3000000 0010015
+#define  B3500000 0010016
+#define  B4000000 0010017
+#define CIBAUD	  002003600000	/* input baud rate (not used) */
+#define CMSPAR    010000000000		/* mark or space (stick) parity */
+#define CRTSCTS	  020000000000		/* flow control */
+
+/* c_lflag bits */
+#define ISIG	0000001
+#define ICANON	0000002
+#define XCASE	0000004
+#define ECHO	0000010
+#define ECHOE	0000020
+#define ECHOK	0000040
+#define ECHONL	0000100
+#define NOFLSH	0000200
+#define TOSTOP	0000400
+#define ECHOCTL	0001000
+#define ECHOPRT	0002000
+#define ECHOKE	0004000
+#define FLUSHO	0010000
+#define PENDIN	0040000
+#define IEXTEN	0100000
+
+/* tcflow() and TCXONC use these */
+#define	TCOOFF		0
+#define	TCOON		1
+#define	TCIOFF		2
+#define	TCION		3
+
+/* tcflush() and TCFLSH use these */
+#define	TCIFLUSH	0
+#define	TCOFLUSH	1
+#define	TCIOFLUSH	2
+
+/* tcsetattr uses these */
+#define	TCSANOW		0
+#define	TCSADRAIN	1
+#define	TCSAFLUSH	2
+
+#endif	/* __ASM_ARM_TERMBITS_H */
diff --git a/xen/include/asm-arm/time.h b/xen/include/asm-arm/time.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/time.h
@@ -0,0 +1,20 @@
+#ifndef __ARM_TIME_H__
+#define __ARM_TIME_H__
+
+#include <xen/types.h>
+#include <asm/bug.h>
+
+typedef u64 cycles_t;
+
+static inline cycles_t get_cycles(void)
+{
+	BUG();
+	return 0;
+}
+
+s_time_t get_s_time(void);
+
+struct tm;
+struct tm wallclock_time(void);
+
+#endif /* __ARM_TIME_H__ */
diff --git a/xen/include/asm-arm/tlb.h b/xen/include/asm-arm/tlb.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/tlb.h
@@ -0,0 +1,58 @@
+/*
+ * tlb.h
+ *
+ * Copyright (C) 2008 Samsung Electronics
+ *          SungKwan Heo  <sk.heo@samsung.com>
+ *          JaeMin Ryu  <jm77.ryu@samsung.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public version 2 of License as published by
+ * the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+#ifndef __ASM_TLB_H__
+#define __ASM_TLB_H__
+
+#include <xen/config.h>
+#include <xen/smp.h>
+
+#define TLB_V3_PAGE		(1 << 0)
+#define TLB_V4_U_PAGE   (1 << 1)
+#define TLB_V4_D_PAGE   (1 << 2)
+#define TLB_V4_I_PAGE   (1 << 3)
+#define TLB_V6_U_PAGE   (1 << 4)
+#define TLB_V6_D_PAGE   (1 << 5)
+#define TLB_V6_I_PAGE   (1 << 6)
+
+#define TLB_V3_FULL		(1 << 8)
+#define TLB_V4_U_FULL   (1 << 9)
+#define TLB_V4_D_FULL   (1 << 10)
+#define TLB_V4_I_FULL   (1 << 11)
+#define TLB_V6_U_FULL   (1 << 12)
+#define TLB_V6_D_FULL   (1 << 13)
+#define TLB_V6_I_FULL   (1 << 14)
+
+#define TLB_V6_U_ASID   (1 << 16)
+#define TLB_V6_D_ASID   (1 << 17)
+#define TLB_V6_I_ASID   (1 << 18)
+
+#define TLB_DCLEAN		(1 << 30)
+#define TLB_WB			(1 << 31)
+
+
+#define TLB_CAP_UNIFIED		(1 << 0)
+#define TLB_CAP_ASID		(1 << 1)
+
+#define local_flush_tlb(mask)
+
+#define flush_tlb_mask(mask)		local_flush_tlb()
+
+#endif /* __ASM_TLB_H__ */
diff --git a/xen/include/asm-arm/trace.h b/xen/include/asm-arm/trace.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/trace.h
@@ -0,0 +1,4 @@
+#ifndef __ARM_TRACE_H__
+#define __ARM_TRACE_H__
+
+#endif /* __ARM_TRACE_H__ */
diff --git a/xen/include/asm-arm/trap.h b/xen/include/asm-arm/trap.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/trap.h
@@ -0,0 +1,35 @@
+/*
+ * trap.h
+ *
+ * Copyright (C) 2008 Samsung Electronics
+ *          JaeMin Ryu  <jm77.ryu@samsung.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public version 2 of License as published by
+ * the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+#ifndef __TRAP_H__
+#define __TRAP_H__
+
+#define EXCEPTION_RESET			(0)
+#define EXCEPTION_UNDEF			(1)
+#define EXCEPTION_SWI			(2)
+#define EXCEPTION_PABT			(3)
+#define EXCEPTION_DABT			(4)
+#define EXCEPTION_RESERVED		(5)
+#define EXCEPTION_IRQ			(6)
+#define EXCEPTION_FIQ			(7)
+
+#if 0
+void trap_init(void);
+#endif
+#endif
diff --git a/xen/include/asm-arm/types.h b/xen/include/asm-arm/types.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/types.h
@@ -0,0 +1,49 @@
+#ifndef __ARM_TYPES_H__
+#define __ARM_TYPES_H__
+
+#ifndef __ASSEMBLY__
+
+#include <xen/config.h>
+
+typedef __signed__ char __s8;
+typedef unsigned char __u8;
+
+typedef __signed__ short __s16;
+typedef unsigned short __u16;
+
+typedef __signed__ int __s32;
+typedef unsigned int __u32;
+
+#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
+typedef __signed__ long long __s64;
+typedef unsigned long long __u64;
+#endif
+
+typedef signed char s8;
+typedef unsigned char u8;
+
+typedef signed short s16;
+typedef unsigned short u16;
+
+typedef signed int s32;
+typedef unsigned int u32;
+
+typedef signed long long s64;
+typedef unsigned long long u64;
+typedef u32 paddr_t;
+#define INVALID_PADDR (~0ULL)
+#define PRIpaddr "016llx"
+
+typedef unsigned long size_t;
+
+typedef char bool_t;
+#define test_and_set_bool(b)   xchg(&(b), 1)
+#define test_and_clear_bool(b) xchg(&(b), 0)
+
+#endif /* __ASSEMBLY__ */
+
+#define BITS_PER_LONG 32
+#define BYTES_PER_LONG 4
+#define LONG_BYTEORDER 2
+
+#endif /* __ARM_TYPES_H__ */
diff --git a/xen/include/asm-arm/uaccess.h b/xen/include/asm-arm/uaccess.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/uaccess.h
@@ -0,0 +1,398 @@
+#ifndef __ASM_UACCESS_H__
+#define __ASM_UACCESS_H__
+
+#include <xen/errno.h>
+
+#define VERIFY_READ		0
+#define VERIFY_WRITE		1
+
+#define __range_ok(addr, size)						\
+	({								\
+		unsigned long flags, sum;				\
+		__asm__("adds	%1, %2, %3\n\t"				\
+			"sbcccs	%1, %1, %0\n\t"				\
+			"movcc	%0, #0"					\
+			: "=&r"(flags), "=&r"(sum)			\
+			: "r"(addr), "Ir"(size), "0"(HYPERVISOR_VIRT_START) \
+			: "cc");					\
+		flags;							\
+	})
+
+#define __addr_ok(addr)	((unsigned long)(addr) < HYPERVISOR_VIRT_START)
+
+#define access_ok(addr,size)	(__range_ok(addr,size) == 0)
+
+#define access_ok_type(type,addr,size)	access_ok(addr,size)
+
+#define array_access_ok(addr,count,size) 				\
+	(likely(count < ((~0UL)/size)) && access_ok(addr,count*size))
+
+#define verify_area(type, addr, size)					\
+	(access_ok(type, addr, size) ? 0 : -EFAULT)
+
+
+/*
+ * Single-value transfer routines.  They automatically use the right
+ * size if we just have the right pointer type.  Note that the functions
+ * which read from user space (*get_*) need to take care not to leak
+ * kernel data even if the calling code is buggy and fails to check
+ * the return value.  This means zeroing out the destination variable
+ * or buffer on error.  Normally this is done out of line by the
+ * fixup code, but there are a few places where it intrudes on the
+ * main code path.  When we only write to user space, there is no
+ * problem.
+ *
+ * The "__xxx" versions of the user access functions do not verify the
+ * address space - it must have been done previously with a separate
+ * "access_ok()" call.
+ *
+ * The "xxx_error" versions set the third argument to EFAULT if an
+ * error occurs, and leave it unchanged on success.  Note that these
+ * versions are void (ie, don't return a value as such).
+ */
+
+extern int __get_user_1(void *);
+extern int __get_user_2(void *);
+extern int __get_user_4(void *);
+extern int __get_user_8(void *);
+extern int __get_user_bad(void);
+
+#define __get_user_x(__r2,__p,__e,__s,__i...)			\
+	   __asm__ __volatile__ (							\
+		__asmeq("%0", "r0") __asmeq("%1", "r2")			\
+		"bl	__get_user_" #__s							\
+		: "=&r" (__e), "=r" (__r2)						\
+		: "0" (__p)										\
+		: __i, "cc")
+
+#define get_user(x,p)							\
+	({								\
+		const register typeof(*(p)) *__p asm("r0") = (p);\
+		register typeof(*(p)) __r2 asm("r2");			\
+		register int __e asm("r0");				\
+		switch (sizeof(*(__p))) {				\
+		case 1:							\
+			__get_user_x(__r2, __p, __e, 1, "lr");		\
+	       		break;						\
+		case 2:							\
+			__get_user_x(__r2, __p, __e, 2, "r3", "lr");	\
+			break;						\
+		case 4:							\
+	       		__get_user_x(__r2, __p, __e, 4, "lr");		\
+			break;						\
+		case 8:							\
+			__get_user_x(__r2, __p, __e, 8, "lr");		\
+	       		break;						\
+		default: __e = __get_user_bad(); break;			\
+		}							\
+		x = __r2;						\
+		__e;							\
+	})
+
+#define __get_user(x,ptr)						\
+({									\
+	long __gu_err = 0;						\
+	__get_user_err((x),(ptr),__gu_err);				\
+	__gu_err;							\
+})
+
+#define __get_user_error(x,ptr,err)					\
+({									\
+	__get_user_err((x),(ptr),err);					\
+	(void) 0;							\
+})
+
+#define __get_user_err(x,ptr,err)					\
+do {									\
+	unsigned long __gu_addr = (unsigned long)(ptr);			\
+	unsigned long __gu_val;						\
+	/*__chk_user_ptr(ptr);*/					\
+	switch (sizeof(*(ptr))) {					\
+	case 1:	__get_user_asm_byte(__gu_val,__gu_addr,err);	break;	\
+	case 2:	__get_user_asm_half(__gu_val,__gu_addr,err);	break;	\
+	case 4:	__get_user_asm_word(__gu_val,__gu_addr,err);	break;	\
+	default: (__gu_val) = __get_user_bad();				\
+	}								\
+	(x) = (__typeof__(*(ptr)))__gu_val;				\
+} while (0)
+
+#define __get_user_asm_byte(x,addr,err)					\
+	__asm__ __volatile__(						\
+	"1:	ldrbt	%1,[%2],#0\n"					\
+	"2:\n"								\
+	"	.section .fixup,\"ax\"\n"				\
+	"	.align	2\n"						\
+	"3:	mov	%0, %3\n"					\
+	"	mov	%1, #0\n"					\
+	"	b	2b\n"						\
+	"	.previous\n"						\
+	"	.section .extable,\"a\"\n"				\
+	"	.align	3\n"						\
+	"	.long	1b, 3b\n"					\
+	"	.previous"						\
+	: "+r" (err), "=&r" (x)						\
+	: "r" (addr), "i" (-EFAULT)					\
+	: "cc")
+
+#ifndef __ARMEB__
+#define __get_user_asm_half(x,__gu_addr,err)				\
+({									\
+	unsigned long __b1, __b2;					\
+	__get_user_asm_byte(__b1, __gu_addr, err);			\
+	__get_user_asm_byte(__b2, __gu_addr + 1, err);			\
+	(x) = __b1 | (__b2 << 8);					\
+})
+#else
+#define __get_user_asm_half(x,__gu_addr,err)				\
+({									\
+	unsigned long __b1, __b2;					\
+	__get_user_asm_byte(__b1, __gu_addr, err);			\
+	__get_user_asm_byte(__b2, __gu_addr + 1, err);			\
+	(x) = (__b1 << 8) | __b2;					\
+})
+#endif
+
+#define __get_user_asm_word(x,addr,err)					\
+	__asm__ __volatile__(						\
+	"1:	ldrt	%1,[%2],#0\n"					\
+	"2:\n"								\
+	"	.section .fixup,\"ax\"\n"				\
+	"	.align	2\n"						\
+	"3:	mov	%0, %3\n"					\
+	"	mov	%1, #0\n"					\
+	"	b	2b\n"						\
+	"	.previous\n"						\
+	"	.section .extable,\"a\"\n"				\
+	"	.align	3\n"						\
+	"	.long	1b, 3b\n"					\
+	"	.previous"						\
+	: "+r" (err), "=&r" (x)						\
+	: "r" (addr), "i" (-EFAULT)					\
+	: "cc")
+
+
+extern int __put_user_1(void *, unsigned int);
+extern int __put_user_2(void *, unsigned int);
+extern int __put_user_4(void *, unsigned int);
+extern int __put_user_8(void *, unsigned long long);
+extern int __put_user_bad(void);
+
+#define __put_user_x(__r2,__p,__e,__s)					\
+	   __asm__ __volatile__ (					\
+		__asmeq("%0", "r0") __asmeq("%2", "r2")			\
+		"bl	__put_user_" #__s				\
+		: "=&r" (__e)						\
+		: "0" (__p), "r" (__r2)					\
+		: "ip", "lr", "cc")
+
+#define put_user(x,p)							\
+	({								\
+		const register typeof(*(p)) __r2 asm("r2") = (x);	\
+		const register typeof(*(p)) *__p asm("r0") = (p);\
+		register int __e asm("r0");				\
+		switch (sizeof(*(__p))) {				\
+		case 1:							\
+			__put_user_x(__r2, __p, __e, 1);		\
+			break;						\
+		case 2:							\
+			__put_user_x(__r2, __p, __e, 2);		\
+			break;						\
+		case 4:							\
+			__put_user_x(__r2, __p, __e, 4);		\
+			break;						\
+		case 8:							\
+			__put_user_x(__r2, __p, __e, 8);		\
+			break;						\
+		default: __e = __put_user_bad(); break;			\
+		}							\
+		__e;							\
+	})
+
+#define __put_user(x,ptr)						\
+	({								\
+		long __pu_err = 0;					\
+		__put_user_err((x),(ptr),__pu_err);			\
+		__pu_err;						\
+	})
+
+#define __put_user_error(x,ptr,err)					\
+	({								\
+		__put_user_err((x),(ptr),err);				\
+		(void) 0;						\
+	})
+
+#define __put_user_err(x,ptr,err)					\
+	do {								\
+	unsigned long __pu_addr = (unsigned long)(ptr);			\
+	__typeof__(*(ptr)) __pu_val = (x);				\
+	/* __chk_user_ptr(ptr);	*/					\
+	switch (sizeof(*(ptr))) {					\
+	case 1: __put_user_asm_byte(__pu_val,__pu_addr,err);	break;	\
+	case 2: __put_user_asm_half(__pu_val,__pu_addr,err);	break;	\
+	case 4: __put_user_asm_word(__pu_val,__pu_addr,err);	break;	\
+	case 8:	__put_user_asm_dword(__pu_val,__pu_addr,err);	break;	\
+	default: __put_user_bad();					\
+	}								\
+} while (0)
+
+#define __put_user_asm_byte(x,__pu_addr,err)				\
+	__asm__ __volatile__(						\
+	"1:	strbt	%1,[%2],#0\n"					\
+	"2:\n"								\
+	"	.section .fixup,\"ax\"\n"				\
+	"	.align	2\n"						\
+	"3:	mov	%0, %3\n"					\
+	"	b	2b\n"						\
+	"	.previous\n"						\
+	"	.section .extable,\"a\"\n"				\
+	"	.align	3\n"						\
+	"	.long	1b, 3b\n"					\
+	"	.previous"						\
+	: "+r" (err)							\
+	: "r" (x), "r" (__pu_addr), "i" (-EFAULT)			\
+	: "cc")
+
+#ifndef __ARMEB__
+#define __put_user_asm_half(x,__pu_addr,err)				\
+({									\
+	unsigned long __temp = (unsigned long)(x);			\
+	__put_user_asm_byte(__temp, __pu_addr, err);			\
+	__put_user_asm_byte(__temp >> 8, __pu_addr + 1, err);		\
+})
+#else
+#define __put_user_asm_half(x,__pu_addr,err)				\
+({									\
+	unsigned long __temp = (unsigned long)(x);			\
+	__put_user_asm_byte(__temp >> 8, __pu_addr, err);		\
+	__put_user_asm_byte(__temp, __pu_addr + 1, err);		\
+})
+#endif
+
+#define __put_user_asm_word(x,__pu_addr,err)				\
+	__asm__ __volatile__(						\
+	"1:	strt	%1,[%2],#0\n"					\
+	"2:\n"								\
+	"	.section .fixup,\"ax\"\n"				\
+	"	.align	2\n"						\
+	"3:	mov	%0, %3\n"					\
+	"	b	2b\n"						\
+	"	.previous\n"						\
+	"	.section .extable,\"a\"\n"				\
+	"	.align	3\n"						\
+	"	.long	1b, 3b\n"					\
+	"	.previous"						\
+	: "+r" (err)							\
+	: "r" (x), "r" (__pu_addr), "i" (-EFAULT)			\
+	: "cc")
+
+#ifndef __ARMEB__
+#define	__reg_oper0	"%R2"
+#define	__reg_oper1	"%Q2"
+#else
+#define	__reg_oper0	"%Q2"
+#define	__reg_oper1	"%R2"
+#endif
+
+#define __put_user_asm_dword(x,__pu_addr,err)				\
+	__asm__ __volatile__(						\
+	"1:	strt	" __reg_oper1 ", [%1], #4\n"			\
+	"2:	strt	" __reg_oper0 ", [%1], #0\n"			\
+	"3:\n"								\
+	"	.section .fixup,\"ax\"\n"				\
+	"	.align	2\n"						\
+	"4:	mov	%0, %3\n"					\
+	"	b	3b\n"						\
+	"	.previous\n"						\
+	"	.section .extable,\"a\"\n"				\
+	"	.align	3\n"						\
+	"	.long	1b, 4b\n"					\
+	"	.long	2b, 4b\n"					\
+	"	.previous"						\
+	: "+r" (err), "+r" (__pu_addr)					\
+	: "r" (x), "i" (-EFAULT)					\
+	: "cc")
+
+
+extern unsigned long __arch_copy_from_user(void *to, const void *from, unsigned long n);
+extern unsigned long __arch_copy_to_user(void *to, const void *from, unsigned long n);
+extern unsigned long __arch_clear_user(void *addr, unsigned long n);
+extern unsigned long __arch_strncpy_from_user(char *to, const char *from, unsigned long count);
+extern unsigned long __arch_strnlen_user(const char *s, long n);
+
+
+static inline unsigned long __copy_from_user(void *to, const void *from, unsigned long n)
+{
+	return __arch_copy_from_user(to, from, n);
+}
+
+
+static inline unsigned long __copy_to_user(void *to, const void *from, unsigned long n)
+{
+	return __arch_copy_to_user(to, from, n);
+}
+
+#define __copy_to_user_inatomic __copy_to_user
+#define __copy_from_user_inatomic __copy_from_user
+
+
+static inline unsigned long __clear_user (void *to, unsigned long n)
+{
+	return __arch_clear_user(to, n);
+}
+
+
+static inline long __strncpy_from_user (char *dst, const char *src, long count)
+{
+	return __arch_strncpy_from_user(dst, src, count);
+}
+
+static inline unsigned long copy_from_user(void *to, const void *from, unsigned long n)
+{
+	if (access_ok_type(VERIFY_READ, from, n))
+		n = __arch_copy_from_user(to, from, n);
+	else /* security hole - plug it */
+		memset(to, 0, n);
+	return n;
+}
+
+static inline unsigned long copy_to_user(void *to, const void *from, unsigned long n)
+{
+	if (access_ok_type(VERIFY_WRITE, to, n))
+		n = __arch_copy_to_user(to, from, n);
+	return n;
+}
+
+static inline unsigned long clear_user (void *to, unsigned long n)
+{
+	if (access_ok_type(VERIFY_WRITE, to, n))
+		n = __arch_clear_user(to, n);
+	return n;
+}
+
+static inline long strncpy_from_user (char *dst, const char *src, long count)
+{
+	long res = -EFAULT;
+	if (access_ok_type(VERIFY_READ, src, 1))
+		res = __arch_strncpy_from_user(dst, src, count);
+	return res;
+}
+
+#define strlen_user(s)	strnlen_user(s, ~0UL >> 1)
+
+static inline long strnlen_user(const char *s, long n)
+{
+	unsigned long res = 0;
+
+	if (__addr_ok(s))
+		res = __arch_strnlen_user(s, n);
+
+	return res;
+}
+
+struct extable_entry {
+	unsigned long instr, fixup;
+};
+
+unsigned long search_extable(unsigned long);
+void sort_extables(void);
+#endif 
diff --git a/xen/include/asm-arm/uart.h b/xen/include/asm-arm/uart.h
new file mode 100755
--- /dev/null
+++ b/xen/include/asm-arm/uart.h
@@ -0,0 +1,20 @@
+#ifndef __DEVICE_UART_H__
+#define __DEVICE_UART_H__
+
+/* These parity settings can be ORed directly into the LCR. */
+#define PARITY_NONE     (0<<3)
+#define PARITY_ODD      (1<<3)
+#define PARITY_EVEN     (3<<3)
+#define PARITY_MARK     (5<<3)
+#define PARITY_SPACE    (7<<3)
+
+struct uart {
+	int	baud;
+        int	data_bits;
+        int	parity;
+        int	stop_bits;
+        int	irq;
+};
+
+#endif
+
diff --git a/xen/include/asm-arm/xenoprof.h b/xen/include/asm-arm/xenoprof.h
new file mode 100644
--- /dev/null
+++ b/xen/include/asm-arm/xenoprof.h
@@ -0,0 +1,56 @@
+#ifndef __ASM_ARM_XENOPROF_H__
+#define __ASM_ARM_XENOPROF_H__
+
+#include <xen/errno.h>
+
+int xenoprof_arch_init(int *num_events, char *cpu_type);
+int xenoprof_arch_reserve_counters(void);
+int xenoprof_arch_counter(XEN_GUEST_HANDLE(void) arg);
+int xenoprof_arch_setup_events(void);
+int xenoprof_arch_enable_virq(void);
+int xenoprof_arch_start(void);
+void xenoprof_arch_stop(void);
+void xenoprof_arch_disable_virq(void);
+void xenoprof_arch_release_counters(void);
+
+static inline int xenoprof_arch_ibs_counter(XEN_GUEST_HANDLE(void) arg)
+{
+    return -ENOSYS;  /* not supported */
+}
+/* AMD IBS not supported */
+#define ibs_caps	0
+
+struct vcpu;
+struct cpu_user_regs;
+
+int xenoprofile_get_mode(struct vcpu *v, struct cpu_user_regs * const regs);
+static inline int xenoprof_backtrace_supported(void)
+{
+    return 0;
+}
+static inline void xenoprof_backtrace(
+    struct domain *d, struct vcpu *vcpu,
+    struct cpu_user_regs *const regs, unsigned long depth, int mode)
+{
+    /* To be implemented */
+    return;
+}
+#define xenoprof_shared_gmfn(d, gmaddr, maddr)                      \
+do {                                                                \
+    unsigned long ret;                                              \
+    ret = create_grant_host_mapping((gmaddr),                       \
+                                    (maddr) >> PAGE_SHIFT, 0, 0);   \
+    BUG_ON(ret != GNTST_okay);                                      \
+} while (0)
+
+#endif /* __ASM_ARM_XENOPROF_H__ */
+
+/*
+ * Local variables:
+ * mode: C
+ * c-set-style: "BSD"
+ * c-basic-offset: 4
+ * tab-width: 4
+ * indent-tabs-mode: nil
+ * End:
+ */
diff --git a/xen/include/public/arch-arm.h b/xen/include/public/arch-arm.h
new file mode 100644
--- /dev/null
+++ b/xen/include/public/arch-arm.h
@@ -0,0 +1,153 @@
+/*
+ * Guest OS interface to ARM Xen.
+ *
+ * Based on ARM Xen 3.0, Copyright (c) samsung electronics, co.
+ */
+
+#ifndef __XEN_PUBLIC_ARCH_ARM_H__
+#define __XEN_PUBLIC_ARCH_ARM_H__
+
+#define CMD_FMRX	0
+#define CMD_FMXR	1
+
+#define FPEXC_XEN       0
+#define FPINST_XEN      1
+#define FPINST2_XEN     2
+
+/* FPEXC bits */
+#define FPEXC_EXCEPTION     (1<<31)
+#define FPEXC_ENABLE        (1<<30)
+
+#ifndef __ASSEMBLY__
+
+/* Structural guest handles introduced in 0x00030201. */
+#if __XEN_INTERFACE_VERSION__ >= 0x00030201
+#define ___DEFINE_XEN_GUEST_HANDLE(name, type) \
+    typedef struct { type *p; } __guest_handle_ ## name
+#else
+#define ___DEFINE_XEN_GUEST_HANDLE(name, type) \
+    typedef type * __guest_handle_ ## name
+#endif
+
+#define __DEFINE_XEN_GUEST_HANDLE(name, type) \
+    ___DEFINE_XEN_GUEST_HANDLE(name, type);   \
+    ___DEFINE_XEN_GUEST_HANDLE(const_##name, const type)
+
+#define DEFINE_XEN_GUEST_HANDLE(name)   __DEFINE_XEN_GUEST_HANDLE(name, name)
+#define XEN_GUEST_HANDLE(name)          __guest_handle_ ## name
+#define XEN_GUEST_HANDLE_64(name)       XEN_GUEST_HANDLE(name)
+#define uint64_aligned_t                uint64_t
+#define set_xen_guest_handle_raw(hnd, val)  do { (hnd).p = val; } while (0)
+#ifdef __XEN_TOOLS__
+#define get_xen_guest_handle(val, hnd)  do { val = (hnd).p; } while (0)
+#endif
+#define set_xen_guest_handle(hnd, val) set_xen_guest_handle_raw(hnd, val)
+
+typedef unsigned long xen_pfn_t;
+#define PRI_xen_pfn "lx"
+
+typedef unsigned long xen_ulong_t;
+
+#ifdef __XEN_TOOLS__
+#define XEN_PAGE_SIZE XC_PAGE_SIZE
+#else
+#define XEN_PAGE_SIZE PAGE_SIZE
+#endif
+
+#define INVALID_MFN       (~0UL)
+
+/*
+ * Virtual addresses beyond this are not modifiable by guest OSes. The
+ * machine->physical mapping table starts at this address, read-only.
+ */
+#define __HYPERVISOR_VIRT_START 0xFC000000
+
+#ifndef HYPERVISOR_VIRT_START
+#define HYPERVISOR_VIRT_START mk_unsigned_long(__HYPERVISOR_VIRT_START)
+#endif
+
+#ifndef machine_to_phys_mapping
+#define machine_to_phys_mapping ((unsigned long *)HYPERVISOR_VIRT_START)
+#endif
+
+typedef struct cpu_user_regs
+{
+	unsigned long	r0;
+	unsigned long	r1;
+	unsigned long	r2;
+	unsigned long	r3;
+	unsigned long	r4;
+	unsigned long	r5;
+	unsigned long	r6;
+	unsigned long	r7;
+	unsigned long	r8;
+	unsigned long	r9;
+	unsigned long	r10;
+	unsigned long	r11;
+	unsigned long	r12;
+	unsigned long	r13;
+	unsigned long	r14;
+	unsigned long	r15;
+	unsigned long	psr;
+	unsigned long	ctx;
+
+	/* sys regs */
+	unsigned long	cpar;
+	unsigned long	cr;
+	unsigned long	dacr;
+	unsigned long	pidr;
+} cpu_user_regs_t;
+
+typedef cpu_user_regs_t	cpu_bounce_frame_t;
+
+typedef struct trap_info {
+	unsigned long flags;
+	unsigned long address;
+} trap_info_t;
+DEFINE_XEN_GUEST_HANDLE(trap_info_t);
+
+typedef struct vcpu_guest_context {
+	cpu_user_regs_t user_regs;
+	unsigned long event_callback;
+	unsigned long failsafe_callback; /* Address of failsafe callback  */
+} vcpu_guest_context_t;
+DEFINE_XEN_GUEST_HANDLE(vcpu_guest_context_t);
+
+typedef struct trap_frame {
+	unsigned long sp;
+	unsigned long lr;
+	unsigned long spsr;
+	unsigned long trap;
+}trap_frame_t;
+DEFINE_XEN_GUEST_HANDLE(trap_frame_t);
+
+typedef struct arch_vcpu_info {
+	unsigned long	sp;
+	unsigned long	lr;
+	unsigned long	trap;
+	unsigned long	spsr;
+	unsigned long	cr;
+	unsigned long	cpar;
+	unsigned long	dacr;
+	unsigned long	pidr;
+	unsigned long	far;
+	unsigned long	fsr;
+	unsigned long	reserved10;
+	unsigned long	reserved11;
+	unsigned long	reserved12;
+	unsigned long	reserved13;
+	unsigned long	reserved14;
+} arch_vcpu_info_t;
+
+/* Maximum number of virtual CPUs. */
+#define XEN_LEGACY_MAX_VCPUS	1
+#define MAX_VIRT_CPUS		1
+
+typedef struct arch_shared_info {
+	unsigned long	max_pfn;
+	unsigned long	pfn_to_mfn_frame_list_list;
+	unsigned long	nmi_reason;
+} arch_shared_info_t;
+
+#endif
+#endif /* __XEN_PUBLIC_ARCH_ARM_H__ */
diff --git a/xen/include/public/xen.h b/xen/include/public/xen.h
--- a/xen/include/public/xen.h
+++ b/xen/include/public/xen.h
@@ -33,6 +33,8 @@
 #include "arch-x86/xen.h"
 #elif defined(__ia64__)
 #include "arch-ia64.h"
+#elif defined(__arm__)
+#include "arch-arm.h"
 #else
 #error "Unsupported architecture"
 #endif
diff --git a/xen/include/xen/libelf.h b/xen/include/xen/libelf.h
--- a/xen/include/xen/libelf.h
+++ b/xen/include/xen/libelf.h
@@ -23,7 +23,7 @@
 #ifndef __XEN_LIBELF_H__
 #define __XEN_LIBELF_H__
 
-#if defined(__i386__) || defined(__x86_64__) || defined(__ia64__)
+#if defined(__i386__) || defined(__x86_64__) || defined(__ia64__) || defined(__arm__)
 #define XEN_ELF_LITTLE_ENDIAN
 #else
 #error define architectural endianness
diff --git a/xen/include/xen/timer.h b/xen/include/xen/timer.h
--- a/xen/include/xen/timer.h
+++ b/xen/include/xen/timer.h
@@ -32,8 +32,8 @@
     void *data;
 
     /* CPU on which this timer will be installed and executed. */
-#define TIMER_CPU_status_killed 0xffffu /* Timer is TIMER_STATUS_killed */
-    uint16_t cpu;
+#define TIMER_CPU_status_killed 0xffffffff /* Timer is TIMER_STATUS_killed */
+    uint32_t cpu;
 
     /* Timer status. */
 #define TIMER_STATUS_invalid  0 /* Should never see this.           */
